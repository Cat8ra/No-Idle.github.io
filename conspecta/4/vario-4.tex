\documentclass[a4paper]{article}

\usepackage{../mathstemplate}

\date{IV семестр, весна 2024 г.}
\title{Вариационное исчисление. Неофициальный конспект}
\author{Лектор: Роман Владимирович Романов \\ Конспектировал Леонид Данилевич}

\begin{document}
    \shorthandoff{"}
    \maketitle
    \tableofcontents
    \newpage
    \setcounter{lection}{0}
    \newlection{15 февраля 2023 г.}
    \section{Что мы будем изучать}
    Вариационное исчисление занимается поиском экстремумов в задаче, где число переменных бесконечно.

    Рассмотрим конечномерную ситуацию.
    Пусть имеется $f: M \map \R$, где $M$ --- какое-то многообразие.

    При поиске экстремумов формируеются следующие направления:
    \numbers{
        \item Необходимое условие: $(\grad f)(x) = 0$.
        \item Достаточное: форма $(D^2 f)(x)$ знакоопределён ($> < 0$).
        \item Поиск экстремумов сужения $f\big|_{N}$ на подмногообразие (метод множителей Лагранжа).
    }
    В случае вариационного исчисления вместо $M$ стоит некоторое бесконечномерное пространство, например, пространство функций.
    В основном мы будем заниматься аналогами 1 и 3 пунктов.

    Функция, которая в свою очередь задана на пространстве функций часто называется \emph{функционал}.
    Чтобы визуально различать <<обычные>> функции, и функционалы, образ точки $f$ под действием функционала $J$ будем обозначать $J[f]$.

    Пускай $X$ --- (пока произвольное) метрическое пространство, $J: X \map \R$ --- функция.
    \definition[$x \in X$ --- cтрогий локальный минимум]{
        $\exists \delta > 0: \forall y \in U_{\delta}(x): J[y] > J[x]$. Квадратные скобочки --- косметическое.
    }
    Аналогично определяются нестрогий минимум и максимумы.
    Также стоит вспомнить про существование глобальных строгих и нестрогих минимумов и максимумов.

    \example[Чего такого особенного в бесконечномерии?]{
        Пусть $X = \defset{f \in C[0, 1]}{f(0) = f(1) = 1}$, норма на $C[0, 1]$ определена формулой $\|f\| = \max\limits_{x \in [0, 1]}|f(x)|$.

        Пусть $J[f] \coloneqq \int\limits_{0}^{1}f^2(x)\d x$. Очевидно, $J$ непрерывен.

        Ясно, что $\forall f \in X: J[f] > 0$.
        С другой стороны, $\inf\limits_{f \in X}J[f] = 0$ --- можно рассматривать функции вида
        \[\begin{tikzpicture}
%            \draw[scale=1,domain={0}:{0.1},smooth,variable=\x,blue,line width=0.8pt] plot ({\x},{sqrt(2*\c*\x)});
            \draw[->] (-1,0) -- (3,0) node[right] {$x$};
            \draw[->] (0,-1) -- (0,3) node[above] {$y$};
            \fill (2,0) circle (1.5pt) node[below] {$1$};
            \fill (0,2) circle (1.5pt) node[left] {$1$};
            \fill (0,0) circle (1.5pt) node[below left] {$0$};
            \draw[blue, line width=0.8pt] (0,2) -- (0.1,0);
            \draw[blue, line width=0.8pt] (0.1,0) -- (1.9,0);
            \draw[blue, line width=0.8pt] (1.9,0) -- (2,2);
            \draw[dashed] (0,2) -- (2,2);
            \draw[dashed] (2,0) -- (2,2);
        \end{tikzpicture}\]

        С третьей стороны, $X$ замкнуто: равномерный предел равномерных непрерывен, и условия на значения на концах уважают предел.
        Получается, в данном случае теорема Кантора не работает. В чём дело?

        Оказывается, проблема в том, что нет компактности: в бесконечномерном пространстве замкнутое ограниченное множество необязательно компактно.
    }
    \subsection{Интегральные функционалы}
    В дальнейшем мы будем рассматривать не произвольные функционалы, а ограничимся некоторым их подмножеством.

    Пусть задано непрерывное $L: [a, b] \times \R^n \times \R^n \map \R$, положим $J[u] \coloneqq \int\limits_{a}^{b}L(t, u(t), \dot{u}(t))\d t$.
    Мы будем заниматься множеством $X = C^1[a, b] = C^1([a, b] \map \R^n)$ (далее не будем указывать область значений, ясно из контекста) и его замкнутыми подмножествами.

    Такие $J$ называются \emph{интегральные функционалы}.
    Мы их изучаем, так как на них возможна богатая теория, и вместе с тем, интегральные функционалы часто встречаются в приложениях.
    \examples{
        \item $X = \defset{u \in C^1[a, b]}{u(a) = u_a, u(b) = u_b}, J[u] = \int\limits_{a}^{b}\sqrt{1 + (u')^2}\d x$ --- функционал длин графиков кривых.
        \item $J = \int\limits_{a}^{b}(\frac{\dot u^2}{2} - V(u))\d x$, где $V$ --- заданная функция. В механике называется \emph{действием}.
    }
    Сначала убедимся, что они непрерывны.
    \note[О норме]{
        Для $f \in C^1[a, b]$: $\|f\| = \max\limits_{x \in [a, b]}|f(x)| + \max\limits_{x \in [a, b]}|f'(x)|$ --- очевидно норма. В дальнейшем мы всегда будем использовать такую норму для $C^1$.
    }
    \proposal{
        Пусть $X = C^1[a, b], L \in C([a, b] \times \R^n \times \R^n)$. Тогда интегральный функционал $J$ непрерывен на $X$.
        \provehere{
            Пусть $u, \tilde{u} \in X, \|u - \tilde{u}\| < \delta < 1$. \[\left|J[u] - J[\tilde{u}]\right| = \left|\int\limits_{a}^{b}L(x, \tilde{u}(x), \dot{\tilde{u}}(x)) - L(x, u(x), \dot{u}(x))\d x\right| \circlesign{\le}\]
            Заметим, что    $\|(x, \tilde{u}(x), \dot{\tilde{u}}(x)) - (x, u(x), \dot{u}(x))\|_{\R^{2n + 1}} < \delta$

            Рассмотрим $K = [a, b] \times \overline{B_{\|u\|_X + 1}} \times \overline{B_{\|u\|_{X} + 1}}$ --- компакт в $\R^{2n + 1}$.

            \[\circlesign{\le} \int\limits_{a}^{b}\omega_{L\big|_K}(\delta)\d x = (b - a)\omega_{L\big|_K}(\delta) \underset{\delta \to 0}\Map 0\]
            где $\omega$ --- модуль непрерывности. Он определён, так как $L\big|_K$ непрерывна на компакте.
        }
    }
    Пусть $X$ --- нормированное пространство (необязательно замкнутое), $J: X \map \R$.

    \definition[Производная функционала $J$ в точке $x$ по направлению $h \in X$]{
        \[\delta J[x, h] = \frac{\d}{\d t}\Big|_{t = 0}J[x + th]\]
        Иначе эту штуку называют \emph{вариация} $J$ по направлению $h$.
    }
    \properties[Вариация]{
    \item Однородность: $\delta J[x, ch] = c \cdot \delta J[x, h]$.
    \item Не следует ожидать аддитивность.
        Так, $\exists \delta J[x, h_1], \delta J[x, h_2]$ не влечёт существование $\delta J[x, h_1 + h_2]$, а если последнее и существует, то не обязано быть суммой.

        Примеры этого были в анализе, здесь бесконечномерной специфики нет.
        \item Как и в конечномерном анализе, в критической (экстремальной) точке вариация (коли $\exists$) должна обращаться в нуль.

        А именно, $x \in X$ --- локальный экстремум $J$, тогда $\forall h: \exists \delta J[x, h] \then \delta J[x, h] = 0$.
        \provehere{
            Сужение $\alpha(t) = J[x + th]$ тоже имеет локальный экстремум, значит, если производная в $t = 0$ есть, то нуль.
        }
    }

    \section{Формула первой вариации. Уравнение Эйлера --- Лагранжа}
    \subsection{Лемма Дюбуа-Реймона}
    \lemma[Дюбуа-Реймон]{\label{du-Bois-Reymond}
        Пускай $f \in C[a, b]$, и для всех $\omega \in C^1[a, b]$, таких, что $\omega(a) = \omega(b) = 0$, известно, что $\int\limits_{a}^{b}f \omega' = 0$.

        Тогда $f \equiv \const$.
        \provehere{
            Если бы $f$ сама была гладкой, то можно было бы интегрировать по частям. $\int f'\omega = 0 \then f' \equiv 0$ --- можно взять $\omega$, сосредоточенную там, где $f'$ одного знака.

            Мы надеемся, что $f$ --- константа, то есть равна своему среднему $\overline{f} \bydef \frac{1}{b - a}\int\limits_{a}^{b}f$.

            Проинтегрируем $f - \overline{f}$: $\omega(x) \coloneqq \int\limits_{a}^{x}\left(f(x') - \overline{f}\right)\d x'$. Понятно, что $\omega \in C^1$. Более того, несложно видеть, что $\omega(a) = \omega(b) = 0$.

            Подставим данную $\omega$ в посылку теоремы. \[0 = \int\limits_{a}^{b}f \omega' = \int\limits_{a}^{b}(f - \overline{f})\omega' = \int\limits_{a}^{b}(f - \overline{f})^2\d x\] Так как интеграл нуль, то получаем $f \equiv \overline{f}$.
        }
    }
    \subsection{Формула первой вариации}
    Опять $X = C^1[a, b]$, и функционал того же самого вида $J[u] = \int\limits_{a}^{b}L(t, u(t),\dot{u}(t))\d t$.
    \lemma[Формула первой вариации]{
        Пусть $L \in C^1([a, b] \times \R^n \times \R^n)$.
        Градиент $L$ по второму и третьему аргументам будем обозначать $\nabla_u L$ и $\nabla_{\dot{u}} L$ соответственно, это векторы из $\R^n$.

        Тогда производная $J$ в точке $u$ по направлению $h$ существует, и равна \[\int\limits_a^b\left[\Big\langle(\nabla_u L)(t, u(t), \dot{u}(t)), h(t)\Big\rangle + \angles{(\nabla_{\dot{u}} L)(t, u(t), \dot{u}(t)), \dot{h}(t)}\right]\d t\]
        \provehere{
        $J[u + \tau h] - J[u] = \int\limits_{a}^{b}\left[ L(t, u(t) + \tau h(t) , \dot{u}(t) + \tau \dot{h}(t)) - L(t, u(t), \dot{u}(t))\right]\d t$.

        Применяя формулу Лагранжа, получаем для некой $\tau_* = \tau_*(t) \in [0, \tau]$:
            \multline{J[u + \tau h] - J[u] = \tau\int\limits_{a}^{b} \biggl[\angles{ (\nabla_u L)(t, u(t) + \tau_* h(t), \dot{u}(t) + \tau_* \dot{h}(t)), h(t)} +\\+ \angles{(\nabla_{\dot{u}} L)(t, u(t) + \tau_* h(t), \dot{u}(t) + \tau_* \dot{h}(t)), \dot{h}(t)}\biggr]\d t}

            Поделив на $\tau$, получаем $\frac{J[u + \tau h] - J[u]}{\tau} = \int\limits_{a}^{b} \dots$ --- вот тот, что выше.

            Сперва разберёмся с первым слагаемым. Покажем, что \[\underbrace{\int\limits_{a}^{b}\angles{(\nabla_u L)(t, u(t) + \tau_* h(t), \dot{u}(t) + \tau_* \dot{h}(t)), h(t)}\d t}_{I} \underset{\tau \to 0}\Map \underbrace{\int\limits_{a}^{b}\angles{(\nabla_{u} L)(t, u(t), \dot{u}(t)), h(t)}\d t}_{\II}\]

            Модуль разности аргументов не превосходит $\tau_* \|h\|_{X}$.
            Отсюда $\|\nabla_u L(\dots) - \nabla_u L(\dots)\|_{\R^n} \le \omega_{L\big|_K}(\tau_* \| h\|_X)$, здесь $K \coloneqq [a, b] \times \overline{B_{\|u\| + \|h\|}} \times \overline{B_{\|u\| + \|h\|}}$ (мы считаем, что $\tau \le 1$, откуда $\tau_* \le 1$).

            Значит, $|(I) - (\II)| \le \int\limits_{a}^{b}\omega_{L\big|_K}(\tau_* \|h\|)\d t \le (b - a)\omega_{L\big|_K}(\tau \|h\|)\d t \underset{\tau \to 0}\Map 0$.

            Таким образом, у первого слагаемого под интегралом --- естественный предел.
            Аналогично со вторым слагаемым, получаем утверждение леммы.
        }
    }
    \subsection{Уравнение Эйлера --- Лагранжа}
    Пусть $u \in X$ --- экстремум.
    Тогда $\forall h \in X: \delta J[u, h] = 0$

    Условие обнуления градиента --- некое уравнение на точку.
    Мы хотим уравнение на $u(t)$, избавимся от $h$.
    Подгоним под лемму Дюбуа-Реймона~(\cref{du-Bois-Reymond}).

    Введём $R(x) \coloneqq \int\limits_{a}^{x}(\nabla_u L)(t, u(t), \dot{u}(t))\d t$.
    Тогда $\delta J[x, h] = \int\limits_a^b \angles{\dot{R}(t), h(t)} + \angles{(\nabla_{\dot{u}} L)(t, u(t), \dot{u}(t)), \dot{h}(t)}\d t$
    Интегируя по частям, получим (поскольку $R(a) = 0$) $\angles{R(b), h(b)} + \int\limits_{a}^{b}\Bigl\langle\underbrace{(\nabla_{\dot{u}}L)(t, u(t), \dot{u}(t)) - R(t)}_{\xi(t)}, \dot{h}(t)\Bigr\rangle\d t$

    И это равно нулю $\forall h \in C^1[a, b]$.
    Рассмотрим $h$, обращающийся на концах в ноль: $h(a)=h(b)=0$.
    Теперь $\int\limits_{a}^{b}\angles{\xi(t), \dot{h}(t)}\d t = 0$, и мы покомпонентно можем применить лемму Дюбуа-Реймона, получая $\xi(t) = C \equiv \const$.
    Но $R(t) \in C^1$, значит, $\nabla_{\dot{u}}L(t, u(t), \dot{u}(t)) \in C^1$ тоже.

    Дифференцируя $\xi$, получаем уравнение: $\frac{\d}{\d t}(\nabla_{\dot{u}} L)(t, u(t), \dot{u}(t)) - (\nabla_u L)(t, u(t), \dot{u}(t)) = 0$.
    Оно называется \emph{уравнение Эйлера --- Лагранжа}, это основное уравнение вариационного исчисления.

    \note{
        В случае общего положения уравнение Эйлера --- Лагранжа --- дифференциальное второго порядка, что соответствует $u \in C^2$: при вычислении $\frac{\d}{\d t}(\nabla_{\dot{u}} L)(t, u(t), \dot{u}(t))$ появится в общем случае вторая производная $u$.
        Такая ситуация, на самом деле, довольно общая: экстремаль <<регулярнее>>, чем произвольный элемент своего пространства.
    }
    \subsection{Случай свободных концов}
    Теперь рассмотрим совсем произвольную $h \in C^1$, и получим уравнение на вариацию \[0 = \delta J[u, h] = \angles{R(b), h(b)} + \int\limits_{a}^{b}\angles{C, \dot{h}(t)}\d t = \angles{R(b), h(b)} + \angles{C, h(b)} - \angles{C, h(a)}\]

    \numbers{
        \item Рассмотрим такую $h$, что $h(b) = 0, h(a) = C$.
        Для неё $\delta J[u, h] = -\|C\|^2$, значит, $\xi = C = 0$.

    Подставляя в определение $\xi$, получаем $R(a) = 0$, то есть $(\nabla_{\dot{u}} L)(a, u(a), \dot{u}(a)) = 0$.

    \item Теперь рассмотрим такую $h$, что $h(b) = R(b)$. В этом случае $\delta J[u, h] = \|R(b)\|^2 \then R(b) = 0$.
        Получили $(\nabla_{\dot{u}} L)(b, u(b), \dot{u}(b)) = 0$.
    }
    Итак, помимо уравнения Эйлера --- Лагранжа, мы получили два условия (но в разных точках) на уравнение второго порядка, можно надеяться, что хватит, чтобы найти решения (но это совсем не факт --- так, может существовать одно решение, а может их вовсе не быть, или быть бесконечно много).

    Подытожим в теорему.
    \theorem[Задача со свободными концами]{
        Пусть $L \in C^1([a, b] \times \R^n \times \R^n)$, пусть $X = C^1[a, b]$, пусть $u$ --- локальный экстремум $J$.

        Тогда
        \numbers{
            \item $\left(\nabla_{\dot{u}} L\right)(t, u(t), \dot{u}(t)) \in C^1[a, b]$.
            \item $\frac{\d }{\d t} \nabla_{\dot{u}} L = \nabla_{u} L$ --- уравнение Эйлера --- Лагранжа.
            \item $(\nabla_{\dot{u}} L)(a, u(a), \dot{u}(a)) = 0$
            \item $(\nabla_{\dot{u}} L)(b, u(b), \dot{u}(b)) = 0$
        }
    }
    \subsection{Случай фиксированных концов}
    Теперь обсудим, что происходит, если концы несвободны.

    Рассмотрим $X = \defset{f \in C^1[a, b]}{f(a) = f_a, f(b) = f_b}$.
    Это не подпространство (не имеет линейной структуры), нельзя определить производную по направлению.

    Функционал $J: X \map \R$ задан той же формулой.

    Какая здесь характеризация локальных экстремумов?

    Рассмотрим $\tilde{J}: C^1[a, b] \map \R$ --- с той же формулой, что и $J$.
    Тогда $\forall u, h: \exists \delta\tilde{J}[u, h]$.

    С другой стороны, если $h \in C^1[a, b], h(a) = h(b) = 0$, то $\forall u \in X, t \in \R: u + th \in X$
    Имеем право рассмотреть $J[u + th]$. Если $u$ --- локальный экстремум, то $\frac{\d }{\d t}\big|_{t = 0}J[u + th] = 0$.
    Она существует, так как это $\frac{\d}{\d t}\tilde{J}[u + th]$.

    Тем самым, такие функции $h$ прибавлять можно, будем это тоже называть вариацией: $\delta J[u, h]$ задаётся той же формулой.
    Дальше работает то же самое рассуждение, все действия те же самые, только при интегрировании по частям внеинтегральный член занулится, никаких дополнительных соотношений не возникнет.
    \theorem[Задача с фиксированными концами]{
        Пусть $L \in C^1([a, b] \times \R^n \times \R^n)$, пусть $X = \defset{f \in C^1[a, b]}{f(a) = f_a, f(b) = f_b}$, пусть $u$ --- локальный экстремум $J$. Тогда
        \numbers{
            \item $(\nabla_{\dot{u}} L)(t, u(t), \dot{u}(t)) \in C^1[a, b]$.
            \item $\frac{\d }{\d t} \nabla_{\dot{u}} L = \nabla_{u} L$ --- уравнение Эйлера --- Лагранжа.
        }
    }
    Заметим, что у нас по-прежнему два условия (теперь уже данные в самой задаче) и уравнение второго порядка, значит, по-прежнему, данных для решения задачи как раз столько, что стоит надеяться на получение решения.
    \newlection{29 февраля 2023 г.}
    Распишем чуть подробнее уравнение Эйлера --- Лагранжа, пусть для определённости $d = 1$.
    \[\frac{\d}{\d t}\der{L}{\dot{u}} = \frac{\partial^2 L}{\partial t \partial \dot{u}} + \frac{\partial^2 L}{\partial u \partial \dot{u}}\dot{u} + \frac{\partial^2 L}{\partial \dot{u}^2}\ddot{u}\label{partial}\tag{$*$}\]
    Общая теорема говорит, что $\nabla_{\dot{u}}L$ имеет $C^1$ гладкость, однако совсем не утверждается, что при разложении~\eqref{partial} каждое слагаемое будет гладким, или даже просто будет существовать.
    И правда, такого и не наблюдается.
    \counterexample{
    Рассмотрим функционал $J[u] = \int\limits_{-1}^{1}u^2 (\dot{u} - 2x)^2 \d x$, где $X = \defset{u \in C^1[-1, 1]}{\arr{c}{u(-1) = 0\\u(1) = 1}}$
    и функцию $u \in X, u(t) = \all{0,& x\in [-1, 0] \\ x^2,& x \in [0, 1]}$. $u$ --- экстремаль, например, потому что это глобальный минимум.
    При этом $u \notin C^2$, хотя $\der{L}{\dot{u}} = 2u^2(\dot{u} - 2x) \equiv 0$ --- бесконечно гладкая.
    }
    Что нужно потребовать, чтобы все слагаемые~\eqref{partial} существовали?

    В примере сам лагранжиан $L(x, u, \dot{u}) = u^2(\dot{u} - 2x^2)$ --- бесконечно гладкий.
    Но $\ddot{u}$ можно выразить из~\eqref{partial} только если $\frac{\partial^2}{\partial \dot{u}^2}L \ne 0$.

    Следующее предложение формулируется в случае, когда $L$ задан на $[a, b] \times \R^d \times \R^d$; в общем случае сужения $L$ на некоторое подмножество принципиально ничего не поменяется.
    \proposal{
    Пусть $L \in C^2(\Omega)$, где $\Omega = [a, b] \times \R^d \times \R^d$, пусть $\det \d^2_v L \ne 0$ везде в $\Omega$.

    Пусть $u$ --- локальный экстремум функционала $J$. Утверждается, что $u \in C^2[a, b]$.
    \provehere{
        Введём функцию \begin{align*}\xi: [a, b] \times \R^d &\map \R^d\\ (t, v) &\mapsto (\nabla_{\dot{u}}L)(t, u(t), \dot{u}(t)) - (\nabla_{\dot{u}}L)(t, u(t), v)\end{align*}

    Согласно посылке теоремы, $\d_v \xi \ne 0$ для всех $t, v$.
        Так как $u$ --- экстремум, то $\xi \in C^1$.

    По теореме о неявной функции $\forall t_0 \in (a, b): \exists \delta > 0: \defset{(t, v)}{\xi(t, v) = 0, |t - t_0| < \delta}$ --- график некоторой функции $v \in C^1\left((t_0 - \delta, t_0 + \delta) \map \R^d\right)$.
    Но $v \equiv \dot{u}\big|_{(t_0 - \delta, t_0 + \delta)}$. Значит, $u \in C^2(a, b)$.

    Случай концов ($t_0 = a, b$)--- упражнение.
    }
    }
    \section{Условные экстремумы}
    \emph{Согласно полу-исторической, полулегендарной справке, некогда Дидона прибыла на берег некоего африканского государства, и потребовала, на основании своего высокого происхождения, выделить ей столько земли, сколько можно опоясать ремешком из шкуры одного быка\ldots}

    Напоминание конечномерного случая:
    Пусть $\Omega \subset \R^d$ --- область, $f, g \in C^1(\Omega)$, $\mathcal{M} = \defset{x \in \Omega}{g(x) = 0}$.

    Заинтересуемся экстремумами сужения $f\big|_{\mathcal{M}}$.
    Пусть $x_0 \in \Omega$ -- экстремум.
    Построим кривую ${x:(-\eps,\eps)\map \Omega}$ так, что $x(0) = x_0$.
    Условие $g(x(t)) \equiv 0$ влечёт, что $f(x(t)$ имеет локальный экстремум в нуле.
    Другими словами, $\frac{\d}{\d t}\Big|_{t = 0}f(x(t)) = \angles{(\nabla f)(x_0), \dot{x}(t)} = 0$.

    Поскольку кривую можно выбрать с любым вектором скорости, то $(\nabla f)(x_0) \perp T_{x_0}\mathcal{M}$.
    Если $(\nabla g)(x_0) \ne 0$ в $x_0$, то $T_{x_0}\mathcal{M}$ --- пространство коразмерности $1$.
    Найдём какой-нибудь вектор, перпендикулярный $\mathcal{M}$.
    Это как раз градиент: $g(x(t)) = 0 \then \angles{(\nabla g)(x_0), \dot{x}} = 0$.

    Иными словами $\exists \lambda\in\R: \nabla(f - \lambda g) = 0$.
    Далее для поиска экстремумов ищут критические точки $f - \lambda g$, выделяют те, которые в $\mathcal{M}$, а с обнулениями градиента $g$ разбираемся отдельно.
\ok
    Пускай $X$ --- нормированное замкнутое пространство, $G \in C^1(X)$ --- задающий условие функционал.
    Иными словами,
    \bullets{
    \item $\forall x \in X: \exists G'(x) \in X^*: |G(x + s) - G(x) - G'(x)s| = o(\|s\|)$ --- сильная дифференциуремость в точке $x$.
    \item $G': X \map X^*$ непрерывно.
    }
    Для применения метода множителей Лагранжа нам понадобится лемма, что в направлении всякого вектора из $\Ker G'(x_0)$ можно пустить путь.
    \lemma{
    Пусть $x_0 \in \mathcal{M} \coloneqq \defset{x \in X}{G(x) =  0}$.
    Пусть $G'(x_0) \ne 0$.

    Тогда $\forall h \in \Ker G'(x_0): \exists x: (\delta,\delta) \map \mathcal{M}, x \in C^1: x(0) = x_0, \dot{x}(0) = h$.
    \provehere{
        Фиксируем $\xi \notin \Ker G'(x_0)$. Рассмотрим функцию $G[x_0 + t\xi + \tau h] \eqqcolon r(t, \tau)$. Это $C^1\left(\left[-\eps, \eps\right] \times [-\eps, \eps]\right)$.

        $r(0, 0) = 0$, $\der{t}{t}(0, 0) = G'[x_0]\xi \ne 0$.
        Применяя теорему о неявной функции, получаем $\exists \delta > 0: \defset{(t, \tau)}{\tau \in (-\delta, \delta), r(t, \tau) = 0}$ --- график $C^1$ функции $t = t(\tau), t: (\delta, \delta) \map \R$.

        $x: \tau \mapsto x_0 + t(\tau)\xi + \tau h$ --- искомая кривая.
    \numbers{
    \item По построению $x: (\delta, \delta) \map \mathcal{M}$ --- класса $C^1$.
    \item $\dot{x}(0) = \dot{t}(0)\xi + h$, с другой стороны, дифференцируя тождество $G(x(t)) = 0$, получаем $G'[x(0)] \cdot \dot{x}(0) = 0$
    Отсюда $\dot{x}(0) \in \Ker G'[x_0]$. Значит, $\dot{t}(0) = 0$ (так как $\xi \notin \Ker G'[x_0]$).
        Тем самым, $\dot{t}(0) = h$
    }
    }
    }
    Пускай $F \in C^1(X), x_0 \in \mathcal{M}$ --- точка локального экстремума сужения $F\big|_{\mathcal{M}}$.

    Рассмотрим только что построенную $x(\tau)$.
    Должно быть $\frac{\d}{\d \tau}\Big|_{\tau = 0}F(x(\tau)) = 0$.
    С другой стороны, она же $F'(x_0)\cdot h$.

    Значит, $\Ker G'[x_0] \subset \Ker F'[x_0]$, и $\exists \lambda \in \R: (F'(x_0) - \lambda G'(x_0)) = 0$ --- и $F'$, и $G'$ обнуляются на пространстве коразмерности 1.
    Формальнее $\exists \eta \notin \Ker G'(x_0), \forall h \in X: h = \underbrace{(h - \frac{G'(x_0)h}{G'(x_0)\eta}\eta)}_{\in \Ker G'[x_0]} + \frac{G'(x_0)h}{G'(x_0)\eta}\eta$.
    Значит, $(F' - \lambda G')(h) = F'(x_0) \eta - \lambda G'(x_0)\eta$.
    Подойдёт $\lambda = \frac{F'(x_0)\eta}{G'(x_0)\eta}$

    Получилась теорема:
    \theorem{
    Пускай $F, G \in C^1(X)$, пускай $x_0$ --- точка локального экстремума $F$ на $\mathcal{M} = \defset{x \in X}{G[x] = 0}$, пусть $G'[x_0] \ne 0$.

    Тогда $\exists \lambda \in \R: \forall h \in X: \delta(F - \lambda G)[x_0, h] = 0$ (отметим, что так как $F, G \in C^1$, то $\exists \delta (F - \lambda G)$.)
    }
    \exercise{Задача с фиксированными концами}
    \subsection{Случай нескольких условий}
    Имеется $F, G_1, \dots, G)n \in C^1(X), \mathcal{M} = \defset{x \in X}{G_1[x] = \dots = G_n[x] = 0}$.

    Образуем линейный оператор $\mathbb{G}'(x_0) = \vect{G'_1(x_0) \\ \vdots \\ G'_n(x_0)}: X \map \R^n$ ($\mathbb{G}'(x_0)h = \vect{G'_1(x_0)h \\ \vdots \\ G'_n(x_0)h}$)

    \theorem{
    Пусть $x_0$ --- точка локального экстремума $F$ на $\mathcal{M}$, пусть $\Ran \mathbb{G}'(x_0) = \R^n$ (экви $\sum c_j G'j(x_0) = 0 \then \forall j: c_j = 0$).

    Тогда $\exists \lambda_1, \dots, \lambda_n \in \R: \forall h \in X: \delta(F - \sum \lambda_j G_j)[x_0, h] = 0$
    \provehere{
    \indentlemma{
        В тех же предположениях невырожденности $\Ran \mathbb{G}'(x) = \R^n$ Пусть $\forall j: h \in \Ker G_j'(x_0)$.
        Тогда $\exists x: (-\delta, \delta) \map \mathcal{M}, x \in C^1, x(0) = x_0, \dot{x}(0) = h$.
    }{
        тоже теорема о неявной функции.
    }
    Полностью аналогично скалярному случаю.
    }
    }
    \note{
    Применить скалярную теорему к $G[x] = \sum G_i^2[x]$ не получится, так как $G'[x] = 0$ везде на $\mathcal{M}$.
    }
    \exercise{Задача с фиксированными концами}

    Пускай $L, r_1, \dots, r_n \in C^1([a, b]\times\R^d \times \R^d)$, $J[u] = \int\limits_{a}^{b}L(t, u(t), \dot{u}(t))\d t, R_j[u] = \int\limits_{a}^{b}r_j(t, u(t), \dot{u}(t))\d t$.

    Пускай $u_0$ --- точка локального экстремума $J\big|_{\bigcap R_j}$.
    Пускай $\R(u_0) = \vect{R_1'(u_0) \\ \vdots \\ R_n'(u_0)}$ имеет полный ранг: $\Ran \R(x_0) = \R^n$.

    Тогда
    \numbers{
        \item $\exists \lambda_1, \dots, \lambda_n: \nabla_{\dot{u}}(L - \sum \lambda_j r_j)(t, u_0(t), \dot{u}_0(t)) \in C^1[a, b]$.
    \item Выполнено уравнение Э --- Л: $\frac{\d}{\d t}\nabla_{\dot{u}}(L - \sum \lambda_j R_j) = \nabla_u (L - \sum \lambda_j R_j)$
    \item $\nabla_{\dot{u}}(L - \sum \lambda_j r_j)\Big|_{t = a, t = b} = 0$.
    }
    \provehere{
    Вытекает из доказательства первой теоремы (там использовалось только то, что вариация обращается в нуль, а не то, что $u_0$ --- экстремаль) и только что доказанного.
    }
    \example{
    Пускай $\Omega \subset \R^3$ --- ограниченная односвязная, граница --- класса $C^1$. $X = C(\partial \Omega)$.

    Заведём $J[\sigma] = \iint_{\partial \Omega \:\partial\Omega}\frac{\sigma(x)\sigma(y)\d S(x)\d S(y)}{|x - y|}$.

    $J$ непрерывен на $X$: $\xi: y \mapsto \int_{\partial \Omega}\frac{\sigma(x)}{|x - y|}\d S(x)$ непрерывно.
    \[J[\sigma + s] - J[\sigma] = 2\iint_{\partial \Omega \:\partial\Omega}\frac{s(x)\sigma(y)}{|x - y|}\d S(x)\d S(y) + \bigO(\|s\|^2_C)\]

    Значит, $s \mapsto \int\limits_{\partial\Omega}s(x)\xi(x)\d x$ непрерывен, откуда $J$ --- даже функционал класса $C^1(X)$.
    }
    \newlection{14 марта 2023 г.}
    Заинтересуемся экстремумами с постоянным значением $G[\sigma] = \int\limits_{\partial \Omega}\sigma(x)\d x$.
    Это типа заряды на поверхности, минимизирующие энергию системы --- физический принцип говорит, что конечное положение экстрмально.

    $J, G \in C^1(X)$.

    Пусть $\sigma$ --- экстремаль $J\big|_{\sigma \in X}{G(\sigma) = Q}$.

    Тогда $\delta (J - \lambda G)[\sigma, h] = 0 \forall h \in X$.

    Посчитаем \[\delta (J - \lambda G)[\sigma, h] = ()[\sigma + h] - ()[\sigma] = 2\int\limits_{\partial \Omega}\int\limits_{\partial \Omega}\frac{\sigma(x)h(y)}{|x - y|}\d S(x)\d S(y) - \lambda \int\limits_{\partial \Omega} h(y)\d S(y) + \int\limits_{\partial \Omega}\int\limits_{\partial \Omega}\frac{h(x)h(y)}{|x - y|}\d S(x)\d S(y)\]
    Третье слагаемое $\bigO(\|h\|^2_X)$: $\iint\frac{1}{|x - y|}$ сходится.
    Заметим, что остальная часть --- линейный функционал от $h$, где коэффициент непрерывен от $\sigma$.
    Это в точности значит, что $J \in C^1$.
    \[J[\sigma + h] -J[\sigma] = l(h) + o(\|h\|)\text{, где }l_\sigma: h \mapsto \int \frac{\sigma(x)h(y)}{|x - y|}\d S(y) = \int \xi(y)h(y)\d S(y)\]
    Напишем
    \[\delta(J - \lambda G)[\sigma, h] = 2\int h(y)\d S(y)\left(2\int \frac{\sigma(x)\d S(x)}{|x - y|} - \lambda\right) = 0 \forall h \]
    По <<нулевой лемме Дюбуа-Реймона>>, выражение в скобочках должен быть всегда нулём.

    Получили
    \encircle{\lambda = 2\int \frac{\sigma(x)\d S(x)}{|x - y|}}
Экстремаль $\sigma$ ищется, как решение <<интегрального уранвения>>: $K: f \mapsto \int \frac{f(x)\d S(x)}{|x - y|}$ --- ограниченный непрерывный интегральный оператор.
    Таким образом, $\sigma$ --- решение $K \sigma = \frac{\lambda}{2}\1$.

    Иными словами, потенциал, создаваемый распределением заряда на самой поверхности постоянен.
    Такая постановка задачи не очень естественна --- бывают точечные заряды, что ещё?
    Естественнее было бы рассматривать задачи вида $\sigma$ --- борелевская мера на $\partial \Omega$, $J[\sigma] = \int\frac{\d\sigma(x)\d \sigma(y)}{|x - y|}$.
        Тут уже уместно задавать вопросы о существовании интеграла, сходимости, и прочем, мы не будем это выяснять по причине нехватки аппарата.
% Вот если бы вы выбрали курс по потенциалам, \textbf{А вы не выбрали!}, то там бы вам рассказали об этом подробнее
    \section{Функционалы на кривых}
    Фиксируем две точки, надо, чтобы длина была максимальна.

    В зависимости от расположения параметра, ответ может не реализовываться, как график функции.
    С другой стороны, хотим независимость от параметризации, потому что зачем

    \definition[Кривая $\gamma \in C$]{Непрерывное отображение $\gamma: [a, b] \map \R^n$}
    \definition[Параметризованная кривая]{$\gamma'(x) \ne 0\forall x \in [a, b]$}.
    \definition[Кривая $\gamma \in C^j$]{Кривая $\gamma \in C^j$}
    Пусть $\gamma_1: [a_1, b_1] \map \R^n, \gamma_2: [a_2, b_2] \map \R^n$.
    \definition[Эквивалентность кривых]{$\exists \kappa \in C^j([a_1, b_1] \map [a_2, b_2])$ --- диффеоморфизм, такой, что $\gamma_1 = \gamma_2 \circ \kappa$ и $\kappa'(x) > 0 \forall x$}
    Ориентированная кривая --- класс эквивалентности относительно данного отношения.

    Класс эквивалентности $\Gamma^j$ --- кривые класса $C^j$.
    Ещё используют $\Gamma^j[a, b]$.

    Пускай $\Fc \in C(\R^n \times \R^n)$, пусть она однородна порядка $1$ по второму аргументу: $\Fc(\lambda, zw) = \lambda \Fc(z, w) \forall \lambda > 0$.
    $\gamma: [a_\gamma, b_\gamma] \map \R^d$ --- кривая класса $C^1$.

    $J[\sigma] = \int\limits_{a_\gamma}^{b_\gamma}\Fc[\gamma(t), \dot{\gamma(t)}]\d t$ --- <<квадратные скобки не несут никакого смысла>>.

    \proposal{
        В этой ситуации $J$ задаёт функционал на $\Gamma^1$.
    \provehere{
        Пусть $\gamma_1: [a_1, b_1] \map \R^n, \gamma_2: [a_2, b_2] \map \R^n$ --- два эквивалентных представителя.
    \multline{J[\gamma_1] = \int \Fc[\gamma_1(t), \dot{\gamma}_1(t)]\d t = \int \Fc [\gamma_2(\kappa(t)), \dot{\kappa}(t) \cdot \dot{\gamma}_2(\kappa(t))]\d t = \\
    =\int \Fc [\gamma_2(\kappa(t)), \dot{\gamma}_2(\kappa(t))]\dot{\kappa}(t)\d t = \left\|\arr{c}{\tau = \kappa(t) \\ \d \tau = \dot{\kappa}(t)\d t}\right\| = \int \Fc[\gamma_1(\tau), \dot{\gamma}_1(\tau)]\d \tau}
    }
    }
    \examples{
    \item $\Fc(z, w) = |w|$.
        Функционал $J$ --- длина кривой
    \item $\Fc(z, w) = |w|\cdot f(z)$, где, например, $n = 2$, $f(z) = z_2^{\alpha}$ (здесь $z = \vect{z_1\\z_2}$).
    \bullets{
        \item При $\alpha = 0$ это предыдущий случай.
        \item При $\alpha = -1$ это длина в гиперболической плоскости (в модули Пуанкаре --- Лобачевского \comment{их?}).
        \item При $\alpha = 1$ это координата центра масс, или же площадь поверхности вращения.
    \item При $\alpha = -\frac{1}{2}$ это время, требуемое шарику, чтобы скатиться по жёлобу данной формы.
    }
    }
    Пусть $L \in C([a, b] \times \R^n \times \R^n)$, $X = C^1[a, b]$, $J[u] = \int\limits_{a}^{b}L(t, u(t), \dot{u}(t))\d t$.
    Превратим его в функционал на кривой.
    Заведём $\Fc: \R^{n+1}\times\R^{n+1}, \Fc(z, w) = L(z_1, z_2, \dots, z_{n+1}, \frac{w_2}{|w_1|}, \dots, \frac{w_{n+1}}{|w_1|})|w_1|$.
    Она имеет требуемую однородность.
    Типа сопоставим функции $u(t)$ кривую $\gamma_u: t \mapsto (t, u(t))$.
    % Потолок пробили, но сверху постучали

    Рассмотрим $\tilde{J}[\gamma] \coloneqq \int\Fc(\gamma(t), \dot{\gamma}(t))\d t$ --- если $L$ <<разумная>>, то $\tilde{J}$ --- функционал на кривых.
    \proposal{
    $\Fc[\gamma_u] = J[u]$.\provehere{$\dot{\gamma}_u(t) = (1, \dot{u}(t))$.}
    }
%    Сформулируем некоторое техническое утверждение, которым будем пользоваться в меньшей общности, и докажем не здесь, но сформулируем сейчас
    \statement{
    Пусть $\Fc \in C^2(\R^n \times (\R^n \sm \{0\}))$ (требование непрерывности по совокупности переменных $\Fc \in C(\R^n \times \R^n)$ накладывается всегда в данной теории).

    Пусть $\forall \lambda > 0: \Fc(z, \lambda w) = \lambda\Fc(z, w)$.

    $E\{\gamma\} = (\nabla_{z} \Fc)(\gamma, \dot{\gamma}) - \frac{\d}{\d t}\nabla_w \Fc(\gamma, \dot{\gamma})$, где $J = \int \Fc[\gamma, \dot{\gamma}]\d t$ --- определение осмысленно, так как кривая параметризована, и $\dot{\gamma} \ne 0$, а $\Fc \in C^2(\dots)$.
    % Пределы не стоят намеренно, так как параметризации могут разниться
        Пусть $\gamma \in \Gamma^2$, $\gamma: [a, b]\map \R^d$.

        Теперь пусть $s \in C^2[a, b] \times [-\eps, \eps] \map \R^n$, и пусть $s(\_, \tau)$ --- кривая (производная ненулевая).
        $\frac{\d}{\d \tau}J[s(\_, \tau)] = \int\limits_{a}^{b}E\{s(x, \tau)\}\d x + \angles{(\nabla_{w}\Fc )(s(x, \tau), \der{s}{x}(x, \tau)), \der{s}{\tau}}\Big|_{a}^{b}$
    \provehere{Упражнение.
    }
    }
    \lemma{
        Пусть $\gamma_1 \sim \gamma_2$ --- представители кривой $\gamma \in \Gamma^2$ ($\gamma_1 = \gamma_2 \circ \kappa$).
        Тогда $E\{\gamma_1\} = \kappa' E\{\gamma_2\}$. Подробнее $(E\{\gamma_1\})(x) = \kappa'(x)\left(E\{\gamma_2\}\right)(\kappa(x))$.
        \provehere{
            \[E\{\gamma_1\}(x) = (\nabla_z) \Fc (\underbrace{\gamma_1(x)}_{\kappa'(x)\gamma_2'(\kappa(x))}, \dot{\gamma}_1(x)) - \frac{\d}{\d x}(\nabla_w \Fc)(\gamma_1(x), \dot{\gamma}_1(x)) = \kappa'(x)(\nabla_z \Fc)\left[\gamma_2(\kappa(x)), \gamma_2'(\kappa(x))\right] - \frac{\d}{\d x}(\dots)\]
            Дифференцируя $\Fc(z, \lambda w) = \lambda \Fc(z, w)$, получаем $\lambda(\nabla_w \Fc)(z, \lambda w) = \lambda (\nabla_w\Fc)(z, w)$
            \[(\dots)-\frac{\d}{\d s}\Big|_{s = \kappa(x)}(\nabla_w\Fc)(\gamma_2(s), \gamma_2'(s)) = \kappa'(x)\cdot (E\{\gamma_2\})(\kappa(x))\]
        }
    }
    \corollary{
    $E\{\gamma_1\} \equiv 0 \iff E\{\gamma_2\} \equiv 0$ при $\gamma_1 \sim \gamma_2$.
    }
    Заведём метрику на $\Gamma^2$, чтобы определить экстремумы

    $\xi, \nu: [a, b] \map \R^d$ --- представители $\gamma_\xi, \gamma_\nu \in \Gamma^2$.

    Пусть $|\dot{\xi}| \equiv c_\xi, |\dot{\nu}| \equiv c_\nu$

    Положим $\|\gamma_\xi - \gamma_\nu\| = \|\xi - \nu\|_{C^2[0, 1]}$.
    \exercise{
    Проверить, что это метрика на $\Gamma^2$.
    }
    С метрикой также пришли всевозможные локальные, глобальные, строгие, нестрогие, минмимумы и максимумы.
    \theorem{
    Пусть $\gamma$ --- локальный максимум $\Gamma^2$, $\Fc \in C^2(\R^n \times (\R^n \sm \{0\})), \Fc(z, \lambda w) = \lambda \Fc(z, w), \lambda > 0$.

    Пусть $\gamma_a, \gamma_b \in \R^n, \mathcal{D} = \defset{\gamma \in \Gamma^2}{\gamma(a_\gamma) = \gamma_a, \gamma(b_\gamma) = \gamma_b}$.
    Тогда $E\{\gamma\} = 0$.
    \provehere{
    $\gamma + \tau h, h(a_\gamma) = h(b_\gamma) = 0$, $h: [a_\gamma, b_\gamma] \map \R^d, h \in C^2$

    Существует $\frac{\d}{\d \tau}J[\gamma + \tau h] = 0$, так как $\dot{\gamma}(s) \ne 0$, значит, $\|\dot{\gamma}(s)\| \ne 0$, и при достаточно малых $\tau: \min\|\dot{\gamma} + \tau \dot{h}\| > \eps$.
        Значит, при подстановке мы попадём в область, где $\Fc \in C^2$.

    Раз $\gamma$ --- экстремум, то производная равна нулю.

    $J[\gamma + \tau h] - J[\gamma] = \tau\int\angles{(\nabla_z\Fc)(\gamma, \dot{\gamma}), h} + \angles{(\nabla_w\Fc)(\gamma, \dot{\gamma}), h'}\d t + \bigO(\tau^2)$

    Интегрируя по частям, получаем $\int\limits_{a}^{b}\angles{E\{\gamma\}, h}\d t + 0 + \bigO(\tau^2)$.
        Применяя <<нулевую лемму Дюбуа-Реймона>>, получаем $E\{\gamma\} = 0$.
    }
    }
    \newlection{28 марта 2024 г.}
    \section{Условия трансверсальности. Задача Лагранжа}
    Пусть $J$ --- функционал на кривой, концы которой должны находиться на двух заданных многообразиях $M_1, M_2 \subset \R^n$.
    Считаем, что $J[\gamma], M_1, M_2 \in C^1$.
    Рассматриваем функционал на пространство $X = \defset{\gamma \in \Gamma^2}{\gamma(a_\gamma) \in M_1, \gamma(b_\gamma)\in M_2}$.

    $J[\gamma] = \int\mathcal{F}[\gamma, \dot{\gamma}]\d t$, где $\mathcal{F} \in C^2(\R^n \times (\R^n \sm \{0\})) \cap C(\R^n \times \R^n)$.

    Пусть $\gamma_0$ --- локальный экстремум $J$ на $X$.
    Тогда $\gamma_0$ --- экстремум на $\defset{\gamma \in X}{\gamma(a_\gamma) = \gamma_0(a_{\gamma_0}), \gamma(b_\gamma) = \gamma_0(b_{\gamma_0})}$, следовательно, $E\{\gamma_0\} = 0$.

    Изучим граничные условия.
    Теперь кривая вида $\gamma + \tau h$ не лежит в $X$, поэтому просто изучить вариацию не получится.

    Попробуем подвигать один из концов кривой так, чтобы он оставался на многообразии, и через некоторое расстояние подвинутая кривая сливалась с изначальной.

    $a \coloneqq a_{\gamma_0}, b \coloneqq b_{\gamma_0}$.

    Пусть $r: (-\eps, \eps) \map M_1, r \in C^2, r(0) = \gamma_0(a)$.
    Пусть $\delta > 0$ мало, $c \in \R$ --- какое-то.
    Рассмотрим $s(t, \tau) = \all{\gamma_0(t) + r(\tau) - \gamma_0(a), & t \in [a, a + \delta) \\ \gamma_0(t),& t \in [b - c, b]}$
    Потребуем $s(t, 0) = \gamma_0(t)$, $s \in C^2([a, b] \times (-\eps, \eps)$, $s(t, \_) \in X$.
    Также потребуем, чтобы $\forall t, \tau: \der{s}{t} \ne 0$, чтобы кривая была регулярной.

    \example{$s(t, \tau) = \gamma_0(t) + (\text{правая половина шапочки от $a$ до $a + \delta$, которая $0$ правее $b$}) \cdot (r(\tau) - r(0))$.}

    $J[s(\_, \tau)]$ имеет локальной минимум при $\tau = 0$.
    Положим $f(\tau) = J[s(\_, \tau)]$, и посчитаем $f'(\tau)$.
    \[f(\tau) - f(0) = \int\angles{\nabla_u \mathcal{F}, s - \gamma_0} + \angles{\nabla_{\dot{u}}\mathcal{F}, \dot{s} - \dot{\gamma}_0} + \bigO(\|s(\_, \tau) - \gamma_0\|_{\Gamma^2})\]
    Далее считаем, что всё перепараметризовано так, что все кривые определены на $[0, 1]$, \comment{так что ли}.
    \[f(\tau) - f(0) = \int\angles{\nabla_u \mathcal{F}, s - \gamma_0} + \angles{\nabla_{\dot{u}}\mathcal{F}, \dot{s} - \dot{\gamma}_0} + \bigO(\|s(\_, \tau) - \gamma_0\|_{C^2})\]
    Также считаем, что $\|s(\_, \tau)\|$ \comment{что?}
    \[\tau\int\angles{\nabla_u\mathcal{F}, \der{s}{\tau}(\_, 0)} + \angles{\nabla_{\dot{u}}\mathcal{F}, \der{s}{\tau}(\_, 0)} + \bigO(\tau^2) = \tau\int\angles{E\{\gamma_0\} + \der{s}{\tau}(\_, 0)} + s(t, \tau) = \gamma_0(t) - \angles{(\nabla_{\dot{u}}\mathcal{F}(\gamma_0)(a), \der{s}{\tau}(a, 0))} + \bigO(\tau^2)\]
    Точку $b$ опускаем, так как $\der{s}{\tau}(b, 0) = 0$ по построению.

    Итак,
    \[f'(\tau) = 0 \then \angles{\nabla_{\dot{u}}\mathcal{F}(\gamma_0(a)), \der{r}{\tau}(0)}\]
    Так как $r$ --- любая кривая, то $(\nabla_{\dot{u}}\mathcal{F})(\gamma_0)(a) \perp T_{\gamma_0(a)}M$.

    Аналогично со вторым концом.

    Запишем всё это в теорему:
    \theorem{
    Пускай $J$ --- функционал на кривой ($\mathcal{F} \in C(\R^n \times \R^n) \cap C^2(\R^n \times (\R^n \sm \{0\}))$), $M_1, M_2 \subset \R^n$ --- многообразия класса $C^1$, пусть $\gamma_0$ --- локальный экстремум $J$ на $X$.

    Тогда
    \numbers{
    \item $E\{\gamma_0\} = 0$.
    \item $\all{(\nabla_{\dot{u}}\mathcal{F})(\gamma_0)(a) \perp T_{\gamma_0(a)}M_1 \\ (\nabla_{\dot{u}}\mathcal{F})(\gamma_0)(b) \perp T_{\gamma_0(b)}M_2}$ --- условия трансверсальности.

    }
    }
    \examples{
    \item $\mathcal{F}(z, w) = |w|$.
    Минимум этого функционала --- расстояние от $M_1$ до $M_2$.

        Условия из теоремы означают, что $\dot{\gamma}_0(a) \perp T_{\gamma(a)}M_1, \dot{\gamma}_0(b) \perp T_{\gamma(b)}M_1$, то есть...
    $\nabla_u\Fc = \frac{w}{|w|}\then\frac{\d}{\d t}(\frac{\dot{\gamma}_0}{|\dot{\gamma}_0|}) = 0$.
        Экстремаль --- отрезок, соединяющий два многообразия, и перпендикулярный обоим многообразиям.
    \item $\mathcal{F}(z, w) = g(z)|w|$. $z = \vect{z_1 \\ z_2}$; мы видели, что тут масса полезностей при разных $g$.
    $\nabla_{w}\Fc = g(z)\frac{w}{|w|}$. В этом случае условия трансверсальности тоже сводятся к условиям ортогональности $\dot{\gamma}(a) \perp M_1, \dot{\gamma}(b) \perp M_1$.
    }
    Рассмотрим частный случай: $n = 2, J[y] = \int\limits_{a_y}^{b_y} L(x, y(x), y'(x))\d x$, $L$ --- гладкая (везде, где нужно) на $\R^3$, $\phi, \psi \in C^2$ таковы, что $y(a_y) = \phi(a_y), y(b_y) = \psi(b_y)$.
    Пусть $y \in C^2$.
    Таким образом, многообразия --- графики функций, и концы $y$ лежат на этих графиках.

    Сведёмся к уже доказанной теореме.
    Подберём $\Fc(z, w) \in C(\R^2 \times \R^2)$ так, что $\Fc(z, w) = L\left(z_1, z_2, \frac{w_2}{|w_1|}\right)|w_1|$. Если $y$ --- экстремаль для $J$, то $(x, y(x))$ --- экстремаль для $\Fc$.

    $M_1 = \defset{(x, \phi(x))}{x \in \R}, M_2 = \defset{(x, \psi(x))}{x \in \R}$.

    Пусть $w_1 > 0$ (на интересующей нас кривой $w_1 \equiv 1$).
    Условия трансверсальности: \[\Fc = \left(L\left(z_1, z_2, \frac{w_2}{w_1}\right) - \frac{w_2 w_1}{w_1^2}\der{L}{\dot{u}}\left(z_1, z_2, \frac{w_2}{w_1}\right) \\ \der{L}{\dot{u}}\left(z_1, z_2, \frac{w_2}{w_1}\right)\right)\]
    $\gamma(t) = (t, y(t))$, $\dot{\gamma}(t) = (1, \dot{y}(t))$.
    Тем самым, $(\nabla_w\Fc)(\gamma)(a) \perp \vect{1 \\ \dot{\phi}(a)}$ и $(\nabla_w\Fc)(\gamma)(b) \perp \vect{1 \\ \dot{\psi}(b)}$.

    Распишем это через скалярное произведение: $(L - \dot{y}\der{L}{\dot{y}})(a) \cdot 1 + \der{L}{\dot{y}}\dot{\phi}(a) = 0$.
    Аналогично со вторым концом, это часто записывают в виде
    \[\all{L(a, y(a), \dot{y}(a)) + \der{L}{\dot{y}}(\dot{\phi}(a) - \dot{y}(a)) = 0 \\ L(b, y(b), \dot{y}(b)) + \der{L}{\dot{y}}(\dot{\psi}(b) - \dot{y}(b)) = 0}\]
%    Теперь --- фокусы

    Продемонстрируем элементарный вывод этого факта
%    \begin{tikzpicture}
%        \draw[->] (-1, 0) -- (4, 0) node[right] {$x$};
%        \draw[->] (0, -1) -- (0, 3) node[above] {$y$};
%        \fill (1, 0) node[below]{$x_0$};
%        \fill (1.5, 0) node[below]{$x_0 + \delta x_0$};
%        \fill (3, 0) node[below]{$x_1$};
%        \fill (3.5, 0) node[below]{$x_1 + \delta x_1$};
%
%    \end{tikzpicture}
    \multline{J[\tilde{y}] - J[y] = \int\limits_{x_0 + \delta x_0}^{x_1 + \delta x_1}L(x, \tilde{y}, \dot{\tilde{y}}) - \int\limits_{x_0}^{x_1}L(x, y, \dot{y}) = \int\limits_{x_0}^{x_1}(L(\tilde.) - L()) - \int\limits_{x_0}^{x_0 + \delta x_0}L(\tilde.)  + \int\limits_{x_1}^{x_1 + \delta x_1}L(\tilde.) = \\=
    \int\limits_{x_0}^{x_1}\left(\der{L}{y} - \frac{\d}{\d x}\der{L}{\dot{y}}\right)h \d x + L(x_1, y(x_1), \dot{y}(x_1))\delta x_1 - L(x_0, y(x_0), \dot{y}(x_0))\delta x_0 +\\+ \bigO(\|h\|^2_C) + o(\delta x_1) + o(\delta x_2) + \der{L}{?}h\big|_{x_0}^{x_1}\circlesign{=}}
    Рассматривая финитные $h$, получаем, что первый член $\left(\der{L}{y} - \frac{\d}{\d x}\der{L}{\dot{y}}\right) = 0$.

    $h(x_0) = \delta y_0 - \dot{y}(x_0)\delta x_0 + o(\delta x_0) + o(\|h\|)$ --- уравнение касательной.
    \[\circlesign{=}L(x_1, y(x_1), \dot{y}(x_1))\delta x_1 - L(x_0, y(x_0), \dot{y}(x_0))\delta x_0 + \der{L}{\dot{y}}(x_1)[\delta y_1 - \dot{y}(x_1)\delta x_1] - \der{L}{\dot{y}}[x_0, y(x_0), \dot{y}(x_0)] \cdot [\delta y_0 - \dot{y}(x_0)\delta x_0]\circlesign{=}\]
    С точностью до некоторых малых поправок, $\delta y_1 = \dot{\psi}(x_1)\delta x_1$ и $\delta y_0 = \dot{\phi}(x_0)\delta x_0$.
    \[\circlesign{=}\delta  x_1\left(L + \der{L}{\dot{y}}(x_1, y(x_1), \dot{y}(x_1))(-\dot{y}(x_1) + \dot{\psi}(x_1))\right) + \delta x_0 \cdot (\cdots)\]
    Ура, вроде вывели.
    \section{Инвариантность уравнения Эйлера --- Лагранжа}
    <<Если сделать замену переменной в уравнении Эйлера --- Лагранжа, то решение будет решением задачи, в которой так же заменили переменные>>

    Пусть $T: \R^n \map \R^n$ --- диффеоморфизм, $J[\gamma] = \int\Fc(\gamma, \dot{\gamma})\d t, \Fc(z, \lambda w) = \lambda\Fc(z, w), \lambda > 0$ \comment{(это и раньше требовалось, надо дописать)}.

    Пусть $\gamma$ --- ориентированная кривая, $T \circ \gamma$ --- также ориентированная кривая.
    $J_T[\gamma] \coloneqq J[T \circ \gamma]$, то есть $J_T[\gamma] = \int \Fc[T(\gamma(t)), T'(\gamma(t)) \cdot \dot{\gamma}(t)]\d t$.

    \[J_T[\gamma] = \int\Fc_T[\gamma, \dot{\gamma}]\]
    Функция $\Fc_T(z, w) = \Fc[T(z), T'(z)w]$ имеет ту же однородность.
    Пусть $E_T$ --- $E$, построенная по $\Fc_T$.

    Пусть задача --- с фиксированными концами.
    Согласно когда-то проделанной выкладке: $\delta J_T[\gamma, h] = \int\angles{E_T\{\gamma\}, h}\d t$.
    \multline{
        J_T[\gamma + h] - J_T[\gamma] = J[T(\gamma) + T'(\gamma)h + r] - J_T[\gamma] = \int\angles{\der{\Fc}{\gamma}, T'(0)h + r} + \left(\der{\Fc}{\dot{\gamma}}(T'(\gamma)h + r)'\right) + o(\|h\|_{C^1}) =\\=
    \int\angles{\der{\Fc}{\gamma}, T'(\gamma) h} - \left(\frac{\d}{\d t}\der{F}{\dot{\gamma}}, T'(\gamma)h\right) = \angles{T'(\gamma)^t E\{T(\gamma)\}, h} + o(\|h\|_{C^1})}
    Итак, $E_T\{\gamma\} = T'(\gamma) E(T(\gamma))$ --- заявленная инвариантность.
    \newlection{11 апреля 2024 г.}
    \section{Прямые методы вариационного исчисления}
    У уравнения Эйлера --- Лагранжа есть некоторые недостатки --- так, выявление характера экстремума является отдельной, зачастую весьма сложной, задачей.

    Здесь пойдёт речь о методах, пытающихся построить точки максимума или минимума непосредственно.
    Платой за такое удобство будет общность.

    Здесь всё будет одномерно и скалярно: пусть $p \in C^1[a, b],  q\in C[a, b]$.
    Рассмотрим задачу с фиксированными концами для функционала $J[u] = \int\limits_{a}^{b}(p u'^2 + qu^2)\d x$, где $X \coloneqq \defset{u \in C^1[a, b]}{u(a) = u(b) = 0, \int\limits_{a}^{b}u^2 = 1}$.
    Последнее условие --- нормировочное, если бы его не было, то всегда (ввиду однородности по $u$) инфимумом $J$ был бы либо $0$, либо $-\infty$.

    В рамках ранее рассмотренной теории это является задачей на условный экстремум (при $G[u] = \int\limits_{a}^{b}u^2 = 1$).
    Уравнение Эйлера --- Лагранжа для $J - \lambda G$ получится
    \[2 (p u')' + qu = \lambda u\tag{$*$}\label{sturm}\]
    Из общей теории (и $C^1$-гладкости $p$) следует, что Для экстремума $u$: $p u' \in C^1$, то есть $u \in C^2$ вне окрестности тех точек, где $p$ обращается в $0$.
    Потребуем, чтобы этих точек не было: $\forall x \in [a, b]: p(x) > 0$.

    Задача поиска минимума уравнения~\eqref{sturm} при условиях $\all{\alpha_a u(a) + \beta_a u'(a) = 0 \\ \alpha_b u(b) + \beta_b u'(b) = 0} \left(\text{считается, что }\all{\alpha^2_u + \beta^2_a \ne 0\\ \alpha^2_b + \beta^2_b \ne 0}\right)$ называется задачей Штурма --- Лиувилля.

    Положим $\lambda_J \coloneqq \inf\limits_{X}J$.
    \numbers{
    \item $\lambda_J \ge \min\limits_{x \in [a, b]}q(x)$
    \item Из однородности $\forall u \in C^1[a, b], u(a) = u(b) = 0 \then J[u] \ge \lambda_J \int\limits_{a}^{b}u^2 \d x$.
    }
    Пускай $u_n \in X$ --- минимизирующая последовательность, такая, что $J[u_n] \searrow \lambda_J$.
    Мы докажем, что из соображений компактности можно выбрать равномерно сходящуюся подпоследовательность, и что предел обладает свойствами, которые от него ожидаются.

    Итак, имеется последовательность $u_n \in X$, такая, что $\int\limits_{a}^{b}p u_n'^2 + qu_n^2 \underset{n \to \infty}\Map \lambda_J$.
    Оценим $J[f] \ge \underbrace{\min\limits_{[a, b]}p}_{> 0} \cdot \int\limits_{a}^{b}f'^2 - \max\limits_{[a, b]}q \cdot \underbrace{\int\limits_{a}^{b}f^2}_{1}$.
    Из ограниченности $J[u_n]$ получаем, что $\sup\limits_{n}\int\limits_{a}^{b}u_n' < \infty$.

    Отсюда сразу следует равностепенная непрерывность: $|u_n(x) - u_n(x')| = \abs{\int\limits_{x}^{x'}u'^2_n} \le \sqrt{|x - x'|} \cdot \left(\int\limits_{x}^{x'}u'^2\right)^{\nicefrac{1}{2}}$.
    Эта же оценка показывает равномерную ограниченность: принимая $x = b$, получаем $|u_n(x)| \le \sqrt{b - a} \cdot C$.

    Тем самым, $\{u_n\}$ лежит в компакте внутри $C$, откуда имеется сходящаяся подпоследовательность;
    без потери общности, эта последовательность совпадает с исходной: $\exists u = \lim\limits_{n \to \infty}u_n$, где предел берётся в $C[a, b]$.

    Эта предельная $u$ --- кандидат на минимизирующую функцию.
    Но пока $u$ даже в интеграл не подставить: про гладкость ничего не известно.
    Тем не менее, конечно, $\int\limits_{a}^{b}u^2 = 1$.

    \theorem{
        Так построенное $u \in C^2$ (в том числе $u \in X$), выполнено $-(pu')' + qu = \lambda_J u$, и $J[u] = \lambda_J$.
    \provehere{
    Сначала докажем в слабом смысле: убедимся, что \[\forall h \in C^2[a, b]: h(a) = h(b) = 0 \then \int\limits_{a}^{b}(-(ph')' + qh)u = \lambda_J \int\limits_{a}^{b}h u\tag{$**$}\label{eq3456}\]
        если бы можно было проинтегрировать по частям.

    $J[u_n + \eps h] = \underbrace{\int\limits_{a}^{b} p u_n'^2 + qu_n^2}_{J[u_n]} + 2\eps\int\limits_{a}^{b}(pu h h' + qu_h h) + \eps^2 J[h]$.
    Интегрируя по частям, получаем $-2\eps\int\limits_{a}^{b}u_n (-(ph')' + qh)$, внеинтегральные члены обнулились.

    Здесь, хотя совсем необязательно $u_n + \eps h \in X$, так как нормировка не выполнены, мы подставили в $J$ на $X_0$, заданный той же формулой.

    $J[\lambda_n + \eps h] \ge \lambda_J \int\limits_{a}^{b}(u_n + \eps h)^2 = \lambda_J + 2\eps\lambda_J \int\limits_{a}^{b} u_n h + \eps^2 \lambda_J \int\limits_{a}^{b}h^2$.
    Переходя к пределу в неравенствах, и сокращая $\lambda_J$, получаем
    \[2\eps\int\limits_{a}^{b}u(-(p u')' + qh) + \eps^2 J[h] \ge 2\eps \lambda_J\int\limits_{a}^{b} u h + \eps^2 \int\limits_{a}^{b}h^2\]
    Так как можно выбирать $\eps$ разных знаков, то~\eqref{eq3456} выполнено.

    Выберем $h(x) \coloneqq \int\limits_{a}^{x}\frac{1}{p(t)} \left(\int\limits_{a}^{t}\xi(s)\d s + C\right)\d t$, где $C$ выбрана так, что $h(b) = 0$, где $\xi = -(ph')'$.
    А именно, $C = \int\limits_{a}^{b}\frac{\d t}{p(t)}\int\limits_{a}^{t}\xi / \int\limits_{a}^{b}\frac{1}{p}$

    По построению $h \in C^2, h(a) = h(b) = 0$.
    \multline{
        0 = \int\limits_{a}^{b}\xi u - \int\limits_{a}^{b}(q(x) - \lambda_J)\int\limits_{a}^{x}\frac{1}{p(t)}\left(\int\limits_{a}^{t}\xi(s)\d s + C\right)\d t = \int\limits_{a}^{b}\xi a - \int\limits_{a}^{b}\xi(s)\d s \int\limits_{s}^{b}\frac{\d t}{p(t)}\int\limits_{t}^{b}(q(x) - \lambda_J)\d x +\\+ \frac{1}{\int\limits_{a}^{b}\frac{1}{p}}\int\limits_{a}^{b}\xi(s)\int\limits_{s}^{b}\frac{\d t}{p(t)}\int\limits_{a}^{b}(q(x) - \lambda)\int\limits_{a}^{x}\frac{1}{p}
    }
    \comment{Выкладки 100\% неправильные, так что дальше не переписываю}
    Итак, $0 = \int\limits_{a}^{b}\xi(s)\left[\cdots\right]$, откуда по лемме Дюбуа-Реймона выражение в скобках равно нулю везде, $u \in C^1$.

    Значит, $u$ можно продифференцировать, получим $u' = ...$, откуда $u \in C^2$.
    Тем самым, $(p(s) u'(s))' = q(s) - \lambda_J$, значит, $u \in X$, $J[u] = \int\limits_{a}^{b}p u'^2 + qu^2$.
        Интегрируя по частям, получаем ровно $\lambda_J \int\limits_{a}^{b}u^2$.
    }
    }
    \corollary{
    $u$ --- нестрогий локальный минимум. причём если $J[u] = \lambda_J = J[\tilde{u}] \then u = \pm \tilde{u}$.
    Это следует из того, что $u$ --- решение соответствующего диффура, то есть лежит в одномерном $\R$-пространстве.

    Пусть $u_n$ --- минимизирующая последовательность.
        Выберем $c \in [a, b]$ так, что $|u|(c) \ne 0$ (между прочим, конечный перебор). ($|u|$ находим, как предел $|u_n|$)

    Подправим $u_n$ так, что $u_n(c) \ge 0$. Теперь $u_n \Map u$.
    }
    \ok
    Пусть $u \in X$ --- минимизирующая $J[u] = \lambda_J \eqqcolon \lambda_1$.

    Пусть $X^{(1)} = \defset{f \in X}{\int\limits_0^1{fu} = 0}$
    Обозначим $\lambda_2 \coloneqq \inf\limits_{X^{(1)}}J$.
    Ясно, что $\lambda_2 \ge \lambda_1$.

    Рассуждая аналогично, построим $u_2 \in C[a, b]: \int\limits_{a}^{b}u_2^2 = 1, u_2(a) = u_2(b) = 0, \int\limits_{a}^{b}u_2 u = 0$.
    Аналогично, $\forall h \in C^2: h(a) = h(b) = 0, \int\limits_{a}^{b}hu = 0 \then \lambda_2 \int\limits_{a}^{b}uh = \int\limits_{a}^{b}u_2 (-(ph')' + qh)$.
    Отсюда следует, что $u_2 \in C^2[a, b]$.

    \comment{////}
    Ну, там, короче, я что-то пропустил, но мы получили, что $\lambda_2 > \lambda_1$.
\end{document}
