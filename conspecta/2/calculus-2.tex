\documentclass[a4paper]{report}

\usepackage{../mathstemplate}

\date{II семестр, весна 2023 г.}
\title{Матанализ. Неофициальный конспект}
\author{Лектор: Сергей Витальевич Кисляков\\ Конспектировал Леонид Данилевич}

\begin{document}
    \shorthandoff{"}
    \maketitle
    \tableofcontents
    \newpage
    \setcounter{lection}{0}
    \newlection{14 февраля 2023 г.}


    \section{Вокруг формулы Тейлора}
    В данном разделе будет небольшое количество фактов, касающихся формулы Тейлора.

    \subsection{Достаточное условие существования локального экстремума}
    Пусть $I = \langle a, b \rangle, f: I \map \R, x_0 \in (a, b)$.

    Как известно, если у $f$ в $x_0$ локальный экстремум, то $f'(x_0) = 0$ (если производная в $x_0$ вообще существует).

    Иногда непонятно, экстремум является локальным максимумом или минимумом.
    \theorem{
        Если функция $f$ дифференцируема в некоторой окрестности $x_0 \in (a, b)$, причём $\exists f'(x_0) = 0$ и $\exists f''(x_0)$, то

        \bullets{
            \item если $f''(x_0) > 0$, то $f$ имеет локальный минимум в $x_0$;

            \item если $f''(x_0) < 0$, то $f$ имеет локальный максимум в $x_0$.
        }
        \provehere{
            Запишем формулу Тейлора для $f$ в точке $x_0$:
            \[f(x) = f(x_0) + \underbrace{f'(x_0)}_{0}(x - x_0) + \frac{1}{2}f''(x_0)(x - x_0)^2 + o((x - x_0)^2) = f(x_0) + \frac{1}{2}f''(x_0)(x - x_0)^2 + \alpha(x)\]
            Запишем определение o-маленького:
            \[\forall \eps > 0: \exists \delta > 0: \forall x \in \U[\delta]{x_0}: |\alpha(x)| < \eps \cdot (x - x_0)^2\]
            Рассмотрим случай $f''(x_0) > 0$.
            Получаем $f(x) \ge f(x_0) + \left(\frac{1}{2}f''(x_0) - \eps\right)(x - x_0)^2$ при $x \in \U[\delta]{x_0}$.
            Приняв $\eps = \frac{1}{4}f''(x_0)$ получаем, что $f(x)$ в достаточно маленькой проколотой окрестности $x_0$ больше $f(x_0)$ , откуда $x_0$ --- действительно точка локального минимума.
        }
    }

    \subsection{Ряд Ньютона}
    Рассмотрим формулу Тейлора для $h(x) \coloneqq (1 + x)^r$ в окрестности 0, где $r \in \R$.
    Можно считать, что $h$ определена на всех $x > -1$.
    \[h^{(n)}(x) = r \cdot (r - 1) \proddots (r - n + 1) (1 + x)^{r - n} \then h^{(n)}(0) = r \proddots (r - n + 1)\]
    Запишем формулу Тейлора до $x^k$ с остаточным членом в форме Лагранжа.
    \[h(x) = \sum\limits_{n = 0}^{k}{\frac{r\proddots (r - n + 1)}{n!}}x^n + \frac{r \proddots (r - k)}{(k + 1)!} (1 + \xi)^{r - k - 1} \cdot x^{k + 1},\text{ где }\xi \in [0, x]\]
    Для краткости обозначим $\binom{r}{n} \bydef \frac{r\proddots (r - n + 1)}{n!}x^n$, что согласуется с определением биномиальных коэффициентов для натуральных чисел.

    В таком случае формула упрощается до \[h(x) = \sum\limits_{n = 0}^{k}\binom{r}{n}x^n + \binom{r}{k + 1}(1 + \xi)^{r - k - 1} \cdot x^{k + 1}\]

    Откинув остаточный член, получим \emph{ряд Ньютона} --- ряд Тейлора для функции $(1 + x)^r$ в окрестности 0: $\sum\limits_{n = 0}^{\infty}\binom{r}{n}x^n$.
    \fact{
        Если $|x| < 1$, то ряд Ньютона сходится (к какому-то числу). Более того, для произвольного $b \in (0, 1)$, ряд сходится равномерно при $x \in [-b, b]$.
        \provehere{
            Оценим числа $\left|\binom{r}{n}\right|$.
            Из определения видно, что \[\binom{r}{n + 1} = \binom{r}{n}\cdot\frac{r - n}{n + 1} = \binom{r}{n}\left(\frac{r + 1}{n + 1} - 1\right)\]
            \numbers{
                \item $n \le r$. Первые несколько слагаемых ряда, на сходимость не влияют.
                \item $n > r \ge 0$. Здесь $\left|\frac{r + 1}{n + 1} - 1\right| < 1$, откуда $\left|\binom{r}{n}\right| \le C_r^+$, где $C_r^+$ --- максимальный биномиальный коэффициент $\binom{r}{n}$ для $n \le r$.
                \item $r < 0$. Для любого $\delta > 0: \left|\frac{r + 1}{n + 1} - 1\right| < 1 + \delta$ при достаточно большом $n$. Зафиксируем $\delta$ и назовём эту границу $n_0$.
                В этом случае, обозначив за $C_r^-$ максимальный биномиальный коэффициент $\binom{r}{n}$ при $n \le n_0$, получаем
                \[\sum\limits_{n = n_0}^{\infty}\left|\binom{r}{n}\right| \cdot |x|^n \le \sum\limits_{n = n_0}^{\infty}{C_r^-}(1 + \delta)^{n - n_0} \cdot b^n\]
                Выбрав настолько маленькое $\delta$, что $(1 + \delta)b < 1$, получаем равномерную сходимость --- ряд оценивается сверху геометрической прогрессией. \qedhere
            }
        }
    }

    \subsection{Формула Тейлора с остатком в интегральной форме}
    \theorem{
        Пусть $I$ --- отрезок, $f: I \map \R$ $n + 1$ раз непрерывно дифференцируема на $I$.
        Для произвольных $l, h \in I$:
        \[f(h) = \underbrace{f(l) + \frac{f^{(1)}(l)}{1!}(h - l) + \frac{f^{(2)}(l)}{2!}(h - l)^2 + \dots + \frac{f^{(n)}(l)}{n!}(h - l)^n}_{\text{стандартные слагаемые}} + \underbrace{\frac{1}{n!}\int\limits_{l}^{h}f^{(n + 1)}(t)\cdot(h - t)^n\d t}_{\text{остаток в интегральной форме}}\]
        \provehere{
            Индукция по $n$.

            \underline{База:} $n = 0$, $f$ 1 раз непрерывно дифференцируема. Формула Тейлора обращается в $f(h) = f(l) + \int\limits_{l}^{h}f'(t)\d t$ --- очевидно верно.

            \underline{Переход:} Доказываем для $n + 1$, считая, что для $n$ уже доказано.
            $f \in C^{(n + 2)}(I)$.
            Запишем остаток в интегральной форме для формулы Тейлора порядка $n$.
            \begin{gather*}
                s \coloneqq \frac{1}{n!}\int\limits_{l}^{h}f^{(n + 1)}(t)\cdot(h - t)^n \d t = -\frac{1}{n!}\int\limits_{l}^{h}f^{(n + 1)}(t)\cdot \d\left((h - t)^{n + 1} \cdot \frac{1}{n + 1}\right) = \\
                \text{проинтегрируем по частям} \\
                = -\frac{1}{(n + 1)!}f^{(n + 1)}(t) \cdot(h - t)^{n + 1}\Big|_{t = l}^{t = h} + \frac{1}{(n + 1)!}\int\limits_{l}^{h}(h - t)^{n + 1}f^{(n + 2)}(t)\d t
            \end{gather*}
            Видим, что если подставить пределы интегрирования, то как раз и получится необходимое:
            \[s = \frac{1}{(n + 1)!}f^{(n + 1)}(l)\cdot (h - l)^{n + 1} + \frac{1}{(n + 1)!}\int\limits_{l}^{h}(h - t)^{n + 1}f^{(n + 2)}(t)\d t\qedhere\]
        }
    }
    Оценим остаток в интегральной форме, заменив переменную под интегралом:
    \begin{gather*}
        \frac{1}{n!}\int\limits_{l}^{h}f^{(n + 1)}(t)\cdot(h - t)^n \d t = \\
        \Big\| t = l + (h - l)w = hw + l(1 - w);\qquad h - t = (h - l)(1 - w) \Big\|\\
        = \frac{(h - l)^{n}}{n!}\int\limits_{0}^{1}f^{(n + 1)}(hw + l(1 - w))\cdot(1 - w)^n \d w
    \end{gather*}
    В частности, при $l = 0$, формула упрощается до $s = \frac{h^{n}}{n!}\int\limits_{0}^{1}f^{(n + 1)}(hw)(1 - w)^n \d w$.

    \theorem{
        Ряд Ньютона сходится к $(1 + x)^r$ на $(-1, 1)$. Если $r > 0$, то в точке $x = 1$ сходимость тоже наблюдается.
        \provehere {

            Применим формулу Тейлора с интегральным остатком к $(1 + x)^r$:
            \[(1 + x)^r = \left(\sum\limits_{k = 0}^{n}\binom{r}{k}x^k\right) + s\qquad\text{где } s = \frac{1}{n!} \cdot \left(r \proddots (r - n)\right)\int\limits_{0}^{1}(1 + xw)^{r - n - 1}(1 - w)^n\d w\]

            Для доказательства теоремы необходимо и достаточно показать $s \underset{n \to \infty}\Map 0$.
            \numbers{
                \item Пусть $x \in [0, 1], n > r$.
                В таком случае $(1 + xw)^{r - n - 1} < 1$ и интеграл можно оценить сверху: \[\int\limits_{0}^{1}(1 + xw)^{r - n - 1}(1 - w)^n \d w \le \int\limits_{0}^{1}(1 - w)^n\d w = -\frac{1}{n + 1}(1 - w)^{n + 1}\Big|_0^1 = \frac{1}{n + 1}\]
                \numbers{
                    \item Если здесь $r \ge 0$, то $\left|\frac{r \proddots (r - n)}{n!}\right| \le C_r^+$, и действительно $s \underset{n \to \infty}\Map 0$.
                    \item Если здесь $r < 0$, то считаем, что $x \in [0, 1)$, тогда $\left|\frac{r \proddots (r - n)}{n!}\right| \le C_r^- \cdot (1 + \delta)^n$, где $\delta > 0$ можно выбирать сколь угодно близким к нулю.
                    Выбрав $\delta$ так, что $x(1 + \delta) < 1$, мы тоже увидим, что $s \underset{n \to \infty}\Map 0$.
                }
                \item Теперь пусть $x \in (-1, 0]$.

                Обозначим $I = \int\limits_{0}^{1}(1 + xw)^{r - n - 1}(1 - w)^n\d w = \int\limits_{0}^{1}(1 + xw)^{r - 1}\cdot\left(\frac{1 - w}{1 + xw}\right)^{n}\d w$.

                Для данного $r$ оценим $\abs{(1 + xw)^{r - 1}} \le C_r(x)$.
                Тогда $|I| \le C_r(x) \cdot \int\limits_{0}^{1}\left(\frac{1 - w}{1 + xw}\right)^n\d w$.
                Воспользуемся тем, что $\left(\frac{1 - w}{1 + xw}\right) \le 1 - w(1 - |x|)$ (проверка раскрытием скобок):
                \[1 - w \le (1 - |x|w)(1 - w(1 - |x|)) = 1 - |x|w - w + |x|w^2 + w|x| - w^2|x|^2 = 1 - w + |x|(1 - |x|)w^2\]
                Таким образом
                \multline{|I| \le C_r(x)\int\limits_{0}^{1}(1 - w(1 - |x|))^n\d w = C_r(x) \cdot \frac{-1}{1 - |x|}\cdot\frac{1}{n + 1} \cdot (1 - w(1 - |x|))^{n+1}\Big|_{w = 0}^{w = 1} = \\= \frac{1}{n + 1}\cdot C_r(x)\frac{1 - |x|^{n+1}}{1 - |x|} }
                Опять получаем $s \underset{n \to \infty}\Map 0$.
            }
        }
    }


    \chapter{Введение в многомерный анализ}
    \newlection{17 февраля 2023 г.}
    Пусть $G \subset \R^n$ --- открытое подмножество, дана некоторая функция \[f: G \map \R^m\]
    Рассмотрим некую точку $x \in G$.
    \definition[$f$ дифференцируема в точке $x$]{
        $\exists L: \R^n \map \R^m$ --- линейное отображение (оператор), такое, что \[f(y) - f(x) = L(y - x) + o(|y - x|)\]
    }

    \subsection{О геометрии пространства $\R^n$}
    $\R^n = \underbrace{\R \times \dots \times \R}_{n \text{ раз}}$.
    $\R^n = \defset{(x_1, \dots, x_n)}{x_j \in \R}$ --- состоит из \emph{точек} или \emph{векторов}.
    Сумма векторов, умножение вектора на число понятны;\ рассмотрим скалярное произведение двух элементов $x, y \in \R^n$.
    \[\langle x, y \rangle \bydef x_1 y_1 + \dots + x_n y_n\]

    \subsubsection{Свойства:}
    \bullets{
        \item $\langle x, y \rangle = \langle y, x \rangle$.
        \item Линейность по каждому аргументу: $\langle \alpha x_1 + \beta x_2, y \rangle = \alpha \langle x_1, y \rangle + \beta \langle x_2, y \rangle$.
        \item $\langle x, x \rangle = x_1^2 + \dots + x_n^2$. Число не меньше 0, равенство достигается, когда все координаты нулевые.
        \definition[Длина вектора]{\[|x| \bydef \sqrt{\langle x, x \rangle}\]}
        \item Неравенство Коши-Буняковского-Шварца (КБШ)\[\langle x, y \rangle \le |x| \cdot |y|\]
        \provehere{
            Рассмотрим $t \in \R$. Запишем $\langle x + ty, x + ty \rangle \ge 0$.
            \[\langle x, x \rangle + 2t\langle x, y \rangle + t^2\langle y, y \rangle \ge 0\]
            Если $y = 0$, то исходное неравенство очевидное;\ иначе выше написан квадратный трёхчлен, который неотрицателен, то есть его дискриминант не превышает 0: $\langle x, y \rangle^2 \le \langle x, x \rangle \cdot \langle y, y \rangle$.
        }
        \corollary[Неравенство треугольника для длины]{
            $\forall x, y \in \R^n: |x + y| \le |x| + |y|$.
            \provehere{
                \[|x + y|^2 = \langle x + y, x + y \rangle = \langle x, x \rangle + 2\langle x, y \rangle + \langle y, y \rangle \le |x|^2 + |y|^2 + 2 |x||y| = (|x| + |y|)^2\]
            }
        }
        \item Введём метрику: $d(x, y) = |x - y|$. Несложно проверить всё три свойства, которым функция должна удовлетворять, чтобы быть метрикой.
        В том числе неравенство треугольника: \[d(x, y) = |x - y| = |(x - z) + (z - y)| \le |x - z| + |z - y|\]
        \item Метрика инвариантна относительно сдвига;\ при домножении всех координат на одно и то же число, метрика тоже умножается на это число.

        \fact{
            Пусть $u, u^{(k)} \in \R^n$ (где $k \in \N$).

            Условие \[\left|u - u^{(k)}\right| \underset{k \to \infty}{\Map} 0\]
            означает покомпонентную сходимость.

            \provehere{Несложно оценить из неравенства $x - y \le |x_i - y_i|$ --- расстояние хотя бы разность координатных проекций.}
        }
    }
    Стандартный базис векторов в $\R^n: e_j = (0, 0, \dots, \underbrace{1}_{j}, \dots, 0)$.
    \definition[$x, y \in \R^n$ ортогональны]{$\langle x, y \rangle = 0$.}
    \lemma{
        Если $u_1, \dots, u_m \in \R^n$ все ненулевые и попарно ортогональны, то они линейно независимы.
        \provehere{
            Рассмотрим вещественные числа $\alpha_1, \dots, \alpha_m \in \R$.
            \[x \coloneqq \sum\limits_{i = 1}^{n}\alpha_i u_i\]
            Заметим, что $\langle u_i, x \rangle = \alpha_i |u_i|^2$.

            Таким образом, если $x \in \langle u_1, \dots, u_m \rangle$, то его коэффициенты в линейной комбинации равны $\dfrac{\langle x, u_j \rangle}{|u_j|^2}$.
        }
    }

    Если векторы $u_j$ имеет единичную длину, то эти коэффициенты равны $\langle x, u_j \rangle$.

    \definition[Система векторов называется ортонормированной]{$\langle u_i, u_j \rangle = \delta_{i,j}$.}
    \theorem{
        Пусть $E$ --- линейное подпространство в $\R^n$, $d = \dim(E)$.
        Тогда в $E$ существует ортонормированная система из $d$ векторов.
        \provehere{
            Будем действовать по индукции. Пусть на $k$-м шаге построена ортонормированная система из $k$ векторов $u_1, \dots, u_k$.

            Если $k < d$, то $\exists v \in E \sm E_k$, где $E_k = \langle u_1, \dots, u_k \rangle$.

            Тогда вектор $\tilde{v} = v - (\langle v, u_1 \rangle u_1 + \dots + \langle v, u_k \rangle u_k) \in E \sm E_k$ тоже; несложно проверить, что $\tilde{v}$ ортогонален всякому вектору из $u_1, \dots, u_k$.

            Теперь возьмём пропорциональный ему вектор, длины 1, и добавим в ортонормированную систему.
        }
    }
    Построенная система --- линейно независима, называется ортонормированным базисом пространства.

    Если рассмотреть разложение векторов $x, y$ по ортонормированному базису, то скалярное произведение будет вычисляться по прежней формуле.
    \emph{Линейное подпространство евклидового пространство евклидово.}

    Пусть $L_1, L_2$ --- линейные пространства.
    Отображение $T: L_1 \map L_2$ называется линейным оператором, если оно линейно.

    \subsubsection{Ортогональный проектор на подпространство}
    \theorem{
        Пусть $E$ --- линейное подпространство в $\R^n$.
        Для всякого $x \in \R^n: \exists! a, b \in \R^n: a \in E, b \perp E \land x = a + b$.
        \provebullets{
            \item Единственность: вычтем соответствующие разложения, если они вдруг не единственны. Получим с одной стороны вектор из $E$, а с другой стороны --- ему перпендикулярный.
            \item Разложим по ортонормированному базису с помощью скалярных произведений.
        }
    }
    \definition[Ортогональный проектор]{
        Отображение, сопоставляющее вектору $x$ этот самый вектор $a \in E$.
    }
    \newlection{21 февраля 2023 г.}
    Можно рассмотреть такое определение проектора:
    линейное отображение $T: L \map L$, такое что $T(L) = R$ и $T\Big|_R = \id_R$.

    Отсюда сразу получается $T^2 = T$, что тоже можно взять за определение, а не за свойство.

    Таким свойствам удовлетворяет, например, ортогональный проектор $P: \R^n \map E$, такой, что ${(x - Px) \perp Px}$.

    Для подпространства $E \subset \R^n$ можно определить ортогональное дополнение $E^\perp \bydef \defset{y \in \R^n}{y \perp E} = \Ker P$.

    Очевидно, что $(I - P)$ --- ортогональный проектор на $E^\perp$, где $I$ --- тождественный оператор.

    Пусть $G \subset \R^n$ --- открытое множество, а $F: G \map \R^m$ --- произвольное отображение.

    Для точки $x \in G$ говорят, что $F$ дифференцируема в точке $x$, если $\exists T: \R^n \map \R^m$ --- линейный оператор, такой, что $F(y) - F(x) = T(x - y) + o(|x - y|)$.

    Для пущей строгости можно записать
    \[F(y) - F(x) = T(x - y) + \alpha(x - y)\]
    где $\alpha: U_0 \map \R^m$ для некой окрестности нуля $U_0$, причём $|\alpha(v)| = o(|v|)$.
    Так как теперь $|\alpha(v)|$ и $|v|$ --- скалярные величины, то записывать $o$-малое точно корректно.

    Оператор $T$ называют дифференциалом (дифференциальным отображением) $F$ и записывают $\d F(x, \cdot) = \d F_x (\cdot)$.
    Заметим, что определение полностью согласуется с определением одномерного дифференциала.

    Прежде всего рассмотрим несколько свойств линейных операторов.

    Пусть $T: \R^n \map \R^m$ --- линеен.
    Обозначим $\{e_j\}_{j=1}^{n}$ --- ортонормированный базис пространства $\R^n$, а $\{g_k\}_{k=1}^{m}$ --- ортонормированный базис $\R^m$.

    По определению базиса $x = \sum\limits_{j = 1}^{n}x_j e_j$, откуда конечно же по линейности $T x = \sum\limits_{j = 1}^{n}x_j \cdot T e_j$.

    С другой стороны $T e_j = \sum\limits_{k = 1}^{m}a_{k,j}g_k$, как разложения $T e_j$ по стандартному базису $g$.


    Итого получаем $T x = \sum\limits_{k = 1}^{m}\left(\sum\limits_{j = 1}^{n}a_{k,j}x_j\right)g_k$, где $a_{k,j}$ --- матрица отображения $T$.

    \corollary{
        $T$ --- непрерывное (покомпонентная сходимость) отображение $\R^n \map \R^m$.
    }
    На самом деле выполняется условие, намного более сильное, чем просто непрерывность:
    \proposal{
        $T$ удовлетворяет условию Липшица: $\exists A \in \R: \forall u, v \in \R^n: |Tu - Tv| \le A|u - v|$.

        Эквивалентная запись: $\forall x \in \R^n: |Tx| \le A|x|$.

        \provehere{
            $|Tx|^2 = \sum\limits_{k = 1}^{m}\left(\sum\limits_{j =1}^{n}a_{k,j}x_j\right)^2 \underset{\text{КБШ}}{\le} \sum\limits_{k = 1}^{m}\left(\sum\limits_{j = 1}^{n}a_{k,j}^2\right)\left(\sum\limits_{j = 1}^{m}x_j^2\right) = |x|^2\sum\limits_{k,j}a_{k,j}^2$.

            Теперь видно, что условие Липшица действительно выполняется, для $A = \sqrt{\sum\limits_{k,j}a_{k,j}^2}$.
        }
    }
    Полученная константа $A$ редко бывает самой плотной оценкой, а плотная оценка очень интересна, хотя и сложно вычислима.

    Определим её. Пусть $T: \R^n \map \R^m$ --- линейный оператор.
    \definition[Норма оператора $T$]{
        $\|T\| \bydef \inf \bigdefset{A \in \R}{\forall x \in \R^n: |Tx| \le A|x|}$.
    }
    \proposal{
        $\|T\| = \sup\bigdefset{|Tx|}{|x| \le 1} = \sup\bigdefset{|Tx|}{|x| = 1}$.
        \provehere{
            Очевидно, супремумы достигаются из компактности и теоремы Вейерштрасса.
            Обозначим $\alpha = \sup\bigdefset{|Tx|}{|x| \le 1};\quad\beta =  \sup\bigdefset{|Tx|}{|x| = 1}; \quad \gamma = \|T\|$.

            Заметим, что в определении нормы можно $\inf$ заменить на $\min$, так как в нестрогом неравенстве можно перейти к пределу.

            Несложно видеть из определения, что $\beta \le \alpha \le \gamma$.
            Докажем, что $\gamma \le \beta$.

            Докажем, что $\forall x \in \R^n: |Tx| \le \beta |x|$.

            \bullets{
                \item Если $x = 0$, то неравенство очевидно верно.
                \item Если $x \ne 0$, то $\left|\frac{x}{|x|}\right| = 1$, и можно применить к нему определение $\beta:$
                \[T\left(\frac{x}{|x|}\right) \le \beta \quad \then \quad T x \le \beta |x|\qedhere\]
            }
        }
    }
    \fact{
        Из линейности $T$ можно брать супремум (но он уже не будет достигаться) и по открытому шару тоже: $\|T\| = \sup\bigdefset{|Tx|}{|x| < 1}$.
            \provehere{Рассмотрим точку $x$ на сфере, где равенство выполняется с точностью до $\eps$, немного отступим от неё.}
    }
    \theorem[Свойства нормы]{\down
    \numbers{
        \item $\|T\| = 0 \iff \forall x : Tx = 0$.
        \item $\|aT\| = |a| \cdot \|T\|$
        \item $\|T_1\| + \|T_2\| \ge \|T_1 + T_2\|$.
        \provehere{
            \[\|T_1 + T_2\| = \sup\limits_{|x| \le 1}|(T_1 + T_2)(x)| = \sup\limits_{|x| \le 1}|T_1(x) + T_2(x)| \le \sup\limits_{|x| \le 1}|T_1(x)| + |T_2(x)| \le \|T_1\| + \|T_2\|\]
        }
    }
    }
    Введём метрику $\rho(T_1, T_2) = \|T_1 - T_2\|$.

    Эта метрика задаёт отнюдь не новую топологию на пространстве линейных операторов.
    Чтобы это увидеть, перейдём к матрицам линейных отображений.

    Воспользовавшись оценкой $\|T\| \le \sqrt{\sum\limits_{k,j}(a_{k,j})^2}$ мы сразу видим, что поэлементная сходимость матриц влечёт стремление $\sqrt{\sum\limits_{k,j}(a_{k,j} - b_{k,j})^2} \Map 0$, то есть нормы близких матриц близки.
    Обратное тоже верно --- если норма разности операторов стремится к нулю, то их матрицы покомпонентно сходятся.

    $T e_j = \sum\limits_{k =1}^{m}a_{k,j}g_k$, откуда можно извлечь коэффициенты матрицы: $a_{k,j}(T) = \langle T e_j, g_k \rangle$.

    Обозначим $|||T||| = \sqrt{\sum\limits_{k,j}a_{k,j}(T)^2}$.

    \fact{
        $|a_{k,j}(T)| \le \|T\| \le |||T|||$.
    }

    \theorem{
        $T_s, T: \R^n \map \R^m$ (где $s \in \N$) --- линейные операторы.
        Следующие условия эквивалентны:
        \bullets{
            \item $|||T_s - T||| \Map 0$.
            \item $\|T_s - T\| \Map 0$.
            \item $\forall k, j: a_{k,j}(T_s - T) \Map 0$.
        }
        \provehere{Собрать факты выше.}
    }
    Так как $|||T|||$ --- длина вектора в $\R^{nm}$, то можно считать, что пространство операторов тоже евклидово.

    \proposal{
        Пусть $\R^n \overset{T}\Map \R^m \overset{S}\Map \R^l$, где $T, S$ --- линейные операторы.
        Тогда $\|S \circ T\| \le \|S\| \cdot \|T\|$.
        \provehere{
            $\forall x \in \R^n: |(S \circ T)(x)| \le \|S\| \cdot |Tx| \le \|S\| \cdot \|T\| \cdot |x|$.
        }
    }
    \note{
        В будущем часто при композиции линейных операторов будет записываться, как произведение, в том числе слитно ($ST$).
    }
    Оценим снизу норму инъективных линейных операторов.

    $T: \R^n \map \R^m$ --- линейный оператор --- инъективен, если $\Ker T = \{0\}$.
    Очевидно, необходимым условием является $m \ge n$.
    \theorem{\label{some_lipshitz}
    Следующие условия эквивалентны:
    \numbers{
        \item $\Ker T = \{0\}$.
        \item $\exists m > 0: \forall x \in \R^n: |Tx| \ge m |x|$.
    }
    \provewthen{
        Очевидно.}{
        Рассмотрим единичную сферу $S = \defset{x \in \R^n}{|x| = 1}$.
        Она компактна, так как ограничена и замкнута.

        Введём непрерывную функцию $\phi: S \map \R; \phi(x) = |Tx|$. Очевидно, $\forall x \ne 0: \phi(x) > 0$.

        По теореме Вейерштрасса $\phi$ где-то достигает своё наименьшее значение.
        Пусть $m = \min\limits_{x \in S}\phi(x)$, причём $m = \phi(x_0)$. Тогда $\left|T\left(\frac{x}{|x|}\right)\right| \ge m \then |Tx| \ge m|x|$.
    }
    \provehere[Другой вариант доказательства]{
        Пусть $E = T(\R^n) \subset \R^m$ --- евклидово подпространство.

        $E$ само евклидово, можно считать, что $T: \R^n \map \R^n$ --- биекция.
        Тогда обратное к $T$ --- тоже линейный оператор, значит, у него есть норма, то есть $\forall y \in E: \exists C \in \R: |T^{-1} y| \le C |y|$.

        Собственно, это и требовалось доказать.
    }
    }
%    Будем искать вместо $\lim\limits_{x \to 0}\frac{\tg(x) - x}{x^3} = \lim\limits_{x \to 0}\frac{\sin(x) - x\cos(x)}{x^3}$ другой предел, а именно, $\alpha \coloneqq \lim\limits_{x \to 0}\frac{\sin(x) - x}{x^3}$: очевидно, искомый предел равен $\alpha + \lim\limits_{x \to 0}\frac{x - x\cos(x)}{x^3} = \alpha + \lim\limits_{x \to 0}\frac{1 - \cos(x)}{x^2} = \alpha + \frac{1}{2}$.
%
%    Заметим, что \[\frac{\sin(x) - x}{x^3} = \frac{3\sin\left(\frac{x}{3}\right) - 4 \sin^3\left(\frac{x}{3}\right) - x}{x^3} = \frac{1}{9}\cdot\frac{\sin\left(\frac{x}{3}\right) - \frac{x}{3}}{\left(\frac{x}{3}\right)^3} - 4\frac{\sin^3\left(\frac{x}{3}\right)}{x^3}\]
%    Заведём функцию $f(x) = \frac{\sin(x) - x}{x^3}$.
%    Видим, что $f(x) = \frac{1}{9}f\left(\frac{x}{3}\right) - 4\frac{\sin^3\left(\frac{x}{3}\right)}{x^3}$.
%
%    Отсюда понятно (навесим пределы на равенство), что если бы у $f$ был в нуле предел, то он был бы равен такому числу $\alpha$, что $\alpha = \frac{1}{9}\alpha - \frac{4}{27} \iff \frac{8}{9}\alpha = -\frac{4}{27} \iff \alpha = -\frac{1}{6}$.
%
%    Пойдём от противного: пусть у $f$ нет предела в нуле.
%    Значит, $\exists \eps > 0: \forall \delta > 0: \exists x \in \U[\delta]{0}: \left|f(x) + \frac{1}{6}\right| > \eps$.
%
%    $f(x)$ очевидно нечётна, будем рассматривать $x > 0$.
%    Зафиксируем $\eps$ из условия выше и рассмотрим $\delta > 0$ такую, что $\forall x \in (0, \delta): \left|\frac{\sin^3\left(\frac{x}{3}\right)}{x^3} - \frac{1}{27}\right| < \frac{\eps}{36}\xi$, где $\xi \in (0, 1)$ мы определим позже.
%    Такая $\delta$ найдётся, потому что $\frac{\sin^3\left(\frac{x}{3}\right)}{x^3}$ непрерывна при $x \ne 0$ и имеет предел $\left(\frac{1}{27}\right)$ при $x \to 0$.
%
%    Выразив $f\left(\frac{x}{3}\right) = 9f(x) + 36\frac{\sin^3\left(\frac{x}{3}\right)}{x^3} = -\frac{1}{6} + 9\left(f(x) + \frac{1}{6}\right) + 36\left(\frac{\sin^3\left(\frac{x}{3}\right)}{x^3} - \frac{1}{27}\right)$ получаем, что как только нашёлся такой $x \in (0, \delta)$, что $\left|f(x) + \frac{1}{6}\right| > \eps$, так сразу $\left|f(\frac{x}{3}) + \frac{1}{6}\right| > (9 - \xi)\cdot\left|f(x) + \frac{1}{6}\right|$ (так как мы выбрали настолько маленькую $\delta$, что вклад $36\left(\frac{\sin^3\left(\frac{x}{3}\right)}{x^3} - \frac{1}{27}\right)$ меньше $\xi\eps$).
%
%    Это значит, что $f$ принимает сколь угодно большие (по модулю) значения в окрестности нуля (при $\frac{x}{3^2}, \frac{x}{3^3}$, etc).
%    В частности, найдётся такой $x$, что $\left(f(x) + \frac{1}{6}\right) \cdot x^{\log_3(9 - \xi)} \ne 0$.
%
%    Тогда $\left|\left(f\left(\frac{x}{3}\right) + \frac{1}{6}\right) \cdot \left(\frac{x}{3}\right)^{\log_3(9 - \xi)}\right| > (9 - \xi)\left|f(x) + \frac{1}{6}\right|\cdot\left|\frac{x^{\log_3(9 - \xi)}}{9 - \xi}\right| = \left|\left(f(x) + \frac{1}{6}\right) \cdot x^{\log_3(9 - \xi)}\right|$

    \newlection{28 февраля 2023 г.}
    В терминах $\eps$ и $\delta$ дифференцируемость можно записать так:

    Для функции $F: U \map \R^m$, заданной на открытом множестве $U$ и точки $x_0 \in U$:
    \[\exists A \text{ --- линейный оператор, такой, что } \forall x \in U: F(x) = F(x_0) + A(x - x_0) + o(|x - x_0|)\]
    Определим $\phi(x) = F(x) - F(x_0) - A(x - x_0)$, определённую на $U$.

    Необходимым и достаточным условием является $\forall \eps > 0: \exists \delta: \forall x \in U: |x - x_0| < \delta \then |\phi(x)| \le \eps \cdot |x - x_0|$.

    \fact{
        Если $F$ дифференцируема в точке $x_0$, то $F$ непрерывна в точке $x_0$.
        Более того, выполняется \emph{локальное условие Липшица}:
        \[\exists C \in \R: |F(x) - F(x_0)| \le C |x - x_0| \text{ при достаточно малом }x - x_0\]
        \provehere{
            \begin{gather*}
                F(x) - F(x_0) = A(x - x_0) + \phi(x) \then \\
                |F(x) - F(x_0)| \le \|A\| \cdot |x - x_0| + \eps \cdot |x - x_0| = (\|A\| + \eps)\cdot |x - x_0|\qedhere
            \end{gather*}
        }
    }
    \proposal{
        У данной функции $F: U \map \R^m$ в данной точке $x_0 \in U$ существует не более одного дифференциала.
        \provehere{
            От противного: нашлись $A, B: \R^n \map \R$ --- дифференциалы $F$ в $x_0$.
            \begin{gather*}
                F(x) - F(x_0) = A(x - x_0) + o(|x - x_0|) \\
                F(x) - F(x_0) = B(x - x_0) + o(|x - x_0|) \\
                \Downarrow\\
                (B -A)(x - x_0) = o(|x -x_0|)
            \end{gather*}
            Положим $C = B - A$. Если $C \ne 0$, то $\exists h \in \R^n: C(h) \ne 0$.

            Рассмотрев $t \in \R$, получаем $C(h) = \frac{C(t \cdot h)}{t \cdot |h|} \underset{t \to 0}\Map 0$, противоречие.
        }
    }
    \examples[Простейшие дифференцируемые отображения]{
        \item Постоянное отображение (дифференциал --- 0).
        \item Линейное отображение (дифференциал совпадает с самим отображением).
    }
    \theorem[О композиции дифференцируемых отображений]{\label{multidimension_composition}
    Пусть $U \in \R^n, V \in \R^m$ --- открытые множества.

    При данных отображениях $F: U \map \R^m$ и $G: V \map \R^k$, таких, что $F(U) \subset V$, выберем точки $x_0 \in U$ и $y_0 = F(x_0)$.

    При сделанных предположениях, если $F$ дифференцируема в $x_0$ с дифференциалом $A$, $G$ дифференцируема в $y_0$ с дифференциалом $B$, то $G \circ F$ дифференцируема в $x_0$ с дифференциалом $BA$.
    \provehere{
        \begin{gather*}
            F(x) = F(x_0) + A(x - x_0) + \phi(x), \qquad |\phi(x)| = o(|x - x_0|) \\
            G(y) = G(y_0) + B(y - y_0) + \psi(y), \qquad |\psi(y)| = o(|y - y_0|) \\
            \text{подставим} \qquad y \coloneqq F(x),\: y_0 \coloneqq F(x_0) \qquad\text{(область определения позволяет)}\\
            (G\circ F)(x) = (G \circ F)(x_0) + B(F(x) - F(x_0)) + \psi(F(x))\\
            (G\circ F)(x) = (G \circ F)(x_0) + BA(x - x_0) + B(\phi(x)) + \psi(F(x))
        \end{gather*}
        Покажем, что $\gamma(x) \coloneqq B(\phi(x)) + \psi(F(x)) = o(|x - x_0|)$.
        \[\gamma(x) \le \underbrace{|B(\phi(x))|}_{\le \|B\|\cdot \phi(x) = o(|x -x_0|)} + \underbrace{|\psi(F(x))|}_{o(|x - x_0|)\text{ из-за локальной липшицевости }F}\]
    }
    }
    \theorem{
        Если $U \subset \R^n$ --- открытое множество, а $F_1, F_2: U \map \R^m$ --- дифференцируемы в точке $x_0$, то для $\alpha, \beta \in \R$:
        \[\d(\alpha F_1 + \beta F_2)(x_0, \cdot) = \alpha\cdot \d F_1(x_0, \cdot) + \beta\cdot \d F_2(x_0, \cdot)\]
    }
    Пусть $F: U \map \R^m$ --- отображение.
    \definition[Координатные проекции $F$]{
        Разложим $F(x)$ по стандартному базису: ${F(x) = \sum\limits_{i = 1}^{m}a_i e_i}$.
        Тогда координатными проекциями называются функции $F_j: \R^m \map \R; \quad F_j(x) = a_j$.
    }
    \theorem{
        Пусть $U \in \R^n$ открыто. Утверждается, что $F: U \map \R^m$ дифференцируема в $x_0 \in U$ если и только если $\forall j = 1..m: F_j$ дифференцируема в $x_0$.

        Более того, $\d F(x_0, h) = \vect{\d F_1(x_0, h), &\cdots, &\d F_m(x_0, h)}$
        \provetwhen{
            Рассмотрим линейный оператор $T_j: \R^m \map \R$, сопоставляющий $y \in \R^m$ его $j$-ю координату в разложении по стандартному базису.
            $F_j = T_j \circ F$ --- дифференцируема, как композиция. Утверждение про матрицу дифференциала $F$ следует из того, что матрица дифференциала $T_j$ --- это $(0, \cdots, \underset{j}{1}, \cdots, 0)$
        }{
            Если все $F_j$ дифференцируемы, то $F_j(x) - F_j(x_0) = A_j(x - x_0) + o(|x - x_0|)$, откуда
            \[F(x) - F(x_0) = \vect{A_1(x - x_0),& \dots,&A_m(x - x_0)} + \vect{\phi_1(x),&\dots,&\phi_m(x)}\]
            Несложно видеть, что это дифференцируемость $F$ по определению.
        }
    }

    \subsection{О скалярных функциях $F: (U\subset \R^n) \map \R$}
    \note{
        Пусть $G: U \map \R$ --- скалярная функция, дифференцируемая в $x_0 \in U$, то есть \[G(x) - G(x_0) = A(x - x_0) + o(|x - x_0|)\]
        где $A: \R^n \map \R$ --- линейный функционал.

        Разложим $A(y) = A(y_1 e_1 + \dots + y_n e_n) = y_1 A(e_1) + \dots + y_n A(e_n)$. Положим $\xi_j = A(e_j) \in \R$, тогда $A(y) = \langle y, \xi\rangle$.
    }
    Пусть $F$ дифференцируема в $x_0 \in U$, тогда $\exists \xi: F(x) - F(x_0) = \langle x - x_0, \xi \rangle + o(|x - x_0|)$.
    Таким образом, дифференциальный оператор для $F$ --- скалярное произведение $\langle x - x_0, \xi \rangle$, где $\xi$ называется \emph{градиентом} $F$ в точке $x_0$.
    Обозначается $\grad_{x_0}f$, или (иногда) $\grad f(x_0)$ (имея в виду $(\grad f)(x_0)$).

    \newlection{3 марта 2023 г.}
    Пусть $I \subset \R$ --- открытый отрезок $I = (a, b)$.

    Рассмотрим $g: I \map U$, дифференцируемую в точке $t_0 \in (a, b)$.
    Как и раньше, $U \subset \R^n$.
    Функцию $g$ такого вида называют \emph{векторнозначная функция}.

    Рассмотрим координатные функции $g(x) = \vect{g_1(x), &\dots, & g_n(x)}$.
    $g$ дифференцируема в ${t_0 \in (a, b)} \iff $ все $g_j$ дифференцируемы в $t_0$.

    Но $g_j: \R \map \R$ дифференцируема, если $\exists g_j'(t) = \lim\limits_{t \to t_0}\frac{g_j(t) - g_j(t_0)}{t - t_0}$.

    Найдём дифференциал функции $g$:
    \[g(t) - g(t_0) = \vect{g_1(t) - g_1(t_0), & \dots, & g_n(t) - g_n(t_0)} = \vect{g_1'(t_0), & \dots, & g_n'(t_0)} (t - t_0) + o(|t - t_0|)\]
    Таким образом \[\vect{g_1'(t_0), & \dots, & g_n'(t_0)} = \lim\limits_{t \to t_0}\frac{g(t) - g(t_0)}{t - t_0}\]
    \definition[Производная векторнозначной функции $g$]{
        Соответствующий вектор $\vect{g_1'(t_0), & \dots, & g_n'(t_0)}$.
    }
    В частности, если $g: \R \map \R^3$ --- координата частицы в зависимости от времени, то её производная --- трёхмерный вектор, вектор скорости частицы.

    В случае функции $g$ такого вида её дифференциал $\d g(t_0, h) = g'(t_0) \cdot h$.
    \ok
    Теперь рассмотрим композицию $F = f \circ g$, где $f: U \map \R$ и $g: I \map U$ рассмотрены выше.

    Пусть $g$ дифференцируема в $t_0$, $x_0 = g(t_0), f$ дифференцируема в $x_0$.
    Тогда согласно~(\ref{multidimension_composition}) $F$ дифференцируема в $t_0$, её дифференциал равен композиции дифференциалов $f$ и $g$.
    \begin{gather*}
        \d f(x_0, u) = \langle u, \grad_{x_0}f \rangle \\
        \d g(t_0, h) = g'(t_0) \cdot h \\
        \Downarrow \\
        \d F(t_0, h) = \langle g'(t_0) \cdot h, \grad_{x_0}f \rangle = \langle g'(t_0), \grad_{x_0}f\rangle \cdot h
    \end{gather*}
    Но $F:I \map \R$ --- одномерная функция, дифференцируемость означает существование одномерного предела.
    Отсюда $F'(t_0) = \langle g'(t_0), \grad_{x_0}f\rangle$.
    \ok
    Пусть $e \in \R^n$, $g: I \map U$.
    Определим $g(t) = x_0 + t \cdot e$, где $I$ --- настолько маленький интервал (содержащий 0), что $g(I) \subset U$.

    В таком случае $F'(0)$ записывается более явно: $F'(0) = \langle e, \grad_{x_0}f \rangle$.
    С другой стороны, $F'(0) = \lim\limits_{t \to 0}\frac{f(x_0 + te) - f(x_0)}{t}$.

    Мы проверили, что если $f$ дифференцируема, то предел выше существует (и равен $\langle e, \grad_{x_0}f \rangle$).
    Этот предел называется \emph{производной $f$ по направлению $e$}.

    Выберем в качестве $e$ стандартный орт: $e \in \{e_j\}_{j=1}^{n} = (0, \cdots, 0, \underset{j}{1}, 0, \cdots, 0)$

    \definition[Частная производная $f$ по $j$-й координате]{
        Производная $f$ по направлению $e_j$.
        Обозначается $\dfrac{\partial f}{\partial x_j}(x_0)$
    }
    Тем самым, \[\grad_{x_0}f = \vect{\der{f}{x_1}(x_0) \\ \vdots \\ \der{f}{x_n}(x_0)}\]
    \ok
    Теперь рассмотрим более общий случай: $h: U \map \R^m$ дифференцируема в $x_0 \in U$.
    Как известно, $h = \vect{h_1, & \dots, & h_m}$, где $h_j$ --- соответствующие координатные функции.

    Запишем дифференциал $h$ в виде столбца: \[\d h(x_0, u) = \vect{\d h_1(x_0, u) \\ \vdots \\ \d h_m(x_0, u)} = \vect{\langle \grad_{x_0}h_1, u \rangle \\ \vdots \\ \langle \grad_{x_0}h_m, u \rangle} = \vect{\der{h_1}{x_1}(x_0), & \dots, & \der{h_1}{x_n}(x_0) \\ \vdots & \ddots & \vdots \\ \der{h_m}{x_1}(x_0), & \dots, & \der{h_m}{x_n}(x_0)}\vect{u_1 \\ \vdots \\ u_n}\]

    Получили следующий результат: матрицы дифференциала отображения $h$ в точке $x_0$ выглядит так: \[\left(\dfrac{\partial h_k}{\partial x_j}(x_0)\right)_{j = 1 .. n}^{k = 1..m}\text{ где $k$ --- номер строки, а $j$ --- номер столбца}\]
    При этом, если $h$ дифференцируема в $x_0$, то существуют все частные производные.
    \counterexample[Если частные производные в $x_0$ в направлении всех ортов существуют, то совсем не обязательно отображение дифференцируемо]{
        Например, \[f(x, y) = \all{\dfrac{xy}{x^2 + y^2}, & (x, y) \ne (0, 0) \\ 0, & (x, y) = (0, 0)}\]
        Очевидно, $\der{f}{x}(0, 0) = \der{f}{y}(0, 0) = 0$, но сужение функции на прямую $y = x$ претерпевает в нуле разрыв: $f(t, t) = \frac{1}{2}$ при $t \ne 0$.
    }
    Также можно найти недифференцируемую функцию, у которой есть частные производные по всем направлениям.

    <<Но жить-то как-то надо>>
    \theorem{
        Пусть $f: U \map \R$, где $U \subset \R^n$.

        При условии, что в некоторой окрестности точки $x_0 \in U$ частные производные $\der{f}{x_j}(x)$ существуют, причём непрерывны в точке $x_0$, $f$ дифференцируема в $x_0$.
        \provehere{
            Для удобства доказательства выберем $n = 2$. Утверждается, что при больших $n$ всё то же самое, но писанины больше.

            При $n = 2$ обозначим $x_0 = (u_0, v_0), x = (u, v)$.

            Из непрерывности производных
            \[\forall \eps > 0: \exists \delta > 0: |x - y| < \delta \then \left|\der{f}{x_j}(x) - \der{f}{x_j}(y)\right| < \eps, \qquad j = 1, 2\]
            Запишем \[f(x) - f(x_0) = f(u, v) - f(u_0, v_0) = \Big(f(u, v) - f(u_0, v)\Big) + \Big(f(u_0, v) - f(u_0, v_0)\Big)\]
            Применим к данным двум разностям формулу Лагранжа.
            \[f(x) - f(x_0) = \der{f}{u}(\theta_v, v) \cdot (u - u_0) + \der{f}{v}(u_0, \eta) \cdot (v - v_0) \text{ где $\theta_v$ между $u$ и $u_0$, $\eta$ между $v$ и $v_0$}\]
            Преобразуем выражение, прибавив и вычтя ожидаемое изменение функции --- произведение производной и изменение аргумента.
            \begin{gather*}
                f(x) - f(x_0) = \left(\der{f}{u}(u_0, v_0) \cdot (u - u_0) + \der{f}{v}(u_0, v_0) \cdot (v - v_0)\right) + \\
                \underbrace{\left(\der{f}{u}(\theta_v, v) - \der{f}{u}(u_0, v_0)\right)(u - u_0) + \left(\der{f}{v}(u_0, \eta) - \der{f}{u}(u_0, v_0)\right)(v - v_0)}_{R}
            \end{gather*}
            Первая пара скобок содержит $\langle \grad_{x_0}f, x - x_0 \rangle$, докажем, что остальное мало.

            Зафиксируем некий $\eps > 0$, выберем $|x - x_0| < \frac{\delta}{2}$, где $\delta$ --- функция от $\eps$ из непрерывности производных.

            Тогда все точки $(u_0, v_0), (u_0, \eta), (\theta_v, v)$ находятся на расстоянии меньше $\delta$ друг от друга.

            Применяя КБШ, получаем, что $|R| \le \sqrt{\eps^2 + \eps^2}\cdot|x - x_0| \le \sqrt{2}\cdot\eps|x - x_0|$.
        }
    }
    \definition[Путь]{
        Непрерывное отображение $\gamma: [a, b] \map \R^n$.
        Образ пути $\gamma([a, b])$ называется \emph{носителем} пути.
    }
    \intfact{Кривая Пеано --- путь, у которого носитель --- квадрат $[0, 1] \times [0, 1]$.}
    Пусть $\gamma$ дифференцируема на $(a, b)$, и $U$ --- открытое множество, такое, что $\gamma([a, b]) \subset U$.

    Рассмотрим скалярную функцию $f: U \map \R$, дифференцируемую везде на $U$.

    Зададим $\phi = f \circ \gamma$.
    Несложно видеть, что $\phi$ непрерывна на $[a, b]$, дифференцируема на $(a, b)$.

    Запишем производную $\phi$: \[\phi'(t) = \langle \grad_{\gamma(t)}f, \gamma'(t) \rangle\]
    Применим формулу Лагранжа: $c, d \in [a, b] \then \exists \xi \in [\min(c, d), \max(c, d)]$:
    \[\phi(d) - \phi(c) = \phi'(\xi)(d - c)\]
    Обозначим $y = \gamma(c), x = \gamma(d)$, тогда $f(y) - f(x) = \langle \grad_{\gamma(\xi)}(f), \gamma'(\xi) \rangle(d - c)$

    Получился многомерный вариант формулы Лагранжа.
    \newlection{7 марта 2023 г.}
    Рассмотрим частный вариант формулы выше:
    $[\alpha, \beta] = [0, 1], U$ --- шар с центром в $a$, содержащий $b$.
    Зададим путь прямолинейно: $\gamma(t) = a + t(b - a)$, $t \in [0, 1]$.

    Запишем: \[f(b) - f(a) = \langle \grad_u f, b - a \rangle = \sum\limits_{j = 1}^{n}\der{f}{x_j}(u)(b_j - a_j)\]

    \fact{Если функция $f$ дифференцируема на всём открытом множестве $G$, а точки $a, b$ --- концы некоего отрезка, содержащегося в $G$ целиком, то на этом отрезке найдётся точка $u$, удовлетворяющая условиям.}

    \corollary{
        $|f(b) - f(a)| \le \sup\limits_{u \in [a, b]}|grad_u f| \cdot |b - a|$, \quad где $[a, b] = \defset{a + t(b - a)}{t \in [0, 1]}$.
    }
    \theorem[Векторный вариант предыдущей]{
        Пусть $U \subset \R^n$ --- открытое множество, $F: U \map \R^m$ дифференцируемо во всех точках $U$.

        Если $[a, b] \subset U$, то $\exists u \in [a, b]: |F(b) - F(a)| \le |\d F(u, b - a)|$.
        \provehere{
            \indentlemma[\sout{О двойственности}]{
                Пусть $x \in \R^k$, тогда $|x| = \max\defset{\langle x, y \rangle}{y \in \R^k, |y| \le 1}$.
            }{
                Согласно КБШ $\langle x, y \rangle \le |x|$.

                Если $x = 0$, то доказывать нечего, иначе при $y = \frac{x}{|x|}$ достигается равенство.
            }
            Согласно лемме, $\exists e \in \R^m: |e| = 1$, причём $|F(b) - F(a)| = \langle F(b) - F(a), e \rangle$.

            Рассмотрим скалярную функцию $f: U \map \R; \qquad x \mapsto \langle F(x), e \rangle$.
            $f$ дифференцируема, как линейная комбинация координатных функций $F$.

            Применив для $f$ формулу Лагранжа, получаем: $\exists u \in [a, b]: f(b) - f(a) = \langle \grad_u f, b - a \rangle$.

            Совместив всё полученное:
            \[|F(b) - F(a)| = \langle F(b) - F(a), e \rangle = |f(b) - f(a)| = |\langle \grad_u f, b - a \rangle|\]
            Посчитаем градиент.
            Для этого разложим $F, e$ по базису: $F(x) = \vect{f_1(x), &\dots,&f_m(x)}, e = \vect{e_1,&,\dots,&e_m}$.
            Тогда получаем явное представление $f(x) = \sum\limits_{j = 1}^{m}f_j(x)e_j$.
            Отсюда $\der{f}{x_k}(x) = \sum\limits_{j = 1}^{m}\der{f_j}{x_k}(x) \cdot e_j$.

            Продолжим оценку:
            \[|\langle \grad_u f, b - a \rangle| = \left|\sum\limits_{k = 1}^{n}\der{f}{x_k}(u) \cdot (b_k - a_k)\right| = \left|\sum\limits_{j = 1}^{m}\sum\limits_{k = 1}^{n}\der{f_j}{x_k}(u)(b_k -a_k)e_j\right| = \left|\langle\ \d F(u, b - a), e \rangle\right| \le |\d F(u, b - a)|\]
        }
    }
    \counterexample[Равенства, вообще говоря, может не быть]{
        $n = 1, m = 2$ --- отображение из прямой в плоскость.
        \[f: \left[0, \frac{\pi}{2}\right] \map \R^2; \qquad f: t \mapsto (\cos(t), \sin(t))\]
        Рассмотрим $f\left(\frac{\pi}{2}\right) - f(0) = \vect{0, 1} - \vect{1, 0} = \vect{-1, 1}$.
        \[|f\left(\frac{\pi}{2}\right) - f(0)| = \sqrt{2}\]
        Предположим, что нашлась точка $\theta \in \left(0, \frac{\pi}{2}\right): \sqrt{2} = \left|f'(\theta)\frac{\pi}{2}\right|$.
        Но $|f'(\theta)| = |\vect{-\sin \theta, \cos \theta}| = 1$, и равенство не выполняется: всегда $\underset{\approx 1.41}{\sqrt{2}} < \underset{\approx 1.57}{\frac{\pi}{2}}$
    }
    \corollary{
        $|F(b) - F(a)| \le \|\d F(u, \cdot)\| \cdot |b - a|$.
    }

    \subsection{Замечания про градиент}
    \numbers{
        \item Необходимое условие существования локального экстремума.

        Пусть $X$ --- топологическое пространство, $g: X \map \R$ --- функция, $x_0 \in X$;
        \definition[$g$ имеет локальный максимум в точке $x_0$] {
            Существует окрестность $\U{x_0}: \forall x \in \U{x_0}: g(x) \le g(x_0)$.
        }
        Также бывают \emph{строгие локальный минимум и максимум}.

        Пусть $U \subset \R^n, f: U \map \R$, причём $f$ имеет локальный экстремум в точке $x_0 \in U$.
        \theorem{
            Если $f$ дифференцируема в точке $x_0$, то $\grad_{x_0} f = \vect{0,&\dots,& 0}$.
            \provehere{
                Пусть $v = \grad_f(x_0) \ne \vect{0,&\dots,& 0}$, то есть $\langle v, v \rangle > 0$.
                Рассмотрим малое $t$, при котором в частности $x_0 + tv \in U$, при нём $f(x_0 + tv) - f(x_0) = \langle v, tv \rangle + \phi(tv)$, где $|\phi(h)| = o(h)$.
                Таким образом, если $v \ne \vect{0,&\dots,&0}$, то найдётся малое $t$, такое, что $f(x_0 + tv) > f(x_0)$.
            }
        }
        Условие, разумеется, не является достаточным (даже в одномерной теории).
        \item Про скорость роста в разных направлениях.
        Пусть $U \subset \R^n$, $f: U \map \R$.

        Если $f$ дифференцируема в $x_0 \in U$, то для единичного вектора $e$ определена в окрестности 0 одномерная функция $\phi_e(t) = f(x_0 + te)$.

        По определению $\der{f}{e} = \phi'_e(0) = \langle \grad_f(x_0), e \rangle$.
        \note{
            Из КБШ видно, что $f$ растёт быстрее всего в направлении $e_0 = \frac{\grad_f(x_0)}{|\grad_f(x_0)|}$ (если $\grad_{f}(x_0) \ne 0$).

            Кроме того, $f$ убывает быстрее всего в направлении против градиента.
        }
    }
    \newlection{10 марта 2023 г.}
    Докажем теорему, аналогичную одномерной теореме про производную обратного отображения.

    Пусть $G$ --- открытое множество в $\R^n$, а $F: G \map \R^n$ --- отображение, дифференцируемое во всех точках $G$.

    Выберем $x_0 \in G$, такую, что $F$ непрерывно дифференцируема в $x_0$, то есть ${\left\|\d F(x_0, \cdot) - \d F(x, \cdot)\right\| \underset{x \to x_0}\Map 0}$.

    Иными словами, $\forall j, k: \der{f_k}{x_j}(x) \underset{x \to x_0}\Map \der{f_k}{x_j}(x_0)$.

    Положим $A$ --- матрица $\d F(x_0, \cdot)$ --- матрица линейного отображения.
    Пусть $\Ker \d F(x_0, \cdot) = \{0\}$, то есть $\det A \ne 0$.
    Здесь существенно, что $F$ действует из пространства размерности $n$ в пространство той же размерности.

    \theorem{
        При сделанных предположениях $\exists U$ --- окрестность точки $x_0$, такая, что $F\Big|_U$ --- биекция между $U$ и $F(U)$.

        Утверждается, что $F(U)$ содержит $V$ --- некоторую окрестность точки $y_0 \coloneqq F(x_0)$, причём на $V$ существует обратное к $F$ отображение.

        Утверждается, что $F^{-1}$ дифференцируема в точке $y_0$ и $\d F^{-1}(y_0, \cdot) = A^{-1}$.

        \provehere{
            \indentlemma[Лемма о билипшицевости]{
                Пусть $G \subset \R^n$ --- открыто, $H: G \map \R^m$ --- отображение.

                Предположим, что $H$ дифференцируема в $G$, причём в $x_0 \in G$ дифференцируемость непрерывная.

                Тогда $\exists U \ni x_0$, $\exists C \in \R: \forall x_1, x_2 \in U: |H(x_1) - H(x_2)| \le C |x_1 - x_2|$.

                Более того, если $\Ker \d F(x_0, \cdot) = \{0\}$, то можно выбрать эту окрестность $U$ вместе так, что ещё и $\exists c\in \R: \forall x_1, x_2 \in U: |H(x_1) - H(x_2)| \ge c |x_1 - x_2|$.
            }{
                Обозначим $A = \d F(x_0, \cdot)$ --- матрица дифференциала.
                Положим $H_1(x) = H(x) - Ax$.
                Тогда $\d H_1(x, \cdot) = \d H(x, \cdot) - A$.

                Из непрерывности дифференциала в $x_0$ следует $\forall \eps > 0: \exists \delta: |x - x_0| \le \delta \then \|\d H(x, \cdot) - A\| \le \eps$.

                Таким образом, $\forall u, v \in \overline{B}_\delta(x_0): \underbrace{|H_1(u) - H_1(v)|}_{|(H(u) - H(v)) - A(u - v)|} \le \eps \cdot |u - v|$ --- здесь мы пользуемся неравенством Коши-Лагранжа для дифференциала на пути.

                Раскрыв модуль, получаем $|A(u - v)| - \eps|u - v| \le |H(u) - H(v)| \le |A(u - v)| + \eps|u - v|$.

                Выбрав $\eps = 1$ получаем оценку сверху --- липшицевость функции $H$.
                Теперь надо доказать билипшицевость --- липшицевость $H^{-1}$.

                Это правда, так как~(\ref{some_lipshitz}) $\exists m > 0: \forall w \in \R^n: |Aw| \ge m|w|$, выберем $\eps = \nicefrac{m}{2}$.
            }
            \indentlemma{
                Рассмотрим матрицы линейных отображений $A$ и $\{A_k\}_{k \in \N}: \R^n \map \R^n$.
                Предположим, что $A$ обратима, и $\|A_k - A\| \underset{k \to \infty}\Map 0$.

                Тогда для достаточно больших $k: A_k$ обратима, причём $\|A_k^{-1} - A^{-1}\| \underset{k \to 0}\Map 0$.
            }{
                Согласно~(\ref{some_lipshitz}) $\exists m > 0: \forall w \in \R^n: |A w| \ge m |w|$.

                Заметим, что \[|A_k w| \ge |A w| - |(A - A_k)w| \ge (m - \|A - A_k\|) \cdot |w|\]
                Так как $A_k$ стремится к $A$ по норме, то при достаточно больших $k$: $m - \|A - A_k\| > \frac{m}{2}$.

                Это показывает, что $A_k$ обратимы, начиная с некоторого места. Сходимость $A_k^{-1}$ к $A^{-1}$ можно показать покомпонентно, можно следующей выкладкой:
                \[\|A^{-1} - A_k^{-1}\| = \|{A^{-1}} \cdot (A_k - A) \cdot A_k^{-1}\| \le \underbrace{\|A^{-1}\|}_{\text{const}} \cdot \underbrace{\|A_k - A\|}_{\underset{k \to \infty}\Map 0} \cdot \underbrace{\|A_k^{-1}\|}_{\le \nicefrac{3m}{2}}\]
            }
            Из леммы о билипшицевости получаем $\exists \rho, c, C > 0: \forall u, v \in \overline{B}_\rho(x_0)$:
            \[c|u - v| \le |F(u) - F(v)| \le C|u - v|\]
            В частности, $F$ инъективна.

            Найдём такое $\eta$, что $\overline{B}_\eta(y_0) \subset F(\overline{B}_\rho(x_0))$.

            Рассмотрим $y \in \overline{B}_\eta(y_0)$, решим уравнение $F(x) = y$, где $x$ надо найти в $\overline{B}_\rho(x_0)$.
            Для решения заведём $\Phi: \overline{B}_\rho(x_0) \map \R: \Phi(x) \coloneqq |F(x) - y|^2$.
            По теореме Вейерштрасса она где-нибудь достигает своего наименьшего значения, пусть в точке $z \in \overline{B}_\rho(x_0)$.

            Покажем, что для достаточно малого $\eta$ решение лежит не на границе: $|x_0 - z| < \rho$.
            Докажем это от противного.

            Пусть $|z - x_0| = \rho$, оценим \[\Phi(z) \underset{\text{по определению }z}{\le} \Phi(x_0) = |y_0 - y|^2 \le \eta^2\]
            Ещё оценим \[|F(z) - y| \ge |F(z) - F(x_0)| - |y_0 - y| \ge c|z - x_0| - \eta = c\rho - \eta\]
            Выберем $\eta$ настолько маленьким, что $c\rho - \eta > \eta$. Тогда $|F(z) - y|^2 \ge \eta^2$, противоречие.

            А раз решение лежит не на границе шара, то $F(z) = y$ --- иначе можно пойти против градиента и уменьшиться ещё сильней.
            Получается, градиент нулевой.

            Для любого $\eps > 0$ при выборе достаточно маленького $\rho: \forall z \in \overline{B}_\rho(x_0): \|\d F(z, \cdot) - A\| \le \eps$, то есть $\d F(z, \cdot)$ обратимо.
            Запишем \[\der{\Phi}{x_k}(z) = 2\sum\limits_{j = 1}^{n}\der{f_j}{x_k}(z) \cdot (f_j(z) - y_j)\]
            Из обратимости $\d F(z, \cdot)$ следует невырожденность матрицы $\der{f_j}{x_k}$ (это та же, но транспонированная), откуда при домножении матрицы на вектор $f(z) - y$ не получится нуля --- единственным решением зануления градиента является $f(z) = y$.

            Таким образом, при $\eta < \frac{c \rho}{2}$ все решения уравнений $F(x) = y$ лежат внутри $\overline{B}_\rho(x_0)$.
            Часть про выбор окрестности $V \subset F(U)$ доказана.
            \ok
            \begin{gather*}
                F(x) - F(x_0) = A \cdot (x - x_0) + \phi(x) \text{, где } |\phi(x)| = o(|x - x_0|) \\
                \forall y \in \overline{B}_{\eta}(y_0): \exists x \in \overline{B}_{\rho(x_0)}: F(x) = y \\
                y - y_0 = A (F^{-1}(y) - F^{-1}(y_0)) + \phi(F^{-1}(y)) \\
                B \coloneqq A^{-1} \\
                F^{-1}(y) - F^{-1}(y_0) = B(y - y_0) - B \phi(F^{-1}(y))
            \end{gather*}
            Осталось показать, что $B \phi(F^{-1}(y)) = o(|y - y_0|)$. Применение линейного оператора $B$ на маленькость не влияет, он билипшицев. Также билипшицевы $F$ и $F^{-1}$, так как $\phi(x) = o(|x - x_0|)$, то $B\phi(F^{-1}(y)) = o(|y - y_0|)$.
        }
    }
    \newlection{14 марта 2023 г.}
    В предыдущей лекции мы показали следующее.
    Рассмотрим открытое $G \subset \R^n, F: G \map \R^n$, такие, что $F$ непрерывно дифференцируема всюду.

    Если в некой точке $x_0 \in G$ наблюдается невырожденный оператор $\d F(x_0, \cdot)$, то при $x$, близких к $x_0$, $\d F(x, \cdot)$ тоже невырождены, функция $F^{-1}$ существует и дифференцируема вблизи $F(x_0)$.

    В частности, использовалась лемма, близкая к следующей.
    \lemma{
        Пусть $T: \R^n \map \R^m$ --- линейный оператор, такой, что $\Ker T = \{0\}$.

        Тогда $\exists \eps > 0$, такой, что для любого линейного оператора $\forall S: \R^n \map \R^m: \|S - T\| < \eps \then \Ker S = \{0\}$.
        \provehere{
            Воспользуемся тем, что $\exists m > 0: |T x| \ge m |x|$. Тогда $|S x| \ge |T x| - |(S - T)x| \ge (m - |\eps|)x$.
        }
    }
    \corollary{
        Если $F: G \map \R^n$ --- непрерывно дифференцируемое отображение, такое, что $\d F(x, \cdot)$ невырождено для $x \in U$, то $F(U)$ открыто в $\R^n$.
    }


    \section{Гладкие многообразия}

    \subsection{Касательные векторы}
    Пусть $x_0 \in A \subset \R^n$, где $A$ --- произвольное множество.
    \definition[Касательный к $A$ вектор $e \in \R^n$]{
        Для $t \in \R: \dist(x_0 + te, A) = o(|t|)$ при $t \to 0$.
    }

    \note{
        Для $x_0$ --- внутренней точки $A$ --- все векторы --- касательные.
    }

    \theorem{
        Пусть $F: (U \subset \R^n) \map \R$ дифференцируема, $x_0 \in U$, $A \subset \R^n$.

        Пускай $F\Big|_{A \cap U}$ имеет локальный экстремум в $x_0$.
        Тогда для касательного к $A$ вектора $e \in \R^n: \d F(x_0, e) = 0$.

        \provehere{
            Пусть $e \in \R^n$ --- касательный вектор к $A$ в $x_0$.
            Пойдём от противного: ${d \coloneqq \d F(x_0, e) \ne 0}$.

            Посмотрим на $F(x_0 + te) - F(x_0)$.
            Для любого $t \in \R: \exists x_t \in A: |x_0 + te - x_t| \le 2 \dist(x_0 + te, A)$ по определению расстояния.

            Запишем определение дифференцируемости $F$ в $x_0$.
            \[F(x_t) - F(x_0) = \d F(x_0, x_t - x_0) + \underbrace{\phi(t)}_{o(|t|)} = \d F(x_0, te) + \d F(x_0, x_t - x_0 - te) + \underbrace{\phi(t)}_{o(|t|)}\]
            Так как $|\d F(x_0, x_t - x_0 - te)| \le \|\d F(x_0, \cdot)\| \cdot |x_t - x_0 - te| \le 2\|\d F(x_0, \cdot)\| \cdot |\dist(x_0 + te, A)| = o(t)$, то
            \[F(x_t) - F(x_0) = \d F(x_0, te) + o(|t|) = t \cdot d + o(|t|)\]
            Получили, что $F\Big|_{A \cap U}$ не имеет локального экстремума в $x_0$, противоречие.
        }
    }
    \ok
    Пускай $\Phi: (U \subset \R^n) \map \R^m$, где $m \ge n$.

    Предположим, что $\Phi$ дифференцируема в $U$ и непрерывно дифференцируема в $x_0 \in U$.
    Также предположим, что $\Phi$ билипшицева на своей области определения.

    Положим $A = \Phi(U)$, предположим, что $\Ker \d \Phi(x_0, \cdot) = \{0\}$ (что следует из билипшицевости).
    \theorem{
        При сделанных предположениях множество касательных векторов к $A$ в точке $y_0 \coloneqq \Phi(x_0)$ есть $\d \Phi(x_0, \R^n)$.
        \provehere{ Обозначим $L \coloneqq \d \Phi(x_0, \cdot)$.
        \bullets{
            \item[$\then$.] Пусть $x \in \R^n$, назначим $e = Lx$, докажем, что $e$ --- касательный вектор.
            Ну, в самом деле, $\dist(A, y_0 + te) \le |\Phi(x_0 + tx) - (y_0 + te)| = |\Phi(x_0 + tx) - \Phi(x_0) - tLx|$.
            Точка $\Phi(x_0 + tx)$ была подобрана таким хитрым образом, что
            \[\Phi(x_0 + tx) - \Phi(x_0) - tLx = L(tx)+ \psi(t) - tL x = \psi(t)\text{, \qquad где $|\psi(t)| = o(|t|)$}\]
            \item[$\when$.] Пусть $e$ --- касательный вектор $A$ в точке $x_0$.
            Найдём $x \in \R^n: e = Lx$.

            По определению касательного вектора.
            \[\alpha(t) \coloneqq \dist(y_0 + te, A) = o(|t|)\]
            Выберем $y_t \in A: |y_0 + te - y_t| \le 2 \dist(y_0 + te, A) = 2\alpha(t)$.
            Отсюда $|y_t - y_0| \le C_1 |t|$ для некой константы $C_1 \in \R$.

            $y_t = \Phi(x_t)$ для некоего $x_t$ вблизи $x_0$.
            Ввиду билипшицевости
            \[|y_t - y_0| = |\Phi(x_t) - \Phi(x_0)| \ge C_2 |x_t - x_0| \qquad \then \qquad |x_t - x_0| \le C_3 |t|\]
            Запишем
            \[te + y_t - (y_0 + te) = y_t - y_0 = \Phi(x_t) - \Phi(x_0) = L(x_t - x_0) + \beta(x_t)\]
            где $|\beta(x_t)| = o(|x_t - x_0|)$, или же (см. $C_3$) $\beta(x_t) = o(|t|)$.
            Поделим равенство на $t$:
            \[e + \underbrace{\frac{y_t - (y_0 + te)}{t}}_{o(1)} = L\left(\frac{x_t - x_0}{t}\right) + \underbrace{\frac{\beta(x_t)}{t}}_{o(1)}\]
            Заметим, что $\left|\frac{x_t - x_0}{t}\right| \le C_3$ --- точки $\frac{x_t - x_0}{t}$ лежат в замкнутом шаре.
            Выбрав последовательность $t_n \to 0$, так, что будет сходимость (всегда можно выбрать сходящуюся подпоследовательность), получим $\frac{x_{t_n} - x_0}{t_n} \underset{t \to 0}\Map x$, где вектор $x \in \R^n$ --- искомый: переходя к пределу сразу получаем $e = L(x)$.
        }
        }
    }

    \subsection{Многообразия, вложенные в $n$-мерное евклидово пространство}
    \definition[$n$-мерное многообразие]{
        Хаусдорфовое, со счётной базой, топологическое пространство $X$, у каждой точки которого есть окрестность, гомеоморфная $B^n$.
    }
    Пускай $F: (U \subset \R^n) \map \R^m$ --- отображение.
    \definition[$F$ непрерывно дифференцируема $k$ раз]{
        Все частные производные всех координатных функций до порядка $k$ включительно существуют и непрерывны.

        Пишут $F \in C^{(k)}$.
    }
    \definition[Карта (локальная)]{
        Отображение $h: B^n \map X$, являющееся гомеоморфизмом на свой образ.
    }
    \definition[Атлас]{
        Семейство локальных карт $\{h_\alpha\}_{\alpha \in \Lambda}$, таких, что $\bigcup\limits_{\alpha \in \Lambda}h_\alpha(B_n) = X$
    }
    Такое семейство карт позволяет в каждой маленькой области $X$ ввести свои \emph{координаты}, \emph{параметризовать} $X$.

    Пусть $U_{\alpha} = h_{\alpha}(B^n)$, $U_{\alpha \beta} = U_{\alpha} \cap U_{\beta}$.
    Если $U_{\alpha \beta} \ne \o$, то возникает дилемма --- координаты какого шара использовать?

    Функцию $\phi_{\alpha \beta} = h_{\beta}^{-1} \circ h_{\alpha}$, переводящую координаты $h_{\alpha}$ в координаты $h_{\beta}$, называют \emph{отображением перехода}.

    \definition[$X$ --- гладкое многообразие класса $C^{(k)}$]{
        Многообразие с фиксированным атласом, в котором все отображения перехода принадлежат классу $C^{(k)}$.
    }
    \example{
        Рассмотрим в качестве $X$ график модуля $X \coloneqq \defset{(x, |x|)}{x \in \R}$.

        $X$ гомеоморфно $\R$.
        Если рассмотреть атлас, состоящий из $(a, b) \mapsto ((a, |a|), (b, |b|))$, то все функции перехода будут тождественными, то есть $X \in C^{(\infty)}$.

        Это противоречит интуиции (ведь модуль далеко не гладок в нуле), скоро мы определим гладкость многообразия в соответствии с объемлющим пространством.
    }
    \newlection{17 марта 2023 г.}
    Пусть $F: (G \subset \R^n) \map \R^m$, где $m > n$ (можно также рассматривать случай $m = n$, но в таком случае ничего интересного не будет).
    По-прежнему дифференцируема в некоторой окрестности $x_0$, непрерывно дифференцируема в $x_0$.

    Рассмотрим $x_0 \in G$, считаем, что $F$ --- билипшицева на всё множестве $G$.

    Обозначим $D = \d F(x_0, \cdot)$, предположим, что он невырожден.
    Параметризуем множество $F(G)$.

    $L \coloneqq D(\R^n) \subset \R^m$ --- касательное подпространство к $F(G)$ в точке $y_0 \coloneqq F(x_0)$.
    Заметим, что $\dim L = n$.

    Положим $N \coloneqq L^\perp$.
    Таким образом, $\R^m = L \oplus N$.
    Введём ортогональный проектор $P: \R^m \map L$.

    Выделим из $F$ составляющую $F_1: \R^n \map L; \quad F_1(x) = P F(x)$.
    Её дифференциал $\d F_1(x_0, \cdot) = P D$, что равно $D$, так как $D(\R^n) = L$ --- проектор ничего не меняет.

    В $V$ --- некоторой окрестности точки $P y_0$ --- существует обратное отображение $\phi = F_1^{-1}; \quad \phi: V \map G$.

    Введём $H: V \map \R^m; \quad H(u) = (F \circ \phi)(u)$.
    $H(V)$ --- кусок множества $F(G)$, $H$ --- его локальная карта.

    Произвольный вектор $u \in V$ после применения $H$ раскладывается в пару $H(u) = (a, b)$, где $\R^m$ рассматривается, как $L \oplus N$ и $a \in L, b \in N$.
    $a = P H(u) = P F \phi(u) = u$, так как $\phi$ --- обратная к $P F$.
    Таким образом, первая компонента вектора $H(u)$ --- просто $u$.
    Вторая компонента вектора $\psi(u) \coloneqq (\id - P)H(u)$, какая-то гладкая функция.

    Получили <<новую параметризацию>> $F(G)$.
    Локальной картой $y_0 \in F(G)$ является $H(u) = (u, \psi(u))$, где $u \in V$.

    Таким образом, локально многообразие $F$ --- график какого-то непрерывного отображения $\psi$.
    Найдём его дифференциал: $\d \psi(y_0, \cdot) = (\id - P) \d H(y_0, \cdot) = (\id - P) \d (F \circ \phi)(y_0, \cdot) = (I - P)D \d \phi(y_0, \cdot)$.
    Получается 0, так как $(I - P)D = 0$ --- $D$ проектирует на $L$, после чего $I - P$ отображает в нуль.

    Таким образом, $L$ --- \emph{касательное подпространство} (иногда говорят \emph{касательная плоскость})  к $F(G)$ в точке $y_0$.
    Любопытно заметить, что чтобы найти обратную к $H$ функцию, надо спроектировать $H(u)$ на касательную плоскость.

    \ok
    Рассмотрим уравнение $x^2 + y^2 + z^2 = 1$.
    Оно задаёт сферу в $\R^3$, которая является многообразием: $\forall (x_0, y_0, z_0) \in S$.
    Если $x$ близок к $x_0 > 0$, то $x = \sqrt{1 - y^2 - z^2}$ и получаем локальную карту.
    Аналогично для $x_0 < 0$.
    Если же $x_0$ неотделим от нуля, то надо выражать другую координату.

    Обобщим.

    Пусть задано отображение $f: (U \subset \R^{n + m}) \map \R^n$, непрерывно дифференцируемое всюду в $U$.
    В продолжении теоремы векторы $z \in \R^{n + m}$ будем раскладывать на две компоненты $(x, y) \in X \oplus Y$, где $\dim X = n, \dim Y = m$ (необязательно $X \perp Y$).

    Пусть $c \in \R^n$.
    Для примера со сферой выше $m + n = 3, n = 1$.

    Рассмотрим множество точек $\defset{(a, b) \in \R^n \oplus \R^m}{f(a, b) = c}$ --- найдём подпространства уровня $f$.
    Пусть оно непусто: $\exists a_0, b_0: f(a_0, b_0) = c$.

    Найдём функцию $h: \left(\U[\delta]{b_0} \subset \R^m\right) \map \R^n$, такую, что $\forall y \in \U[\delta]{b_0}: f(h(y), y) = c$.

    Обозначим $D = \d f((a_0, b_0), \cdot)$.
    Обозначим $D\Big|_X = A, D\Big|_X = B$.
    Предположим, что $D\Big|_X$ невырожден.
    \theorem[О неявной функции]{
        При сделанных предположениях $\exists \U[\delta]{b_0} \subset \R^m: \exists ! h: \U[\delta]{b_0} \map \R^n: f(h(y), y) = c$.

        Более того, полученная функция $h$ непрерывно дифференцируема.
        \provehere{Введём $F: U \map \R^n \oplus \R^m; \quad F(x, y) = (f(x, y), y)$. Найдём дифференциал:
        \gather{F(x, y) - F(a_0, b_0) = (f(x, y) - f(a_0, b_0), y - b_0) = \\ = (D(x, y) + \underbrace{\phi(x, y)}_{o(|b_0 - y|)}, y - b_0) = (a_0(x - a_0) + b_0(y - b_0), y - b_0) + o(|b_0 - y|)}
        Таким образом $\forall (u, v) \in \R^{n + m}: \d F((a_0, b_0), (u, v)) =  L(u, v) = (Au + Bv, v)$.

        Если $L(u, v) = 0$, то $v = 0$, откуда $Bv = 0$, откуда $Au = 0 \then u = 0$, так как $A$ невырожден.
        Таким образом, $L$ невырожден, к $F$ применима теорема об обратном отображении.
            \[F(a_0, b_0) = (f(a_0, b_0), b_0) = (c_0, b_0)\]
            Рассмотрим $W$ --- окрестность $(a_0, b_0)$, такую, что $\exists G = F^{-1}$, заданная на $W$, причём $G$ непрерывно дифференцируема в этой окрестности.

            Так как $G(u, v) = (*, v)$, то $\exists \psi: W \map \R^n$, $\psi$ непрерывно дифференцируема на $W$.
            Таким образом $\forall (u, v) \in W: F(\psi(u, v), v) = (u, v)$.

            Определим $h(v) \coloneqq \psi(c, v)$. В самом деле, видим, что $h$ определена на некоторой окрестности $b_0$, причём $h(y) = c$.
        }
    }
    \newlection{21 марта 2023 г.}
    Продолжим теорему, доказанную на предыдущей лекции: найдём дифференциалы.

    Мы показали, что существует формула для отображения $\phi$ в точке $b$. $D = \d \phi(b, \cdot)$.
    Так как $f(\phi(y), y) \equiv c$ при $y$, близких к $b$, то
    \[0 = \d (f(\phi(y), y)) = AD + B\]
    Так как $A$ обратима, то $D = -A^{-1}B$.

    \example{
        $\R^2 = \R \oplus \R$.
        На плоскости задана кривая соотношением $f(x, y) = c$, где $f: \R^2 \map \R$.

        Если $f(a, b) = c$, то (при условии $\der{f}{x}(a, b) \ne 0$) $\exists \phi(y): f(\phi(y), y) \equiv 0$ при $|y - b| < \delta$.

        Производная этой функции $\phi'(b) = -\dfrac{\der{f}{y}(a, b)}{\der{f}{x}(a, b)}$.
    }
    Пусть $U \subset \R^k; f: U \map \R^n; (a, b) \in U$, где $k > n$.
    Предположим, что $\forall u \in U$ ранг матрицы Якоби равен $n$, то есть максимально возможный.
    \[\rk \vect{\der{f_1}{x_1}(u) & \dots & \der{f_1}{x_k}(u) \\ \vdots & \ddots & \vdots \\ \der{f_n}{x_1}(u) & \dots & \der{f_n}{x_k}(u)} = n\]
    Рассмотрим множество решений относительно $u$ уравнения $f(u) = c$.
    Решения называются \emph{множествами уровня} отображения $f$. $L_c = \defset{u}{f(u) = c}$.

    Пусть $f(u_0) = c$.

    Выберем минор матрицы порядка $n$ с ненулевым определителем.
    Переупорядочим столбцы так, чтобы первые $n$ были линейно независимы.

    Обозначим за $X$ пространство, натянутое на первые $n$ координат, за $Y$ --- последние $k - n$ координат.

    $\R^k = X \oplus Y$, окрестность точки $u_0$ описывается локальной картой вида $H(y) \coloneqq (\phi(y), y), y \in Y$, причём $y$ близко к проекции $u_0$ на $Y$.

    $V$ --- окрестность точки $u_0$ на $L_c$, которая накрывается локальной картой $H$. $H^{-1}(z) = Qz$, где $Q$ --- ортогональный проектор на $Y$.

    Покажем гладкость отображения переходами между картами. $H_1(y) = (\phi_1(y), y), H_2(y) = (\phi_2(y), y)$.

    Посмотрим на $H_2^{-1}H_1$, где задано.
    Это $QH_1$, что несомненно является гладким отображением, как композиция.

    Таким образом, $L_c$ --- $(k - n)$ мерное гладкое многообразие.
    \ok
    Займёмся описанием касательной плоскости --- $\Image \d \phi(u_0, \cdot)$ не очень удобно, так как $\phi$ вполне может не быть задана явно.

    \theorem{
        При сделанных предположениях об $f$ (матрица Якоби --- максимального ранга), если $L_c \ne \o$, то
        \[\forall u_0: f(u_0) = c \then \Ker(\d f(u_0, \cdot)) \text{ --- касательное подпространство к $L_c$ в точке $u_0$}\]
        \provehere{
            Пусть $N$ --- касательное подпространство к $L_c$ в точке $u_0$. $\dim N = k - n = m$.

            Обозначим оператор $D \coloneqq \d f(u_0, \cdot)$. $D: \R^k \map \R^n$ --- сюръекция. Тогда $\dim \Ker D = m$.

            Покажем, что $N \subset \Ker D$. Так как их размерности совпадают, то мы докажем совпадение.

            Пусть $x \in N$, то есть $\alpha(t) \coloneqq \dist(u_0 + tx, L_c) = o(|t|)$.
            Для всякого достаточно маленького $t > 0: \exists x_t \in L_c: \dist(u_0 + tx, x_t) \le 2 \alpha(t)$.

            Запишем \[0 = f(x_t) - f(u_0) = D(x_t - u_0) + \phi(x_t)\text{, где $\phi(y) = o(|y - u_0|)$}\]
            Так как $|x_t - u_0| \le |tx + x_t - u_0| + |tx| \le C |t|$ при $t$, близких к 0. Тем самым, $\phi(y_t) = o(|t|)$.

            \[0 = D(x_t + tx - u_0) - D(tx) + \phi(x_t)\]
            Так как $D(x_t + xt - u_0) \le \|D\| \cdot |x_t + tx - u_0| \le 2\|D\|\alpha(t) = o(|t|)$, то поделив на $t$ последнее равенство, получаем
            \[0 = \frac{D(x_t + tx - u_0)}{t} - Dx + \frac{\phi(x_t)}{t} \underset{t \to 0}\Map -Dx\]
            Отсюда действительно получается $D x = 0$.
        }
    }

    \theorem[О множителях Лагранжа]{
        Пусть $f_1, \dots, f_n: (U \subset \R^k) \map \R$, где по-прежнему $k \ge n$.
        Пусть все $f_j$ непрерывно дифференцируемы.

        Рассмотрим $L$ --- множество тех $x \in U: f_1(x) = c_1, f_2(x) = c_2, \dots, f_n(x) = c_n$.

        Пусть $x_0 \in L$, а ещё произвольная функция $f: U \map \R$ --- тоже непрерывно дифференцируема.
        Пусть векторы $\grad_{f_i}(x_0)$ линейно независимы, а $f\Big|_L$ имеет локальный экстремум в точке $x_0$..

        При сделанных предположениях $\exists \{\lambda_i\}_{i = 1}^{n}$ --- множители Лагранжа, такие, что $\grad_f(x_0) = \sum\limits_{i = 1}^{n}\lambda_i \grad_{f_i}(x_0)$
        \provehere{
            Положим $F = \vect{f_1\\ \vdots\\ f_n}$. Матрица Якоби $F$ получается $J \coloneqq \vect{\grad_{f_1}(x) \\ \vdots \\ \grad_{f_n}(x)}$.
            Линейная независимость строчек при $x = x_0$ означает, что матрица имеет ранг $n$.

            Для $c = \vect{c_1\\ \vdots\\ c_n}$ получается $L = \defset{x}{F(x) = c}$.

            Для $N$ --- касательного подпространства к $L$ в точке $x_0$ выполнено условие $\grad_{x_0}f \perp N$, $\grad_{x_0}f \in N^\perp$.

            Заметим, что $Ju = 0 \iff \forall j: \langle u, \grad_{f_j}(x_0) \rangle = 0 \iff u \in \Lin \{\grad_{f_j}(x_0)\}^\perp$.

            Так как $\grad_f(x_0) \perp N = \Ker J$, то $\grad_f(x_0) \in \Lin \{\grad_{f_j}(x_0)\}$.
        }
    }
    \ok
    Пусть $\langle a, b\rangle \subset \R$ --- промежуток общего вида, $g: \langle a, b\rangle \map \R^n$ --- векторнозначная функция.

    Если $g$ дифференцируема в точке $x_0$, $g = \vect{g_1& \dots & g_n}^t$, то $\d g(x_0, h) = \vect{g_1'(x_0) & \dots & g_n'(x_0)}^t \cdot h$.

    Функцию $g$ можно рассматривать, как описание движения материальной точки, например.

    Вектор $g'(x_0) = \vect{g_1'(x_0), \dots, g_n'(x_0)}$ называют \emph{производной} функции $g$.
    Заметим, что определение $g'(x_0) = \lim\limits_{h \to 0}\frac{g(x_0 + h) - g(x_0)}{h}$ по-прежнему выполняется.

    Также выполняется неравенство Лагранжа: $\forall t_1, t_2: \exists c$ между $t_1, t_2: |g(t_1) - g(t_2)| \le |g'(c)| \cdot |t_1 - t_2|$.

    \definition[Определённый интеграл векторнозначной функции]{
        Для $\alpha, \beta \in (a, b)$: \[\int\limits_{\alpha}^{\beta}g(x)\d t \bydef \vect{\int\limits_{\alpha}^{\beta}g_1(x)\d t & \dots & \int\limits_{\alpha}^{\beta}g_n(x)\d t}\]
    }
    \fact[Основная оценка интеграла]{
        \[\abs{\int\limits_{\alpha}^{\beta}g(t) \d t} \le \int\limits_{\alpha}^{\beta}|g(t)| \d t\quad\text{или}\quad\left(\sum\limits_{j = 1}^{n}\left(\int\limits_{\alpha}^{\beta}g_j(t) \d t\right)^2\right)^{\nicefrac{1}{2}} \le \int\limits_{\alpha}^{\beta}\left(\sum\limits_{j = 1}^{n}\left(g_j(t)\right)^2\right)^{\nicefrac{1}{2}}\d t\]
        \provehere{
            Докажем в предположении, что все $g_j$ кусочно-непрерывны на $[\alpha, \beta]$.
            В общем случае надо обосновывать, почему $|g|$ интегрируема по Риману, это останется в качестве упражнения.

            Пусть $y = \int\limits_{\alpha}^{\beta}g(t) \d t \in \R^n$. Рассмотрим $e \in \R^n$, такой, что $|e| = 1, |y| = \langle y, e \rangle = |y|$.

            Введём $\phi: \R \map \R; \phi(t) = \langle g(t), e \rangle = \sum\limits_{j = 1}^{n}g_j(t) \xi_j$, где $e = \vect{\xi_1 & \dots & \xi_n}$.
            Запишем \[\abs{\angles{\intab g(t) \d t, e}} = \abs{\intab{\phi(t) \d t}} \le \intab\abs{\phi(t)}\d t \le \intab |g(t)|\d t\]
        }
    }


    \section{Длина пути}
    Пусть задана кривая.
    Как найти её длину?
    Приблизим её ломаной, длина ломаной --- сумма длин отрезков.
    Если приближения разными ломаными имеют тенденцию куда-то стремиться, то это число называют длиной ломаной.

    Кривую, вообще говоря, можно определить как множество точек, а можно --- как отображение.

    Пусть $\gamma: [a, b] \map \R^n$ --- непрерывное отображение.
    Рассмотрим $T \coloneqq \{t_i\}_{i = 0}^{k} \subset \R: {a \le t_1 < \dots < t_k \le b}$.

    Определим приближение длины ломаной $S(\gamma, T) = |\gamma(t_1) - \gamma(t_0)| + \dots + |\gamma(t_{k - 1}) - \gamma(t_k)|$.

    \definition[Спрямляемая кривая $\gamma$]{
        Числа $S(\gamma, T)$ ограничены сверху.
        В таком случае супремум этих чисел называют длиной пути $\gamma$.
    }
    Для $[c, d] \subset [a, b]$ у спрямляемого пути определена \emph{длина сужения} $l(\gamma, [c, d])$ --- длина пути $\gamma\Big|_{[c, d]}$.
    \ok
    Пусть $f: [a, b] \map \R^n$ --- произвольное отображение.
    Здесь определим такую же, как для пути, функцию $S(f, T) = |f(t_1) - f(t_0)| + \dots + |f(t_{k - 1}) - f(t_k)|$.

    \definition[$f$ имеет ограниченную вариацию]{
        Все суммы $S(f, T)$ ограничены сверху.
        В таком случае их супремум называют \emph{вариацией} $V(f, [a, b])$.
    }
    \numbers{
        \item Пусть $T_1, T_2$ --- два набора точек на $[a, b]$. Если $T_1 \subset T_2$, то $S(f, T_1) \le S(f, T_2)$.
        Достаточно понять, что эту выполняется, если $T_2 = T_1 \cup \{pt\}$. В самом деле, $|f(t_j) - f(t_{j + 1})|$ заменяется на $|f(t_j) - f(pt)| + |f(pt) - f(t_{j + 1})|$, что не меньше.
        \item Можно ослабить условия на точки, считая, что $t_j \le t_{j + 1}$.
        \item Если $f, g$ --- функции ограниченной вариации, $c,d \in \R$, то $cf + dg$ --- тоже функция ограниченной вариации.

        Конкретнее, $V(cf + dg, [a, b]) \le |c|V(f, [a, b]) + |d|V(g, [a, b])$.
        \[\sum\limits_{j = 1}^{k}|(cf + dg)(t_j) - (cf + dg)(t_{j - 1})| \le |c|\sum\limits_{j = 1}^{k}|(f(t_j) - f(t_{j - 1})| + |d|\sum\limits_{j = 1}^{k}|(f(t_j) - f(t_{j - 1})|\]
        \item Если $f$ --- функция ограниченной вариации на $[\alpha, \beta]$ и на $[\beta, \gamma]$, то $f$ --- функция ограниченной вариации на $[\alpha, \gamma]$.
        \[V(f, [\alpha, \gamma]) = V(f, [\alpha, \beta]) + V(f, [\beta, \gamma])\]
        Пусть $T$ --- набор точек в $[\alpha, \gamma]$, причём $T_1 = T \cap [\alpha, \beta]$, а $T_2 = T \cap [\beta, \gamma]$.
        Считаем, что $\beta \in T$.
        Тогда $S(f, T) = S(f, T_1) + S(f, T_2)$.
        Переходя к супремуму по $T$, получаем $V(f, [\alpha, \gamma]) \le V(f, [\alpha, \beta]) + V(f, [\beta, \gamma])$.

        Обратное неравенство получается примерно так же.
    }
    \note{
        $f$ ограниченной вариации $\then f$ ограничена.
    }
    \note{
        $f$ постоянна $\iff V(f, [a, b]) = 0$.
    }
    \theorem{\down
    \numbers{
        \item Пусть $f: [a, b] \map \R^n$.
        Рассмотрим координатные функции $f = \vect{f_1 & \dots & f_n}$. Следующие условия эквивалентны:
        \bullets{
            \item $f$ --- ограниченной вариации.
            \item Все $f_j$ --- ограниченной вариации.
        }
        \item Пусть $f: [a, b] \map \R$. Следующие условия эквивалентны:
        \bullets{
            \item $f$ --- ограниченной вариации.
            \item $f = \phi_1 - \phi_2$, где $\phi_1, \phi_2$ --- возрастают на отрезке $[a, b]$.
        }
    }
    \provehere{\down
    \numbers{
        \item \bullets{
            \item[$\then$.] Пусть $t, s \in [a, b]$. $|f_j(t) - f_j(s)| \le |f(t) - f(s)|$.
            Таким образом, для всякого конечного набора $T \subset [a, b]: S(f_j, T) \le S(f, T) \le V(f, [a, b])$.
            \item[$\when$.] $f(t) = \sum\limits_{j = 1}^{n}f_j(t)e_j$. Таким образом, $f$ --- сумма функций ограниченной вариации.
        }
        \item \bullets{
            \item[$\when$.] Возрастающая функция есть функция ограниченной вариации:
            \[S(\phi, T) = \sum\limits_{j = 1}^{k}|\phi(t_j) - \phi(t_{j - 1})| = \sum\limits_{j = 1}^{k}(\phi(t_j) - \phi(t_{j - 1})) = \phi(t_k) - \phi(t_0)\then V(\phi, [a, b]) = \phi(b) - \phi(a)\]
            Значит, $f$ --- конечной вариации, как сумма двух функций конечной вариации.
            \item[$\then$.] Обозначим $u: [a, b] \map \R; u(t) = V(f, [a, t])$.
            Докажем, что $v(t) \coloneqq u(t) - f(t)$ возрастает.

            Рассмотрим $s < t \in [a, b]$. Заметим. что $f(t) - f(s) \le |f(t) - f(s)| \le V(f, [s, t]) = u(t) - u(s)$.
            Отсюда $u(t) - f(t) \ge u(s) - f(s)$, действительно, $v(t)$ возрастает.

            Осталось заметить, что $v$ тоже возрастает, $f = u - v$.
        }
    }
    }
    \note{
        Если $f$ --- непрерывная скалярная функция, то получившиеся в доказательство $\phi_1, \phi_2$ тоже непрерывны.
    }
    }
    \newlection{24 марта 2023 г.}
    \theorem{
        Пусть $f: [a, b] \map \R^n$ --- векторнозначная функция, имеющая ограниченную вариацию.

        Введём функцию $V: [a, b] \map \R, V(t) = V(f, [a, t])$.
        Утверждается, что $\forall x_0 \in [a, b]$: $f$ непрерывна в $x_0 \then V$ непрерывна в $x_0$.
        \provehere{
            Докажем, что $V$ непрерывна слева в точке $t_0$, где $t_0 > a$. $V$ возрастающая функция.
            Выберем $\eps > 0$, найдём точку $s < t$, такую, что $V(s) > V(t) - \eps$.

            Так как $V(t)$ --- супремум сумм, участвующих в определении вариации $V(f, [a, t])$, то найдётся последовательность точек $s_0 < \dots < s_k, s_j \in [a, t_0]$, такая, что $\sum\limits_{j = 1}^{k}|f(s_{j - 1}) - f(s_j)| > V(t) - \nicefrac{\eps}{2}$.

            Из непрерывности: $\exists \delta: \forall u \in (t_0 - \delta; t_0): |f(u) - f(t_0)| < \nicefrac{\eps}{2}$.
            Добавим точек так, чтобы выполнялись условия $s_k = t_0, s_{k - 1} \in (t_0 - \delta, t_0)$. $\sum\limits_{j = 1}^{k}|f(s_{j - 1}) - f(s_j)| > V(t) - \nicefrac{\eps}{2}$. по-прежнему выполнено.

            Теперь заметим, что $V(f, [a, s_{k - 1}]) \ge \sum\limits_{j = 1}^{k - 1}|f(s_{j - 1}) - f(s_j)|$.
            Комбинируя неравенства, получаем $V(f, [a, s_{k-1}]) \ge V(f, [a, t_0]) - \eps$. Точка $s_{k-1}$ подходит в качестве $s$.
        }
    }
    \note{
        Если $f$ --- непрерывная скалярная функция, то во всех точках непрерывности $f$ функции $\phi_1$ и $\phi_2$ тоже непрерывны.
    }
    Вспомним, что \emph{носитель пути} $\gamma: [a, b] \map \R^n$ --- его образ ($\Image \gamma$). \emph{Начало пути} --- точка $\gamma(a)$, \emph{конец пути} --- точка $\gamma(b)$.

    Предположим, что $\gamma: [a, b] \map \R^n$ --- путь, $\phi: [c, d] \map [a, b]$ --- гомеоморфизм подотрезков $\R$.
    Иными словами, непрерывная, строго монотонная функция.

    Утверждается, что $f \circ \phi$ имеет ограниченную вариацию $\iff f$ имеет ограниченную вариацию.
    Более того, в этом случае вариации совпадают.
    \provehere{
        Всякой сумме $\sum\limits_{j = 1}^{k}|(f \circ \phi)(s_{j - 1}) - (f \circ \phi)(s_j)|$ соответствует сумма $\sum\limits_{j = 1}^{k}|(f)(\phi(s_{j - 1})) - (f(\phi(s_j))|$.
        Их супремумы равны, а если точки $s_0, \dots, s_k$ образуют монотонную последовательность отрезка $[a, b]$ (либо $a \le s_0 < \dots < s_k \le b$, либо $a \le s_k < \dots < s_0 \le b$).
        Их образ --- точки $\phi(s_0), \dots, \phi(s_k)$ --- тоже образуют монотонную последовательность отрезка, причём $\phi$ обратимо, все разбиения отрезка достигаются.
    }

    \definition[Простая дуга]{
        Такой путь $\gamma: [a, b] \map \R^n$, что $\gamma$ --- инъекция.
    }
    Тогда $\gamma$ --- гомеоморфизм между отрезком $[a, b]$ и своим носителем $\gamma([a, b])$.
    Это следует из того, что компактность прообраза влечёт компактность образа, а замкнутость образа влечёт замкнутость прообраза (плюс и $[a, b]$, и $\gamma([a, b])$ ограничены).

    Пусть $\gamma_1: [a, b] \map L, \gamma_2: [c, d] \map L$ --- простые дуги, причём $\gamma_1([a, b]) = \gamma_2([c, d]) = L$.

    Тогда оказывается, что длины путей $\gamma_1$ и $\gamma_2$ равны: для $\phi: \gamma_1^{-1} \circ \gamma_2$ --- гомеоморфизма --- $\gamma_2 = \gamma_1 \circ \phi$.

    Таким образом, о длине носителя простой дуги можно говорить вне зависимости от пути, параметризующего его.

    \ok
    Рассмотрим простую дугу --- верхнюю полуокружность $x^2 + y^2 = 1$, где $y \ge 0$.
    Это простая дуга, так как можно параметризовать в виде $\gamma: [-1, 1] \map \R^2; \quad \gamma: x \mapsto \left(x, \sqrt{1 - x^2}\right)$.

    \definition[Число $\pi$]{
        Длина данной дуги полуокружности.
    }

    Пусть $A: \R^n \map \R^n$ --- изометрическое отображение.
    Тогда $V(A \circ f, [a, b]) = V(f, [a, b])$ --- это видно из взаимнооднозначного соответствия между суммами при подсчёте вариации.

    Отсюда следует, что длина нижней полуокружности $x^2 + y^2 = 1, y \le 0$ --- тоже $\pi$.

    \subsection{Длина гладкого пути}
    Пусть $\gamma: [a, b] \map \R^n$ --- путь, причём $\gamma \in C^{(1)}$.
    А именно: запишем его через координатные функции, $\gamma(t) = \vect{\gamma_1(t)\\ \vdots \\\gamma_n(t)}$, все производные $\gamma_j'(t)$ существуют и непрерывны при $t \in [a, b]$.
    Такой путь называется \emph{гладким}.
    \theorem{
        Всякий гладкий путь спрямляем, причём его длина равна \[l(\gamma, [a, b]) = \int\limits_{a}^{b}|\gamma'(t)|\d t = \int\limits_{a}^{b}\sqrt{\sum\limits_{j = 1}^{n}(\gamma_j'(t))^2}\d t\]
        \provehere{
            Пусть $a = t_0 \le t_1 \le \dots \le t_k = b$.
            Запишем сумму, получающуюся при вычислении вариации: $\sum\limits_{i =1}^{k}|\gamma(t_i) - \gamma(t_{i-1})|$.

            Пусть $I_1, \dots, I_k$ --- попарно непересекающиеся (за исключением, быть может, концов) замкнутые отрезки, $I_i = [t_{i-1}, t_i]$.
            Видим, что всякому разбиению из точек $\{t_i\}_{i = 0}^{k}$ соответствует разбиение из отрезков $\{I_i\}_{i = 1}^{k}$.

            Согласно неравенству Лагранжа: $|\gamma(t_{i-1}) - \gamma(t_i)| \le |\gamma'(\xi)|\cdot|t_i - t_{i + 1}|$, где $\xi \in [t_i, t_{i + 1}]$.

            Продолжим неравенство: \[|\gamma(t_{i-1}) - \gamma(t_i)| \le |\gamma'(\xi)|\cdot|t_{i-1} - t_{i}| \le \sup\limits_{u \in [t_i, t_{i + 1}]} |\gamma'(u)| \cdot |t_{i-1} - t_i|\]
            В правой части неравенства получилось слагаемое из верхней суммы Дарбу для $\gamma'$.

            Положим $\eps > 0$, выберем такое разбиение $\{t_i\}_{i = 0}^{k}$, что $\sum\limits_{i = 1}^{k}|\gamma(t_i) - \gamma(t_{i-1})| \ge l(\gamma, [a, b]) - \eps$.

            Измельчим соответствующее разбиение $\{I_i\}_{i = 1}^{k}$, превратив его в разбиение $\{J_j\}_{j = 1}^{s}$, такое, что $\sum\limits_{J_j}\sup\limits_{t \in J_j}|\gamma'(t)| \cdot |J_j| \le \int\limits_{a}^{b}\gamma'(t)\d t + \eps$.

            Теперь в качестве точек $\{t_i\}_{i = 1}^{k}$ рассмотрим концы отрезков $\{J_j\}_{j = 1}^{s}$.   $\sum\limits_{j = 1}^{s}|\gamma(t_j) - \gamma(t_{j-1})| \ge l(\gamma, [a, b]) - \eps$ по-прежнему верно.

            Таким образом, мы доказали, что $l(\gamma, [a, b]) \le \int\limits_{a}^{b}|\gamma'(t)| \d t$ --- с точностью до $\eps$, где $\eps$ можно выбрать сколь угодно малым.
            \ok
            Рассмотрим произвольные $x < y \in [a, b]$. Для них верны неравенства \[|\gamma(y) - \gamma(x)| \le l(\gamma, [x, y]) \le \int\limits_{x}^{y}|\gamma'(t)|\d t\]
            Поделив это на $y - x$, получим
            \[\abs{\frac{\gamma(y) - \gamma(x)}{y - x}} \le \frac{l(\gamma, [a, y]) - l(\gamma, [a, x])}{y - x} \le \frac{1}{y - x}\int\limits_{x}^{y}\gamma'(t)\d t\]
            Обозначим $L(u) \coloneqq l(\gamma, [a, u])$.
            Устремим $y \map x_+$, получим $|\gamma'(x)| \le \underset{\text{справа}}{L'(x)} \le |\gamma'(x)|$, то есть по принципу о двух полицейских наступает равенство. Аналогичным образом получается $\underset{\text{слева}}{L'(u)}$.

            Тогда очевидно $L(u) = \int\limits_{a}^{u}|\gamma'(t)|\d t + C$ для некой константы $C$. Так как $L(a) = 0$, то $C = 0$.
        }
    }
    <<Если всё хорошо>>, то для скалярной функции $g: [a, b] \map \R$ должно выполняться $V(g, [a, b]) = \int\limits_{a}^{b}|g'(t)|\d t$.
    \example[Когда не совсем всё хорошо]{
        Вариация возрастающей функции $g(t) = \sqrt{t}$ равна $g(1) - g(0) = 1$.
        При подсчёте по формуле, получаем $V(g, [0, 1]) = \int\limits_{0}^{1}\frac{\d t}{\sqrt{t}}$.
        Интеграл этот не существует, производная в нуле не определена.

        Если посчитать $V(g, [\eps, 1]) = \int\limits_{\eps}^{1}\frac{\d t}{\sqrt{t}}$, то получится $2 - 2\sqrt{\eps}$.
        Здесь возникает понятие о несобственном интеграле --- при стремлении $\eps \to 0$.
    }
    \newlection{31 марта 2023 г.}


    \section{Естественная параметризация}
    Пусть $\gamma: [a, b] \map \R^n$ --- спрямляемый путь.

    Выберем $t_0 \in [a, b]$, обозначим $\phi(t) = \all{l(\gamma, [t_0, t]), & t \ge t_0 \\ -l(\gamma, [t, t_0]),& t < t_0}$.
    Функция $\phi$ возрастает и непрерывна.
    Обозначим $\phi([a, b]) = [\alpha, \beta]$.

    \definition[Движение без задержек]{
        Такой путь $\gamma: [a, b] \map \R$, что $\forall [c, d] \subset [a, b]: c < d \then l(\gamma, [c, d]) > 0$.
    }
    При движении без задержек $\phi$ строго возрастает, значит, есть биекция $\psi = \phi^{-1}: [\alpha, \beta] \map [a, b]$.

    Введём $\tilde{\gamma}: [\alpha, \beta] \map \R^n; \tilde{\gamma} = \gamma \circ \psi$.

    Рассмотрим $[\delta, \rho] \subset [\alpha, \beta]$.
    Положим $c = \psi(\delta), d = \psi(\rho)$.

    Заметим, что $\rho - \gamma = \phi(d) - \phi(c) = l(\gamma, [c, d]) = l(\tilde{\gamma}, [\delta, \rho])$.

    При такой параметризации для любого отрезка $I: l(\tilde{\gamma}, I) = |I|$.
    Отображение $\psi$ называется \emph{естественной параметризацией пути} $\gamma$;\ $\tilde{\gamma}$ --- тот же путь, \emph{параметризованный естественным образом}.
    \ok
    Пусть теперь $\gamma$ --- гладкий путь, то есть $\gamma \in C^{(1)}$.
    Тогда для $\phi$ имеется формула:
    \[\phi(t) = \int\limits_{t_0}^{t}|\gamma'(t)|\d t\]
    Было бы удобно, чтобы путь $\gamma$ был движением без задержек.
    Предположим ещё больше: $\gamma'(s) \ne 0$ для любого $s \in [a, b]$.
    Это называется \emph{безостановочным движением}.

    Отсюда видим $\phi'(t) = |\gamma'(t)|$ по теореме Ньютона-Лейбница, откуда $\psi'(\tau) = \frac{1}{\phi'(\psi(\tau))}$ и наконец \[\tilde{\gamma}'(\tau) = \gamma'(\psi(\tau)) \cdot \psi'(\tau) = \frac{\gamma'(\psi(\tau))}{\phi'(\psi(\tau))} = \frac{\gamma'(\psi(\tau))}{|\gamma'(\psi(\tau))|}\]
    Таким образом, $|\tilde{\gamma}'(\tau)| = 1$, что и стоило ожидать при условии $\forall I: l(\tilde{\gamma}, I) = |I|$.

    \note{
        Пусть $\gamma: [a, b] \map \R^n$ --- спрямляемый путь, предположим, что $\gamma'$ существует и непрерывна на интервале $(a, b)$.
        Тогда тоже есть функция $\phi(t) = \int\limits_{t_0}^{t}|\gamma'(t)|\d t$, определённая при $t, t_0 \in (a, b)$.

        Более того, у функции $\phi$ есть пределы при $t \to a$ или $t \to b$.
        \[l(\gamma, [a, b]) = \lim\limits_{\eps \to 0, \delta \to 0}l(\gamma, [a + \eps, b - \delta]) = \lim\limits_{\eps \to 0, \delta \to 0}\int\limits_{a + \eps}^{b - \delta}\]
    }
    \example{
        Рассмотрим путь $\kappa(t) = \left[t, \sqrt{t}\right]$. Для него $\kappa'(t) = \left(1, \frac{1}{2\sqrt{t}}\right); |\kappa'(t)| = \sqrt{1 + \frac{1}{4t}}$.

        Тогда \[l(\kappa, [0, 1]) = \lim\limits_{\eps \to 0}l(\kappa, [\eps, 1]) = \lim\limits_{\eps \to 0}\int\limits_{\eps}^{1}\sqrt{1 + \frac{1}{4t}}\d t\]

        Об интеграле $\int\limits_{0}^{1}\sqrt{1 + \frac{1}{4t}}\d t$ говорят, что он существует в \emph{несобственном смысле};
        в данном случае он очевидно существует, так как обе координаты пути монотонны, то есть путь --- ограниченной вариации.
    }


    \section{Про комплексные числа}
    Рассмотрим комплексную плоскость $\C \cong \R^2; x + i y \leftrightarrow (x, y)$.
    Я буду обозначать вещественную часть $\Re(x + iy) = x$ и мнимую часть $\Im(x + iy) = y$.

    Всякую функцию $g: (\langle a, b\rangle\subset \R) \map \C$ можно рассматривать, как векторнозначную функцию со значением в $\R^2$;
    в частности, их можно дифференцировать.

    Пусть $g(x) = \vect{g_1(x) & g_2(x)} = g_1(x) + i g_2(x)$.
    Тогда $g'(x) = \vect{g_1'(x) & g_2'(x)} = g_1'(x) + i g_2'(x)$.

    Комплекснозначные функции наследуют все свойства векторнозначных функций, но вдобавок тут появляются некоторые дополнительные операции.
    Так, комплексные числа можно перемножать.

    Пусть $g_1, g_2: \langle a, b \rangle \map \C$ --- обе дифференцируемы.
    Сохраняется формула
    \[(g_1 \cdot g_2)'(t) = g_1(t)g_2'(t) + g_1'(t)g_2(t)\]
    Это можно видеть, либо проверив вручную, что при перемножении комплексные производные перемножаются соответствующим образом, либо просто повторив доказательство производной произведения:
    \[\frac{g_1(t)g(2(t) - g_1(s)g_2(s)}{t - s} = \frac{(g_1(t) - g_1(s))g_2(t) + g_1(s)(g_2(t) - g_2(s))}{t - s} \underset{s \to t}\Map \lim\limits_{s \to t}\left[\frac{g_1(t) - g_1(s)}{t - s} + g_2(s)\frac{g_1(t) - g_1(s)}{t - s}\right]\]
    То, что комплексное произведение непрерывно, следует из покоординатной непрерывности, получаем искомое равенство.

    Определим для $z = a + bi$ его длину как вектор в $\R^2$ --- \emph{модуль} $|z| = \sqrt{a^2 + b^2}$.
    Определим для $z = a + bi$ его \emph{комплексно-сопряжённое} $\overline{z} = a - bi$.
    Можно заметить, что $z\overline{z} = |z|^2$.
    Также можно заметить, что для $z \ne 0: z^{-1} = \frac{\overline{z}}{|z|^2}$.

    Теперь изучим производные комплекснозначных функций. $g: \langle a, b \rangle \map \C$.
    $(\overline{g})'(t) = \overline{g'(t)}$.

    Для $g(t) \ne 0: (g'^{-1})(t) = -\frac{g'(t)}{g(t)^2}$.
    Для доказательства опять же повторим вещественное доказательство:
    \[\frac{1}{t - s}\left(\frac{1}{g(t)} - \frac{1}{g(s)}\right) = \frac{1}{t - s} \cdot \frac{g(s) - g(t)}{g(s)g(t)}\]

    Введём на комплексной плоскости единичную окружность $\T \bydef \defset{z \in \C}{|z| = 1}$ и единичный круг $\D \bydef \defset{z \in \C}{|z| < 1}$.
    Замкнутый комплексный круг обозначают $\overline{\D} \bydef \defset{z \in \C}{|z| \le 1}$, что не следует путать с комплексным сопряжением.

    \fact{
        $\T$ --- подгруппа в $\C^*$ по умножению.
        \provehere{
            $|z_1 z_2| = |z_1| \cdot |z_2|$, что следует из прямой проверки.
            $z^{-1} = \frac{\overline{z}}{|z|^2} = \overline{z}$ для $z \in \T$.
        }
    }
    \note{
        Заметим, что для $z = a + bi, w = c + di$ верно:
        \[z\overline{w} = (a + bi)(c - di) = ac + bd + i(bc - ad)\]
        Таким образом, для точек-векторов комплексной плоскости $z, w$ их скалярное произведение равно $\Re(z\overline{w})$.
        В частности, $z \perp w \iff z \overline{w}$ чисто мнимое число.
    }

    \subsection{Простое вращение}
    \definition[Простое вращение]{
        Отображение $\gamma: \R \map \T$ со следующими свойствами:
        \numbers{
            \item $\gamma$ всюду дифференцируема (и всюду непрерывна).
            \item $\forall t \in \R: |\gamma'(t)| = 1$.
            \item $\gamma(0) = 1, \gamma'(0) = i$.
        }
    }
    \theorem{
        Простое вращение существует и единственно.
    }
    \note{
        Пусть $\phi: \langle a, b \rangle \map \T$ --- гладкое отображение (класса $C^{(1)}$).
        Продифференцируем равенство $\phi(t) \cdot \overline{\phi(t)} = 1$:
        \[\phi(t)\overline{\phi'(t)} + \phi'(t)\overline{\phi(t)} = 0\]
        Получили сумму двух комплексносопряжённых чисел, равную 0. Значит, $2\Re(\phi'(t)\overline{\phi(t)}) = 0$, то есть $\overline{\phi(t)} \perp \phi'(t)$.

        Таким образом, $\exists w: \langle a, b \rangle \map \R$, такая, что $\phi'(t)\overline{\phi(t)} = w(t)i$.

        Пусть $\forall t: \phi'(t) \ne 0$.
        Тогда $w$ --- непрерывная не обнуляющаяся функция, значит, она сохраняет знак.
    }
    \definition[Движение против часовой стрелки]{
        Движение $\phi$ по окружности, такое, что $w(t) > 0$.
        Также говорят о \emph{движении в положительном направлении} (при движении \emph{круг остаётся слева}).
    }
    Если $|\phi'(t)| = 1$, то $|w(t)| = 1$.
    Так как $w(t)$ не меняет знак, то на самом деле $w(t)$ --- константа, не зависит от $t$: всегда либо $+1$, либо $-1$.

    Из определения простого вращения извлекаем, что $w(0) = 1$.
    Таким образом, простое вращение происходит против часовой стрелки.

    Так как $w = 1$, то $\phi'(t) = i \phi(t)$.

    Если $\phi_1, \phi_2: \langle a, b \rangle \map \T$ и удовлетворяют выше написанному, то <<более-менее они одинаковые>>.
    \newlection{4 апреля 2023 г.}
    \ldots Пропущена первая пара, доказали $\exists!$ простое вращение, посмотрели на него внимательно.

    \[i = \Gamma\left(\frac{\pi}4\right)^2 = \Gamma\left(\frac\pi2\right) \then \left(\cos\left(\frac\pi4\right) + i \sin\left(\frac\pi4\right)\right)^2 = \cos\left(\frac\pi4\right)^2 - \sin\left(\frac\pi4\right)^2 + 2i\cos\left(\frac\pi4\right)\sin\left(\frac\pi4\right)\]
    Так как $\sin\left(\frac\pi4\right), \cos\left(\frac\pi4\right) > 0$, то уравнение имеет единственное решение $\cos\left(\frac\pi4\right) = \sin\left(\frac\pi4\right) = \frac{\sqrt{2}}{2}$.

    \subsection{Формулы Тейлора и ряд Тейлора для функций $\Gamma, \sin, \cos$}
    Используя основное тождество, получаем $\Gamma^{(n)}(t) = i^n\Gamma(t)$.
    Значит, записывая формулу Тейлора с остаточным членом в форме Пеано, получаем в нуле
    \[\Gamma(t) = 1 + it + \frac{1}{2!}i^2 t^2 + \frac{1}{3!}i^3 t^3 + \dots + \frac{1}{n!}i^n t^n + o(t^n)\]

    Пусть $f: \langle a, b \rangle \map \R^n$ --- векторнозначная функция, непрерывно дифференцируемая $n + 1$ раз.
    Как можно записать для неё формулу Тейлора?
    \[f(t) = \vect{f_1(t)\\ \vdots \\ f_j(t)}\]
    Выбрав $t_0 \in (a, b)$, можем записать $f_j(t) = \sum\limits_{k = 0}^{n}\frac{f^{(k)}(t_0)}{k!}(t - t_0)^k + \frac{1}{(n + 1)!}f_j^{(n + 1)}(\xi_j)(t - t_0)^{n + 1}$
    Эти точки $\xi_j$ зависят от $j$, поэтому записать формулу Лагранжа прямо не получится.

    Для оценки того, сходится ли ряд Тейлора к соответствующей функции, можно оценить $f^{(n + 1)}$ по модулю независимо от точки, на всём промежутке $(t_0, t)$.

    Можно пойти по-другому:
    $\exists \xi \in (t_0, t): \left|f(t) - \sum\limits_{k = 0}^{n}\frac{f^{(k)}(t_0)}{k!}(t - t_0)^k\right| \le \frac{1}{(n + 1)!}\left|f^{(n + 1)}(\xi)(t - t_0)^{n + 1}\right|$.
    \provehere{
        Такое же, как и в формуле Лагранжа: рассмотрим $u \in \R^n$, такой, что $|u| = 1$ и
        \[\angles{u, f(t) - \sum\limits_{k = 0}^{n}\frac{f^{(k)}(t_0)}{k!}(t - t_0)^k} = \abs{f(t) - \sum\limits_{k = 0}^{n}\frac{f^{(k)}(t_0)}{k!}(t - t_0)^k}\]
        Введём функцию $g(\tau) \coloneqq \langle u, f(\tau) \rangle$ и запишем формулу Лагранжа для неё:
        \gather{g(t) - \sum\limits_{k = 0}^{n}\frac{g^{(k)}(t_0)}{k!}(t - t_0)^k = \frac{1}{(n + 1)!}g^{(n + 1)}(\xi)(t - t_0)^{n + 1},\quad\text{для $\xi \in (t_0, t)$}\\
        \Downarrow\\
        \abs{f(t) - \sum\limits_{k = 0}^{n}\frac{f^{(k)}(t_0)}{k!}(t - t_0)^k} \le \frac{1}{(n + 1)!}|u|\cdot|t - t_0|^{n + 1}\abs{f^{(n + 1)(\xi)}}}
    }
    Итак, \[\abs{\Gamma(t) - \sum\limits_{k = 0}^{n}\frac{i^k}{k!}t^k} \le \frac{1}{(n + 1)!}|t|^{n + 1} \cdot |\Gamma^{(n + 1)}(\xi)| \le \frac{1}{(n + 1)!}|t|^{n + 1},\quad\text{для некой $\xi \in (0, t)$}\]
    Если $|t| \le R$ для некой константы $R \in \R$, то остаточный член равномерно стремится к нулю: $\frac{t^n}{(n + 1)!} \le \frac{R^n}{(n + 1)!} \underset{n \to \infty}\Map 0$.

    Значит, ряд Тейлора сходится для $\Gamma(t)$ на всей вещественной оси: $\Gamma(t) = \sum\limits_{k = 0}^{\infty}\frac{i^k}{k!}t^k$.
    Вспомним, что $e^t = \sum\limits_{k = 0}^{\infty}\frac{1}{k!}t^k$.

    Взяв вещественную и мнимую часть разложения в ряд Тейлора $\Gamma(t)$, получим разложение в ряд Тейлора косинуса и синуса соответственно:
    \gather{
        \cos(t) = \Re \sum\limits_{k = 0}^{\infty}\frac{i^k}{k!}t^k = \sum\limits_{k = 0}^{\infty}\Re\left(\frac{i^k}{k!}t^k\right) = 1  - \frac{t^2}{2} + \frac{t^4}{4!} - \frac{t^6}{6!} + \dots \\
        \sin(t) = \Im \sum\limits_{k = 0}^{\infty}\frac{i^k}{k!}t^k = \sum\limits_{k = 0}^{\infty}\Im\left(\frac{i^k}{k!} t^k\right)= t - \frac{t^3}{3!} + \frac{t^5}{5!} - \frac{t^7}{7!} + \dots
    }
    \definition[Тангенс]{
        Функция $\tg(x) \bydef \frac{\sin(x)}{\cos(x)}$, заданная везде, где знаменатель не обращается в ноль.
    }
    \note{Период тангенса --- $\pi$: $\tg(x + \pi) = \frac{\sin(x + \pi)}{\cos(x + \pi)} = \frac{-\sin(x)}{-\cos(x)} = \tg(x)$.}
    Тангенс строго возрастает на промежутках определённости:
    \[\tg'(t) = \left(\frac{\sin t}{\cos t}\right)' = \frac{(\cos t)^2 + (\sin t)^2}{(\cos t)^2} = \frac{1}{(\cos t)^2}\]

    \subsection{Обратные тригонометрические функции}

    \subsubsection{Арксинус}
    $\sin' x = \cos x$, что больше нуля на $\left(-\frac\pi2, \frac\pi2\right)$.
    Значит, $\sin x$ возрастает на $\left(-\frac\pi2, \frac\pi2\right)$, обозначим $\arcsin \bydef \sin^{-1}: [-1, 1] \map \left[-\frac\pi2, \frac\pi2\right]$.

    \gather{\arcsin'(x) = \frac{1}{\cos(\arcsin x)} = \frac{1}{\cos(\arcsin x)}
    \underset{\text{так как на $\left(-\frac\pi2, \frac\pi2\right)$ косинус положительный}}=\frac{1}{\sqrt{1 - \sin^2(\arcsin x)}} = \frac{1}{\sqrt{1 - x^2}}}

    \subsubsection{Арктангенс}
    $tg$ возрастает на $\left(-\frac\pi2, \frac\pi2\right)$, определим $\arctg \bydef \tg^{-1}: \R \map \left(-\frac\pi2, \frac\pi2\right)$.
    \[\arctg'(x) = \frac{1}{\tg'(\arctg x)} = \cos^2(\arctg x) = \dots = \frac{1}{1 + x^2}\]

    Очевидным следствием является $\arctg x = \int\limits_{0}^{x}\frac{\d t}{1 + t^2}, t \in \R$.

    Запишем $\frac{1 - t^{n+1}}{1 + t} = 1 - t + t^2 - \dots + (-1)^{n} t^{n}$.
    Таким образом, $\frac{1}{1 + t^2} = 1 - t^2 + t^4 - \dots + (-1)^{n}t^{2n} + \frac{t^{2(n + 1)}}{1 + t^2}$.

    \[\arctg(x) = x - \frac{x^3}{3} + \frac{x^5}{5} - \dots + (-1)^n\frac{1}{2n + 1}x^{2n + 1} + \int\limits_{0}^{x}\frac{t^{2(n + 1)}}{1 + t^2}\d t\]
    Считаем, что $|x| \le 1$, оценим \[\abs{\int\limits_{0}^{x}\frac{t^{2(n + 1)}}{1 + t^2}\d t} \le \int\limits_{0}^{|x|}t^{2n + 2}\d t = \frac{1}{2n + 3}|x|^{2n + 3}\]
    Таким образом, получаем ряд Тейлора для арктангенса: \[\arctg (x) = x - \frac{x^3}{3} + \frac{x^5}{5} - \dots + (-1)^n\frac{1}{2n + 1}x^{2n + 1} +\dots \]
    \ok
    Запишем $\arcsin x = \int\limits_{0}^{x}\frac{\d t}{\sqrt{1 - t^2}}$ для $|x| \le 1$.

    Ряд Ньютона для $\frac{1}{\sqrt{1 - t^2}}$ сходится равномерно при $|t| \le x < 1$.
    Равномерно сходящийся ряд можно проинтегрировать и получить ряд Тейлора для арксинуса.
    \ok
    Ещё раз посмотрим на сходство:
    $\Gamma(t) = \sum\limits_{k = 0}^{\infty}\frac{i^k}{k!}t^k$;\quad
    $e^t = \sum\limits_{k = 0}^{\infty}\frac{1}{k!}t^k$.
    Если в ряд для экспоненты формально подставить $t \leftarrow it$, то получится простое вращение.

    Простое вращение ещё называют \emph{мнимой экспонентной}.
    $e^{ix} \bydef \Gamma(x) = \sum\limits_{n = 0}^{\infty}\frac{(ix)^n}{n!}$.
    В частности, $e^{i \pi} = -1 \iff \Gamma(\pi) = 1$.

    Покамест $e^{ix}$ --- это только обозначение, не имеющее обозначение к $e^x$ для $x \in \R$, потом мы увидим ещё причины, по которым эта запись естественна.

    \subsection{Формула Эйлера}
    \gather{
        \Gamma(x) = \cos x + i \sin x; \quad \Gamma(-x) = \overline{\Gamma(x)} = \cos x - i \sin x\\
        \Downarrow \\
        \cos x = \frac{e^{ix} + e^{-ix}}{2}; \quad \sin x = \frac{e^{ix} - e^{-ix}}{2i}
    }

    Определим $e^z \bydef e^a \cdot e^{ib} = e^a \Gamma(b)$.
    Основное свойство экспоненты $e^{z_1 + z_2} = e^{z_1} \cdot e^{z_2}$ сохраняется.

    Для комплексного числа $z \in \C$ определим $\cos z = \frac{e^{iz} + e^{-iz}}{2}$ и $\sin z = \frac{e^{iz} - e^{-iz}}{2i}$.

    Заметим также, что $(e^{ax})' = a \cdot e^{ax}$, а $(e^{ibx})' = \Gamma(bx)' = ib \Gamma(bx) = ib\cdot e^{ibx}$, согласованность полная.


    \section{Дифференцирование высших порядков}
    Рассмотрим скалярную функцию $f: (G \subset \R^n) \map \R$.
    Для векторнозначных функций это тоже можно делать, но получится много индексов, и в любом случае можно разобрать векторнозначную функцию на координатные скалярные функции.

    Пусть $\der{f}{x_j}$ существуют и непрерывны для $j = 1..n$.
    При дифференцировании один раз получаем $\d f(x, h) = \sum\limits_{j = 1}^{n}\der{f}{x_j}(x) \cdot h_j \eqqcolon \phi_h(x)$, где $h = \vect{h_1 & \dots & h_n}$.

    Предположим, что возможно продифференцировать $\phi_h(x)$ по $x$ ещё раз: % \[\d \phi_h(x, k) = \sum\limits_{j = 1}^{n}\der{\phi_h}{x_j}(x)\cdot k_j\text{,\quad где $k = \vect{k_1 & \dots & k_n}$}\]
    ${\frac{\partial}{\partial x_j}\phi_h(x) = \sum\limits_{s = 1}^{n}\frac{\partial}{\partial x_j}\frac{\partial}{\partial x_s}f(x)\cdot h_s}$.

    Предположим, что все производные $\frac{\partial}{\partial x_j}\frac{\partial}{\partial x_s}f$ существуют и непрерывны.
    Тогда \[\d \phi_h(x, k) = \sum\limits_{j = 1}^{n}\sum\limits_{s = 1}^{n}\frac{\partial}{\partial x_j}\frac{\partial}{\partial x_s}f(x)h_s k_j = D^2 f(x, h, k)\]
    При каждом $x$ полученный дифференциал $D^2 f(x, \cdot, \cdot)$ --- билинейная функция.

    По определению $D^r f\left(x, h^{(1)}, \dots, h^{(r)}\right)$ --- при фиксированном $x$ это $r$-линейная форма по $h^{(1)}, \dots, h^{(r)}$.

    Раскрыв, получим $r$-ый дифференциал $f$ --- $r$-линейную форму: \[D^{r} f(x, h^{(1)}, \dots, h^{(r)}) \bydef \sum\limits_{1 \le j_1, \dots, j_r \le n} \frac{\partial}{\partial x_{j_1}}\cdots \frac{\partial}{\partial x_{j_r}}f(x)h_{j_1}^{(1)} \cdots h_{j_r}^{(r)} = \sum\limits_{1 \le j_1, \dots, j_r \le n} \frac{\partial^r f}{\partial x_{j_1}\cdots \partial x_{j_r}}(x)h_{j_1}^{(1)} \cdots h_{j_r}^{(r)}\]
    Разумеется, для существования дифференциала мы предполагаем, что существуют и непрерывны все производные вплоть до $r$-й.
    \newlection{11 апреля 2023 г.}
    \definition[Полилинейная функция порядка $s$]{Линейное по каждому из $s$ аргументов отображение $L: \underbrace{\R^n \times \dots \times \R^n}_{s} \map \R$.
    Она же --- \emph{$s$-линейная функция}.}
    Пусть в функцию $L$ подставили $h^{(1)}, \dots, h^{(s)}$.
    Разложим их по базису $h^{(j)} = \sum\limits_{k = 1}^{n}h_k^{(j)}e_k$ и воспользуемся линейностью:
    \[L(h^{(1)}, \dots, h^{(s)}) = \sum\limits_{1 \le j_1, \dots, j_s \le n}h_{j_1}^{(1)} \dots h_{j_s}^{(s)} \cdot a_{j_1, \dots, j_s}\]
    Все полилинейные функции имеют такой вид, причём всякая функция, имеющая такой вид --- полилинейна.

    $s$-линейной функции $L$ соответствует $s$-форма $T(h) = L(h, \dots, h)$ --- сужение $L$ на диагональ.
    В частности, для $s = 2: T$ --- \emph{квадратичная форма}.
    \definition[Симметричная $s$-линейная форма $L$]{
        Такая, что она не зависит от перестановки векторов-аргументов.
    }
    \theorem{
        Если все частные производные порядка $r$ от $f$ непрерывны, то они не зависят от порядка дифференцирования.
        \provehere{Позднее.}
    }
    \theorem{
        Пусть $L$ --- $s$-линейная функция, $T$ --- соответствующая $s$-форма.
        Если $L$ симметрична, то $L$ однозначно восстанавливается по $T$.
        \example[Объяснение]{Рассмотрим $s = 2$.
        \gather{
            T(x + y) = L(x + y, x + y) = L(x, x) + L(x, y) + L(y, x) + L(y, y) = L(x, x) + 2L(x, y) + L(y, y)\\
            T(x - y) = L(x - y, x - y) = L(x, x) - L(x, y) - L(y, x) + L(y, y) = L(x, x) - 2L(x, y) + L(y, y)\\
            L(x, y) = \frac{1}{4}(T(x + y) - T(x - y))
        }
        }
        \provehere{
            \[L(h^{(1)}, \dots, h^{(s)}) = \frac{1}{2^s s!}\left(\sum\limits_{\eps_1, \dots, \eps_s = \pm 1}\left(\eps_1\proddots \eps_s\right)\cdot T\left(\eps_1 h^{(1)} + \dots + \eps_s h^{(s)}\right)\right)\]
            Проверим истинность формулы: раскроем $T\left(\eps_1 h^{(1)} + \dots + \eps_s h^{(s)}\right)$ в сумму $s^s$ слагаемых вида ${\left(\prod\eps_i\right) \cdot L\left(\sum\limits\eps_j h^{(j)}\right)}$.
            При фиксированных $i_1, \dots, i_s$, рассмотрим все слагаемые $\pm L\left(h^{(i_1)}, \dots, h^{(i_s)}\right)$.
            Если $i_1, \dots, i_s$ --- перестановка, то слагаемое входит со знаком $1 = \left(\eps_1 \proddots \eps_s\right)^2$, иначе найдётся $j \ne i_1, \dots, i_s$, тогда $\eps_j = \pm 1$ нейтрализуют друг друга, в сумме останется 0.
        }
    }
    Дифференциалом порядка $r$ от $f$ обычно считают $r$-форму \[\d^{(r)} f(x, h) = D^{(r)}f(x, \underbrace{h, \dots, h}_{r})\]
    В дальнейшем все упоминания дифференциала будут относится к $\d^{(r)}$.


    \section{Формула Тейлора функции нескольких переменных}
    $f: G \map \R$ --- $r + 1$ раз непрерывно дифференцируема (нам придётся использовать $r + 1$-ю производную для записи остатка).

    Рассмотрим $x_0 \in G, \overline{B_r(x_0)} \subset G, x \in B_r(x_0)$.

    Выберем настолько маленький $\eps > 0: B_\eps(x) \subset B_r(x_0)$.
    Тогда $x_0 + t(x - x_0) \in B_r(x_0)$ для $t \in (-1, 1 + \eps)$.

    Продифференцируем $\phi: (-1, 1 + \eps) \map \R, \phi(t) = f(x_0 + t(x - x_0))$.

    Обозначим $p = x - x_0$, при новом обозначении $\phi(t) = f(x_0 + tp)$.
    \gather{\phi'(t) = \sum\limits_{j = 1}^{n}\der{f}{x_j}(x_0 + tp)p_j \underset{\angles{\grad_f(x_0), p}}= \d f(x_0 + tp, p)\\    \phi^{(2)}(t) = \sum\limits_{j = 1}^{n}\sum\limits_{k = 1}^{n}\frac{\partial^2 f}{\partial x_k \partial x_j}(x_0 + tp)p_k p_j = \d^2 f(x_0 + tp, p)}
    В общем случае $\phi^{(s)}(t) = \d^{(s)}f(x_0 + tp; p)$.

    $f(x) - f(x_0) = \phi(1) - \phi(0) = \frac{\phi'(0)}{1!} + \frac{\phi^{(2)}(0)}{2!} + \dots + \frac{\phi^{(r)}(0)}{r!} + \frac{\phi^{(r + 1)}(\xi)}{(r + 1)!}$, где $\xi \in [0, 1]$.
    \[f(x) = \underbrace{f(x_0) + \frac{\d^{(1)}f(x_0, x - x_0)}{1!} + \frac{\d^{(2)}f(x_0, x - x_0)}{2!} + \dots + \frac{\d^{(r)}f(x_0, x - x_0)}{r!}}_{\text{$r$-й многочлен Тейлора для $f$ в точке $x_0$}} + \frac{\d^{(r + 1)}f(u, x - x_0)}{(r + 1)!}\]
    где $u$ лежит на отрезке с концами в точках $x_0$ и $x$.
    Заведомо $u \in B_r(x_0)$.
    \proposal{
        Пусть $L$ --- $s$-линейная функция на $\R^n$. Тогда $\exists C \in \R:$
        \[\abs{L\left(h^{(1)}, \dots, h^{(s)}\right)} \le C \cdot \abs{h^{(1)}}\proddots \abs{h^{(s)}}\]
        Для соответствующей $s$-формы: $\abs{T(h)} \le C \cdot |h|$.
        \provehere{
            Вспомним формулу $L\left(h^{(1)}, \dots, h^{(s)}\right) = \sum\limits_{1 \le {j_1, \dots, j_s}\le n}a_{j_1, \dots, j_s}h_j^{(1)}\proddots h_{j_s}^{(s)}$.
            Существует такое $A: \forall j_1, \dots, j_s: |a_{j_1, \dots, j_s}| \le A$, так как $a$ --- конечно.
            \[\abs{\sum{a_{j_1, \dots, j_s}}h_j^{(1)}\proddots h_{j_s}^{(s)}} \le A \sum\limits_{a_{j_1, \dots, j_s}}\abs{h_1^{(1)}}\proddots \abs{h_s^{(s)}} = A\left(\abs{h_1^{(1)}} + \dots + \abs{h_1^{(s)}}\right)\proddots \left(\abs{h_n^{(1)}} + \dots + \abs{h_n^{(s)}}\right)\]
            $i$-й множитель оценивается $\sqrt{n} \cdot \abs{h^{i}}$ согласно КБШ.
        }
    }
    \note{
        Пусть $\exists h: T(h) \ne 0$. Тогда $T(th) = t^s T(h)$, то есть оценка в некотором смысле плотная.
    }
    Таким образом, в многочлене Тейлора $k$-е слагаемое оценивается по модулю $\frac{1}{k!}|x - x_0|^k$

    Оценим остаточный член в формуле Тейлора: $\d^{(r + 1)}f(u, x - x_0)$ есть $\frac{\partial^{r + 1}}{\partial x_{j_1}\proddots \partial x_{j_r}}f(u)$.
    В этом шаре все производные существуют и непрерывны, значит, ограничены некой константой.

    Так как $u \in \overline{B_r(x_0)}$, то $\abs{\d^{(r + 1)}f(u, x - x_0)} \le C |x - x_0|^{r + 1}$.
    \theorem{
        Пусть $f$ --- $r + 1$ раз непрерывно дифференцируема в $G \subset \R^{n}$, причём $\overline{B_r(x_0)} \subset G, x \in B_r(x_0)$.
        Тогда
        \[f(x) = f(x_0) + \sum\limits_{j = 1}^{r}\frac{\d^{(j)}f(x_0, x - x_0)}{j!} + \underset{\text{или }o(|x - x_0|^r)}{\bigO\left(|x - x_0|^{r+1}\right)}\]
        \provehere{
            Написано выше.
        }
    }

    \theorem[Единственность многочлена Тейлора]{
        Пусть $f$ --- $r + 1$ раз непрерывно дифференцируема в $G \subset \R^{n}$, причём $\overline{B_r(x_0)} \subset G, x \in B_r(x_0)$.

        Пусть $f(x) - f(x_0) = \sum\limits_{j = 1}^{r}T_j(x - x_0) + o(|x - x_0|^r)$, где $T_j$ --- некоторая $j$-форма.

        Тогда непременно $\forall j: T_j(h) = \frac{\d^{(j)}f(x_0, h)}{j!}$.
        \provehere{
            Аналогично одномерному случаю:

            Пусть есть два представления --- формула Тейлора, и ещё одно, такое: $f(x) - f(x_0) = \sum\limits_{j = 1}^{r}S_j(x - x_0) + o(|x - x_0|^r)$, где $S_j$ --- $j$-форма.

            Вычтем одно из другого.
            Получим функцию $r: G \map \R$, $r(x) = \sum\limits_{j = 1}^{r}R_j(x - x_0) = o(|x - x_0|^r)$, где $R_j$ --- $j$-форма.

            Пусть $k$ --- наименьший индекс, такой, что $R_k \not\equiv 0$, то есть найдётся вектор $v$, такой, что $R_k(v) \ne 0$.

            Рассмотрим $t \in \R$ в такой окрестности 0, что $x + tv \in G$. Для них $r(tv) = t^k R_k(v) + o(t^{k + 1})$.
            Получили противоречие.
        }
    }
    \newlection{14 апреля 2023 г.}

    \newlection{18 апреля 2023 г.}
    Упс, была лекция в пятницу, а ещё я опоздал минут на 5. % доску сфотографировал
    To be deployed\ldots

    3.
    Форма $V\Big|_L$ неопределённая. $\exists u_1, u_2 \in L: V(u_1) > 0, v(u_2) < 0$.
    Так как $u_1, u_2 \in L$, то $\exists a)1, a_2 \in \R^m: u_1 = \d \Phi(t_0, a_1), u_2 = \d \Phi(t_0, a_2)$, где $\Phi(x_0) = t_0 \in B$.

    Запишем
    \[F(\Phi(t_0 + \tau u_1)) - F(\Phi(t_0))\]
    где $\tau \in (-\delta, \delta)$.

    Вычисления с прошлой лекции показывают, что $\tau \mapsto F(\Phi(t_0 + \tau a_1))$ имеет локальный минимум при $t = 0$.
    При замене $a_1$ на $a_2$ получаем локальный максимум.

    Значит, нет ни максимума, ни минимума.

    \subsection{Независимость частных производных от порядка дифференцирования}
    Понятно, что достаточно научиться переставлять два оператора дифференцирования.

    \theorem{
        Пусть $U \subset \R^2$ --- открытое множество плоскости, $f: U \map \R$ --- функция, такая, что $\der{f}{x}, \der{f}{y}, \frac{\partial^2 f}{\partial y \partial x}$ существуют и непрерывны.

        Тогда $\frac{\partial^2 f}{\partial x \partial y}$ существует и совпадает с $\psi \coloneqq \frac{\partial^2 f}{\partial y \partial x}$.
        \provehere{
            Докажем в одной точке $(x_0, y_0) \in U$.

            Выберем $\rho > 0: K \coloneqq \bigdefset{(x, y)}{|x -x_0| \le \rho, |y - y_0| \le \rho} \subset U$.

            Выберем последовательность $\{h_n\}_{n \in \N}, (0 < h_n \le \rho)$, стремящуюся к нулю.
            $\phi(x) = \frac{f(x, y_0 + h_n) - f(x, y_0)}{h_n}$.
            $\phi_n(x) \Map \frac{\partial}{\partial y} f(x, y_0)$ (1).

            $\phi_n'(x) \Map \frac{\partial}{\partial x}\frac{\partial}{\partial y} f(\cdot, y_0) = \psi(x, y_0)$ (2) поточечно.

            Была теорема, что при некоторых условиях тогда что?

            Достаточно доказать, что сходимость в (1) и (2) равномерная.

            Касательно (2): $\exists \xi_n(x)$ между $y_0 + h_n$ и $y_0: \dfrac{\frac{\partial}{\partial x} f(x, y_0 + h_n) - \frac{\partial}{\partial x} f(x, y_0)}{h_n} = \frac{\partial}{\partial y}\frac{\partial}{\partial x}f(x, \xi_n(x))$.
            По теореме Кантора $\forall \eps > 0: \exists \delta: |t - t_1| \le \delta, |s - s_1| \le \delta, (t, s), (t_1, s_1) \in K \then \abs{\phi(t, s) - \phi(t_1, s_1)} < \eps$.

            Заметим, что $|y_0 - \xi_n(x)| \le h_n < \delta$ при достаточно больших $n$.
            Значит, $\abs{\frac{\partial}{\partial x}\frac{\partial}{\partial y}f(x, \xi_n(x)) - \frac{\partial}{\partial x}\frac{\partial}{\partial y}f(x, y_0)} < \eps$ при таких $n$.
        }
    }


    \chapter{Несобственные интегралы и компания}


    \section{Одна из ситуаций}
    $(\alpha, \beta) \subset \R$ --- возможно бесконечный отрезок.
    $f: (\alpha, \beta) \map \R$. $\forall [a, b] \subset (\alpha, \beta)$ пускай $f$ интегрируема на $[a, b]$ по Риману-Дарбу.

    Если $f$ не интегрируема по Риману-Дарбу на $(\alpha, \beta)$, но $\exists \lim\limits_{a \to \alpha, b \to \beta}\int\limits_{a}^{b}f(x)\d x$, то говорят, что $f$ интегрируема по отрезку $(\alpha, \beta)$ \emph{в несобственном смысле}.

    \definition[Несобственный интеграл]{
        Выше предложенный предел $\int\limits_{\alpha}^{\beta}f(x)\d x \bydef \lim\limits_{a \to \alpha, b \to \beta}\int\limits_{a}^{b}f(x)\d x$.
    }
    Обозначение такое же, как и у обычного интеграла, но следует говорить, что интеграл несобственный.

    \numbers{
        \item Предел существует --- <<(несобственный) интеграл сходится>>.
        \item Предела нет --- <<(несобственный) интеграл расходится>>.
        \item Есть предел $\lim\limits_{b \to \beta - 0}\int\limits_{a}^{b}|f(x)|\d x$ --- <<интеграл сходится абсолютно>>.
    }
    Применение критерия Коши: $\forall \eps > 0: \exists c < \beta: u, v \in [c, \beta) \then \abs{\int\limits_{u}^{v}f(x)\d x} < \eps$.

    \theorem{
        $f, g: [\alpha, \beta) \map \R$ непрерывны, $\forall b < \beta$ обе интегрируемы по Риману на $[\alpha, b]$ и $|f| \le g$.
        Если $\int\limits_{\alpha}^{\beta}g(x)\d x$ сходится, то $\int\limits_{\alpha}^{\beta}f(x)\d x$ сходится абсолютно.
        \provehere{
            $\forall u < v \in [\alpha, \beta): \abs{\int\limits_{u}^{v}f(x)\d x} \le \int\limits_{u}^{v}|f(x)|\d x\le \int\limits_{u}^{v}g(x)\d x$.
        }
    }
    \corollary{
        Интеграл сходится абсолютно $\then$ интеграл сходится.
    }
    \examples{
        \item $\int\limits_{1}^{\infty}x^\gamma \d x$ сходится $\iff \gamma < -1$.
        \item $\int\limits_{1}^{\infty}x^\rho \d x$ сходится $\iff \rho > -1$.
    }
    Пусть нас интересует интеграл $\int\limits_{\alpha}^{\beta}f(x)g(x)\d x$, при $f, g$ непрерывных на $[\alpha, \beta)$, $f'$ непрерывна на $(\alpha, \beta)$.

    Нас интересует предел $b \to \beta$ выражения:
    \[\int\limits_{\alpha}^{b}f(x)g(x)\d x = \left\|\arr{c}{G(x) = \int\limits_{\alpha}^{x}g(t)\d t}\right\| = \int\limits_{\alpha}^{b}f(x)\d G(x) = G(x)f(x)\Big|_{\alpha}^{b} - \int\limits_{\alpha}^{b}G(x)f'(x)\d x\]
    Сформулируем условия на функции $f, g$.
    Предположим, что
    \numbers{
        \item $G$ ограничена константой $A$.
        \item $\lim_{\beta - 0}f = 0$.
        \item $f$ монотонно убывает на $[\alpha, \beta)$.
        Тогда производная неположительна, интеграл $\int\limits_{\alpha}^{\beta}G(x)f'(x)\d x$ сходится абсолютно: $\abs{G(x)f'(x)} \le A|f'(x)| = -Af'(x)$.
    }
    \theorem{\label{a}
    При данных условиях интеграл $\int\limits_{\alpha}^{\beta}f(x)g(x)\d x$ сходится.
    }
    \example{\label{b}
        $\int\limits_{0}^{\infty}\frac{\sin x}{x}\d x$ сходится.

        Заметим, что особенность есть только в $\infty$, будем рассматривать $\int\limits_{1}^{\infty}\frac{\sin x}{x}\d x$.
        Положим $f(x) = \frac{1}{x}, g(x) = \sin x$.
        Тогда все условия выполнены.
    }


    \section{Сравнение рядов и интегралов}
    Пусть $f: [0, \infty) \map \R$ --- монотонная функция.
    Тогда \[\sum\limits_{j = 1}^{n}f(j) \text{\quad и \quad} \int\limits_{1}^{n}f(x)\d x\]
    вещи близкие.
    \newlection{21 апреля 2023 г.}
    Итак, пусть $f: [0, \infty) \map \R$ --- убывающая положительная функция.
    Предположим (хотя на самом деле для убывающей функции это всегда правда), что для любого $R < \infty$: $f$ интегрируема по Риману-Дарбу на $[0, R]$.

    Пусть $A_1 < A_2 < \dots < A_j$ --- возрастающая последовательность.
    Тогда оцениваем \[\sum\limits_{j = 1}^{k}f(A_{j + 1})(A_{j + 1} - A_{j}) \le \int\limits_{A_1}^{A_{k + 1}}f(x)\d x \le \sum\limits_{j = 1}^{k}f(A_j)(A_{j + 1} - A_{j})\]
    В частном случае $A_j = j$ получаем
    \gather{
        \sum\limits_{j = 1}^{k}f(j + 1) \le \int\limits_{1}^{k + 1}f(x)\d x \le \sum\limits_{j = 1}^{k}f(j)\\
        \int\limits_{1}^{k + 1}f(x)\d x \le \sum\limits_{j = 1}^{k}f(j) \le \int\limits_{1}^{k + 1}f(x)\d x + f(1) - f(k + 1)
    }
    Пусть $f(x) \underset{x \to \infty}\Map 0$, тогда при сделанных предположениях ряд $\sum\limits_{j = 1}^{k}f(j)$ сходится $\iff \int\limits_{1}^{k + 1}f(x)\d x$ сходится при $k \to \infty$.
    \note{
        Пусть $\int\limits_{1}^{\infty}f(x)\d x$ расходится. Тогда, поделив неравенство, получаем
        \[1 \le \frac{\sum\limits_{j = 1}^{k}f(j)}{\int\limits_{1}^{k + 1}f(x)\d x} \le 1 + \frac{f(1) - f(k + 1)}{\int\limits_{1}^{k + 1}f(x)\d x}\]
        Таким образом, по принципу двух полицейских, получаем, что $\int\limits_{1}^{k + 1}f(x)\d x$ и $\sum\limits_{j = 1}^{k}f(j)$ --- эквивалентные бесконечно большие при $k \to \infty$.
    }
    \corollary{
        $1 + \frac{1}{2} + \dots + \frac{1}{k} \sim \log(k + 1)$. Кстати, так как $\log(k + 1) - \log(k) = \log\left(1 + \frac{1}{k}\right) \underset{k \to \infty}\Map 0$, то можно написать и $\log(k)$ вместо $\log(k + 1)$.
    }
    \ok
    Давайте теперь возьмём $A_j = 2^j$, где $\{A_j\}_{j = 0}^{k}$.
    Так как $A_{j + 1} - A_j = 2^j$, то получаем, что сходимость ряда $\sum\limits_{j = 1}^{\infty}f(2^j)2^j$ эквивалентна сходимости интеграла $\int\limits_{1}^{\infty}f(x)\d x$.

    Забавным следствием получается формулирующееся без интегралов утверждение из первого семестра о том, что ряды $\sum\limits_{j = 1}^{\infty}f(2^j)2^j$ и $\sum\limits_{j = 1}^{\infty}f(j)$ сходятся (или расходятся) одновременно.

    \note{
        Аналогичные соображения для возрастающих функций, например, можно получить, что для $s > 0: \sum\limits_{n = 1}^{N}n^s \sim \frac{1}{s + 1}N^{s + 1}$.
    }

    \subsection{Частичные суммы гармонического ряда и постоянная Эйлера-Маскерони}
    Оказывается, есть более сильное условие, чем $1 + \frac{1}{2} + \dots + \frac{1}{k} \sim \log(k)$.
    \[\log(k + 1) = \int\limits_{1}^{k + 1}\frac{\d x}{x} = \sum\limits_{j = 1}^{k}\int\limits_{j}^{j + 1}\frac{\d x}{x} = \sum\limits_{j = 1}^{k}\frac{1}{j} + \sum\limits_{j = 1}^{k}\int\limits_{j}^{j + 1}\left(\frac{1}{x} - \frac{1}{j}\right)\d x\]
    Оценив $\abs{\frac{1}{x} - \frac{1}{j}} = \abs{\frac{x - j}{xj}} \le \frac{1}{j^2}$, получаем, что ряд этих штук сходится и разность \[\log(k + 1) - \sum\limits_{j = 1}^{k}\frac{1}{j} \underset{k \to \infty}\Map C\] стремится к некой постоянной $C$ --- \emph{постоянной Эйлера-Маскерони} (на самом деле, постоянная Эйлера-Маскерони $\gamma \bydef \lim\limits_{n \to \infty}\sum\limits_{j = 1}^{n}\frac{1}{j} - \log(n)$. Так как $\log(k + 1) - \log(k) = \log\left(1 + \frac{1}{k}\right)\underset{k \to \infty}\Map 0$, то $\gamma = -C$).

    \subsection{Формула Стирлинга}
    Получим асимптотическую оценку для факториала.

    $\log(n!) = \sum\limits_{i = 1}^{n}\log i$, сравним эту штуку с $\int\limits_{1}^{n + 1}\log x \d x$.
    Как известно, $\int \log x \d x = x \log x - x + \const$.

    \[\int\limits_{1}^{n + 1}\log x \d x = (n + 1)\log(n + 1) - (n+ 1) + 1 = (n + 1)\log(n + 1) - n\]
    Оценим по формуле Тейлора $\log(1 + x) = x - \frac{x^2}{2(1 + \xi)^2}$, $\xi \in [0, x]$, откуда $\log(1 + x) = x + \phi(x)$, $\abs{\phi(x)} \le \frac{1}{2}x^2$.
    \[\int\limits_{1}^{n + 1}\log x \d x = \sum\limits_{j = 1}^{n}\int\limits_{1}^{j + 1}\log x \d x = \sum\limits_{j = 1}^{n}\int\limits_{j}^{j + 1}(\log x - \log j)\d x + \sum\limits_{j = 1}^{n}\log j\]
    Для $x \in [j, j + 1]$ получаем $\log x - \log j = \log\left(1 + \left(\frac{x}{j} - 1\right)\right) = \frac{x - j}{j} + \phi\left(\frac{x - j}{j}\right)$, где $\abs{\phi\left(\frac{x - j}{j}\right)} \le \frac{1}{2}\frac{\abs{x - j}^2}{j^2}$.

    Итак, \gather{(n + 1)\log(n + 1) - n = \sum\limits_{j = 1}^{n}\log j + \sum\limits_{j = 1}^{n}\int\limits_{j}^{j + 1}\phi\left(\frac{x - j}{j}\right)\d x + \sum\limits_{j = 1}^{n}\frac{1}{j} = \underbrace{\int\limits_{j}^{j + 1}(x - j)\d x}_{\nicefrac{1}{2}}\sum\limits_{j = 1}^{n}\log j + \frac{1}{2}\log(n + 1) + \underbrace{v_n}_{\text{сходится}}
        \\
        \left(n + \frac{1}{2}\right)\log(n + 1) - n = \log(1) + \dots + \log(n) + v_n \\
        (n + 1)^{n + \frac{1}{2}}\cdot e^{-n} = n! \cdot e^{v_n}\\
        n^{n + \frac{1}{2}}\underbrace{\left(\frac{n + 1}{n}\right)^{n + \frac{1}{2}}}_{\text{стремится к }e}e^{-n} = n! \cdot e^{v_n} \\
        n! \sim C\sqrt{n}\left(\frac{n}{e}\right)^{n}
    }
    \intfact{Появившаяся в последней строчке константа $C = \sqrt{2 \pi}$.}


    \section{Суммируемые семейства}
    Пусть есть множество проиндексированных (быть может комплексных) чисел $\{\xi_\alpha\}_{\alpha \in A}$, где $A$ --- множество любой природы.

    Число $a$ называется суммой этого семейства, если $\forall \eps > 0: \exists$ конечное подмножество $B \subset A$, такое, что $\forall B\subset C \subset A: \abs{a - \sum\limits_{\alpha \in C}\xi_\alpha} < \eps$, где рассматриваются конечные надмножества $C$.
    \definition[Суммируемое семейство]{Семейства, у которого есть сумма. Пишут ${a = \sum\limits_{\alpha \in A}\xi_{\alpha}}$.}
    \note{
        Семейство $\{\xi_\alpha\}_{\alpha \in A}$ суммируемо $\iff \{\Re(\xi_\alpha)\}_{\alpha \in A}$ и $\{\Im(\xi_\alpha)\}_{\alpha \in A}$ оба суммируемы.
    }
    \theorem{
        Следующие условия эквивалентны:
        \numbers{
            \item Семейство $\{\xi_{\alpha}\}_{\alpha \in A}$ суммируемо.
            \item Суммы $\sum\limits_{\alpha \in C}|\xi_\alpha|$ ограничены по всем конечным $C \subset A$.
        }
    }
    \newlection{25 апреля 2023 г.}
    Ниже все множества $E, e, \overline{e}$ --- конечны.
    \theorem{
        Пусть $\{a_\alpha\}_{\alpha \in A}$ --- числовое семейство.
        Следующие условия эквивалентны:
        \numbers{
            \item Семейство суммируемое.
            \item Множество $\defset{\abs{\sum\limits_{\alpha \in e}a_{\alpha}}}{e \subset A, e\text{ --- конечно}}$ ограничено.
            \item Множество $\defset{\sum\limits_{\alpha \in e}\abs{a_{\alpha}}}{e \subset A, e\text{ --- конечно}}$ ограничено.
        }
        \provebullets{
            \item[$1 \then 2$.] Положим $a$ --- сумма семейства.
            Выберем $\eps = 1$, по определению суммируемого семейства $\exists E \subset A: \forall: e \supset E: \abs{\sum\limits_{\alpha \in e}a_{\alpha} - a} \le 1$.

            Рассмотрим произвольное $\overline{e} \subset A$, положим $e = \overline{e} \cup E$.
            \[\abs{\sum\limits_{\alpha \in \overline{e}}a_{\alpha}} = \abs{\sum\limits_{\alpha \in e}a_{\alpha} -\sum\limits_{\alpha \in E \sm \overline{e}}a_{\alpha}} \le \underbrace{\abs{\sum\limits_{\alpha \in e}a_{\alpha}} + \sum\limits_{\alpha \in E}\abs{a_\alpha}}_{\text{ограничено}}\]
            \item[$3 \then 2$] Очевидно.
            \item[$2 \then 1,3$.]
            \indentlemma{
                Пусть $\{a_\alpha\}_{\alpha \in A}$ --- множество положительных чисел.
                Следующие условия эквивалентны:
                \bullets{
                    \item Семейство суммируемое.
                    \item Множество $\defset{\sum\limits_{\alpha \in e}a_{\alpha}}{e \subset A, e\text{ --- конечно}}$ ограничено.
                }
                Если любое из условий выполнено, то $\sum\limits_{\alpha \in e}a_{\alpha} = \sup\defset{\sum\limits_{\alpha \in e}a_\alpha}{e \subset A}$.
            }{
                $1 \then 2$ уже доказали.

                Положим $a = \sup\defset{\sum\limits_{\alpha \in e}a_\alpha}{e \subset A}$.

                По определению супремума $\exists E \subset A: \sum\limits_{\alpha \in E}a_{\alpha} > a - \eps$.
                Тогда $\forall \overline{e} \supset E: a - \eps \le \sum\limits_{\alpha \in E}a_{\alpha} \le \sum\limits_{\alpha \in \overline{e}}a_{\alpha} \le a$.

                Значит, множество суммируемо по определению.
            }
            Разложим $a_{\alpha} = b_{\alpha} + i c_{\alpha}$.
            Понятно, что $\{b_\alpha\}, \{c_\alpha\}$ удовлетворяют условию (2).

            Для $\{u_\alpha\}_{\alpha \in A}$ рассмотрим $u_\alpha = u_\alpha^+ - u_\alpha^-$, теперь $\{u_\alpha\}$ разложимо в разность двух неотрицательных семейств $\{u_\alpha^+\}$ и $\{u_\alpha^-\}$.

            Если $\{u_\alpha\}$ удовлетворяет условию (2), то так же удовлетворяют условию и $\{u_\alpha^+\}$ вместе с $\{u_\alpha^-\}$ --- можно выбирать в конечное множество только положительные или только отрицательные числа.

            Тогда $a_\alpha = b_\alpha^+ - b_\alpha^- + i(c_\alpha^+ - c_\alpha^-) \then \{a_\alpha\}$ суммируемо согласно лемме.
            Доказали $2 \then 1$.

            Чтобы доказать, $2 \then 3$ покажем, что $\abs{a_\alpha} \le b_\alpha^+ + b_\alpha^- + c_\alpha^+ + c_\alpha^-$.
        }
    }
    \note{
        Если $\{u_\alpha\}_{\alpha \in A}$ --- числовое семейство, $u_\alpha \ge 0$, то
        \[\sum\limits_{\alpha \in A}u_\alpha = \all{\text{сумма семейства,} & \text{если оно суммируемо}\\+\infty,& \text{иначе}}\]
    }
    \theorem{
        Если семейство $\{a_\alpha\}_{\alpha \in A}$ суммируемо, то $\defset{\alpha \in A}{a_\alpha \ne 0}$ не более, чем счётно.
        \provehere{
            Так как семейство суммируемо, то множество $\defset{\sum\limits_{\alpha \in e}\abs{a_{\alpha}}}{e \subset A, e\text{ --- конечно}}$ ограничено неким числом $C$.

            Выберем $n \in \N$, предположим. что нашлось $k$ элементов $a_{\alpha_1}, \dots, a_{\alpha_k}: \abs{a_{\alpha_i}} \ge \frac{1}{n}$.

            Тогда $\sum\limits_{i = 1}^{k}\abs{a_{\alpha_i}} \ge \frac{k}{n}$.
            Но так как эти суммы ограничены константой $C$, то $k \le nC$, то есть $A_n \coloneqq \defset{a_\alpha}{\abs{a_\alpha} \ge \frac{1}{n}}$ конечно.

            Тогда $\defset{\alpha}{\abs{a_\alpha} > 0} = \bigcup\limits_{n = 1}^{\infty}A_n$ счётно.
        }
    }
    \theorem[О перестановках]{
        Пусть $\phi: A \map A$ --- биекция. Тогда семейство $\{a_\alpha\}_{\alpha \in A}$ суммируемо $\iff$ семейство $\{a_{\phi(\alpha)}\}_{\alpha \in A}$ суммируемо, причём их суммы совпадают, если есть.
    }
    \proposal{
        Пусть $\{a_n\}$ --- числовая последовательность.
        Тогда следующие условия эквивалентны:
        \numbers{
            \item $\sum\limits_{n = 1}^{\infty}a_n$ абсолютно сходится.
            \item Семейство $\{a_n\}_{n \in \N}$ суммируемо.
        }
        При этом если условия верны, то суммы равны.
        \provehere{
            Для всякого конечного $e \subset \N$ найдётся $N \coloneqq \max e$, тогда $\sum\limits_{i \in e}\abs{a_{i}} \le \sum\limits_{i = 1}^{N}\abs{a_i}$.

            Обратно --- для всякого $N \in \N$ найдётся $e \coloneqq \{1, \dots, N\}$, тогда $\sum\limits_{i = 1}^{N}\abs{a_{i}} \le \sum\limits_{i \in e}\abs{a_i}$.

            То, что суммы равны, тоже можно доказать, рассмотрев хвосты с суммой меньше $\eps$.
        }
    }
    \corollary{
        Абсолютно сходящийся ряд сходится к той же сумме после любой его перестановки.
    }
    \theorem[Лейбниц]{
        Пусть $\{a_j\}_{j \in \N} \subset \R$, причём $\sum\limits_{j = 1}^{\infty}a_j$ сходится лишь условно: ${\sum\limits_{j = 1}^{\infty}\abs{a_j} = +\infty}$.

        Пусть $-\infty \le r \le s \le +\infty$.
        Тогда $\exists \phi: \N \map \N$ --- биекция, такая, что \[\varliminf_{n \to \infty}\sum\limits_{j = 1}^{n}a_{\phi(j)} = r\qquad\varlimsup_{n \to \infty}\sum\limits_{j = 1}^{n}a_{\phi(j)} = s\]
        \provehere[Схема доказательства]{
            Пусть --- для удобства доказательства --- $-\infty < r \le s < +\infty$.
            Упорядочим $\abs{a_1}\ge \abs{a_2} \ge \dots$
            Так как $\sum\limits_{j = 1}^{\infty}a_j^+$ и $\sum\limits_{j = 1}^{\infty}a_j^-$ оба расходятся, то можно брать поочерёдно положительные, то отрицательные числа, бегая от границы к границе.
        }
    }
    Пусть $\{a_\alpha\}_{\alpha \in A}$ --- числовое семейство, $\{B_\gamma\}_{\gamma \in \Gamma}$ --- разбиение $A$ на непустые множества.
    \theorem{
        Если семейство $\{a_\alpha\}_{\alpha \in A}$ суммируемо (с суммой $a$), то все частичные семейства $\{a_\alpha\}_{\alpha \in B_\gamma}$ суммируемы (с суммой $b_\gamma$), причём семейство их сумм $\{b_\gamma\}_{\gamma \in \Gamma}$ тоже суммируемо --- с суммой $a$.

        Если все $a_\alpha \ge 0$ (но необязательно семейство суммируемо), то $\sum\limits_{\alpha \in A}a_\alpha = \sum\limits_{\gamma \in \Gamma}\left(\sum\limits_{\alpha \in B_\gamma}a_\alpha\right)$
        \provehere{
            Докажем только последнюю строчку, остальное из неё следует, так как семейство можно разбивать на линейную комбинацию неотрицательных составляющих.

            Если одно из $b_\gamma = +\infty$, то обе суммы равны $+\infty$. Дальше считаем, что все $b_\gamma$ конечны.
            Покажем, что \[\underbrace{\sup\defset{\sum\limits_{\alpha \in e}a_\alpha}{e \subset A}}_{V} = \underbrace{\sup\defset{\sum\limits_{\gamma\in \overline{e}}b_\gamma}{\overline{e} \subset \Gamma}}_{W}\]

            Можно показать, что $V \le W$, а ещё для любого $\eps > 0$: $W - \eps \le V$ --- для доказательства второго неравенства суммируем лишь конечное число групп.
        }
    }
    \newlection{28 апреля 2023 г.}

    \subsection{Применения}
    Пусть $\sum\limits_{n \ge 1}a_n$ и $\sum\limits_{n \ge 1}b_n$ --- два (быть может условно) сходящихся ряда с суммами $a$ и $b$ соответственно.

    Рассмотрим последовательность, проиндексированную парами $\N \times \N: (a_n \cdot b_k)_{n\in\N, k \in \N}$.
    \theorem{
        Если оба ряда сходятся абсолютно, то полученное семейство $(a_n \cdot b_k)_{n\in\N, k \in \N}$ суммируемо, причём его сумма --- $ab$.
        \provehere{
            Докажем суммируемость $(a_n \cdot b_k)_{n\in\N, k \in \N}$.
            Для этого рассмотрим семейство модулей $(\abs{a_n \cdot b_k})_{n\in\N, k \in \N}$.
            Разобьём его на группы $B_i = \defset{(i, j)}{j \in \N}$.

            Сумма модулей в каждой группе $B_i$ --- это $\abs{a_i} \cdot B$, где $B = \sum\limits_{n \ge 1}|b_i|$.

            Тогда семейство суммируемо, так как сумма сумм групп --- это $AB$, где $A = \sum\limits_{n \ge 1}|a_i|$.

            Чтобы показать, что сумма семейства --- $AB$, повторим вычисление уже без модулей.
        }
    }
    \theorem{
        Пары $(n, k)$ всегда можно расположить в последовательность так, чтобы соответствующий ряд сходился к $ab$.
        \provehere{
            Подойдёт такой порядок суммирования:
        % https://q.uiver.app/?q=WzAsMTksWzAsMCwiYV8xYl8xIl0sWzEsMCwiYV8xYl8yIl0sWzIsMCwiYV8xYl8zIl0sWzMsMCwiYV8xYl80Il0sWzAsMSwiYV8yYl8xIl0sWzEsMSwiYV8yYl8yIl0sWzIsMSwiYV8yYl8zIl0sWzMsMSwiYV8yYl80Il0sWzAsMiwiYV8zYl8xIl0sWzEsMiwiYV8zYl8yIl0sWzIsMiwiYV8zYl8zIl0sWzMsMiwiYV8zYl80Il0sWzAsMywiYV80Yl8xIl0sWzEsMywiYV80Yl8yIl0sWzIsMywiYV80Yl8zIl0sWzMsMywiYV80Yl80Il0sWzQsMCwiXFxidWxsZXQiXSxbNCwxLCJcXGJ1bGxldCJdLFs0LDIsIlxcYnVsbGV0Il0sWzAsNF0sWzQsNV0sWzUsMV0sWzEsMl0sWzIsNl0sWzYsMTBdLFsxMCw5XSxbOSw4XSxbOCwxMl0sWzEyLDEzXSxbMTMsMTRdLFsxNCwxNV0sWzE1LDExXSxbMTEsN10sWzcsM10sWzMsMTZdLFsxNiwxN10sWzE3LDE4LCJcXHZkb3RzIiwxXV0=
            \[\begin{tikzcd}[ampersand replacement=\&]
            {a_1 b_1}
                  \& {a_1 b_2} \& {a_1 b_3} \& {a_1 b_4} \& \bullet \\
                  {a_2 b_1} \& {a_2 b_2} \& {a_2 b_3} \& {a_2 b_4} \& \bullet \\
                  {a_3 b_1} \& {a_3 b_2} \& {a_3 b_3} \& {a_3 b_4} \& \bullet \\
                  {a_4 b_1} \& {a_4 b_2} \& {a_4 b_3} \& {a_4 b_4}
                  \arrow[from=1-1, to=2-1]
                  \arrow[from=2-1, to=2-2]
                  \arrow[from=2-2, to=1-2]
                  \arrow[from=1-2, to=1-3]
                  \arrow[from=1-3, to=2-3]
                  \arrow[from=2-3, to=3-3]
                  \arrow[from=3-3, to=3-2]
                  \arrow[from=3-2, to=3-1]
                  \arrow[from=3-1, to=4-1]
                  \arrow[from=4-1, to=4-2]
                  \arrow[from=4-2, to=4-3]
                  \arrow[from=4-3, to=4-4]
                  \arrow[from=4-4, to=3-4]
                  \arrow[from=3-4, to=2-4]
                  \arrow[from=2-4, to=1-4]
                  \arrow[from=1-4, to=1-5]
                  \arrow[from=1-5, to=2-5]
                  \arrow["\vdots"{description}, from=2-5, to=3-5]
            \end{tikzcd}\]
        }
    }
    Другим популярным порядком является суммирование по диагонали: $\sum\limits_{N = 2}^{\infty}\sum\limits_{k + j = N}a_k b_j$.
    Как ни странно, если ряды сходились абсолютно, то сумма в таком порядке даёт $ab$, а если сходились условно --- то необязательно сойдётся (но если сойдётся, то к $ab$: \ref{product_convergence}).

    Вспомним, что для комплексного числа $z = x + iy$ по определению $e^z = e^x \cdot e^{iy}$, где $e^{iy} = \Gamma(y)$ --- простое вращение.

    Экспоненту можно представить рядом: $e^x = \sum\limits_{n = 0}^{\infty}\frac{x^n}{n!}; \quad e^{iy} = \sum\limits_{n = 0}^{\infty}\frac{(iy)^n}{n!}$.
    Ряды сходятся абсолютно, запишем
    \[e^z = \sum\limits_{k,n}\frac{x^k \cdot (iy)^n}{k! n!} = \sum\limits_{N = 0}^{\infty}\frac{1}{N!}\underbrace{\sum\limits_{k + n = N}\binom{N}{k}x^k \cdot (iy)^n}_{(x + iy)^N} = \sum\limits_{N =0 }^{\infty}\frac{z^N}{N!}\]
    Доказали, что формула для экспоненты комплексного числа верна для любого $z \in \C$, необязательно вещественного или чисто мнимого.


    \section{Степенные ряды}
    \definition[Степенной ряд]{
        Ряд вида $\sum\limits_{n \ge 0}a_n(z - z_0)^n$, где $z_0 \in \C$ --- фиксированная точка, $\{a_n\}_{n \in \N_0} \subset \C, z$ --- переменная из $\C$.
    }
    При каких $z$ ряд сходится?
    Абсолютно сходится?

    \theorem{
        Пусть степенной ряд $\sum\limits_{n \ge 0}a_n(z - z_0)^n$ сходится при значении $w$ переменной $z$.
        Обозначим $r = |w - z_0|$.

        Тогда ряд сходится абсолютно при $|z - z_0| < r$.
        Более того, для всякого $r' < r$: в круге $|z - z_0| \le r'$ сходимость равномерная.
        \provehere{
            Из сходимости ряда $\exists A \in \R: \forall n \in \N: \abs{a_n (w - z_0)^n} \le A$. Если $|z - z_0| < r$, то \[\abs{a_n (z - z_0)^n} = \abs{a_n (w - z_0)^n} \cdot \abs{\frac{(z - z_0)^n}{r^n}} \le A\abs{\frac{(z - z_0)^n}{r^n}}\]
            Для $|z - z_0| < r$ получаем, что ряд мажорируется убывающей геометрической прогрессией, значит, сходится абсолютно.
            Если дополнительно $|z - z_0| \le r'$, то можно оценить независимо от $z$:
            \[\abs{a_n (w - z_0)^n} \cdot \abs{\frac{(z - z_0)^n}{r^n}} \le \abs{a_n (w - z_0)^n} \cdot \abs{\frac{{r'}^n}{r^n}}\]
        }
    }
    Выберем $R \coloneqq \sup\defset{w \in \C}{\text{ряд сходится при значении $w$ переменной $z$}}$.
    Из условия теоремы следует, что ряд сходится в открытом круге с центром в $z_0$ и радиусом $R$ и расходится --- за границей круга.

    Если $R = 0$, то ряд сходится в одной точке $z = z_0$, если $R = \infty$, то ряд сходится на всей $\C$.

    \subsection{Признак Коши сходимости ряда}

    Пусть $\sum\limits_{n = 0}^{\infty}a_n$ --- числовой ряд $(a_n \in \C)$.

    Обозначим за $\sigma = \varlimsup\limits_{n \to \infty}\sqrt[n]{\abs{a_n}}$.
    \theorem[Признак Коши]{
        \numbers{\down
        \item Если $\sigma > 1$, то ряд расходится.
        \item Если $\sigma < 1$, то ряд сходится абсолютно.
        }
        \provebullets{
            \item[1.] $\forall \eps > 0$: найдётся сколь угодно большое $n$: $\sqrt[n]{\abs{a_n}} > \sigma - \eps$.
            Тогда $\abs{a_n} > (\sigma - \eps)^n > 1$, общий член ряда не стремится к нулю.
            \item[2.] Выберем $\eps > 0$ так, что $\sigma + \eps < 1$.
            Начиная с некоторого места $n_0 \in \N: \forall n > n_0: \sqrt[n]{\abs{a_n}} \le \sigma + \eps$ и ряд мажорируется геометрической прогрессией.
        }
    }
    \note{
        Признак довольно грубый: $\sum\limits_{n \ge 0}\frac{1}{n^\alpha}$ для любого $\alpha \in \R$ признак оценить не сможет --- тут $\sigma = 1$.
    }
    Тем не менее, для степенных рядов получается неплохо: для ряда $\sum\limits_{n = 0}^{\infty}a_n (z - z_0)^n: {\sigma = \varlimsup\limits_{n \to \infty}\sqrt[n]{|a_n|}\cdot|z - z_0|}$.

    Таким образом, для радиус сходимости $R$ верно равенство $\frac{1}{R} = {\varlimsup\limits_{n \to \infty}\sqrt[n]{|a_n|}}$.

    \examples{
        \item Ряд $\sum\limits_{n \ge 0}n^n z^n$ сходится в единственной точке: $R = 0$.
        \item Ряд $\sum\limits_{n \ge 0}\frac{1}{n!}z^n$ сходится на всей $\C: R = \infty$.
        \item Все ряды вида $\sum\limits_{n \ge 0}n^\alpha z^n$ сходятся в круге радиуса 1.
    }

    \subsection{Аналитические функции}
    Пусть $G \subset \C$ --- открытое множество.

    Рассмотрим функцию $f: G \map \C$.
    \definition[$f$ --- аналитическая функция]{
        $\forall z_0 \in G: \exists B_r(z_0) \subset G: \forall z \in B_r(z_0): {f(z) = \sum\limits_{n \ge 0}{a_n}(z - z_0)^n}$, то есть функция представима некоторым степенным рядом в окрестности любой точки.
    }
    \example[Аналитическая функция]{
        Экспонента: $e^z = e^{z_0} \cdot e^{z - z_0} = e^{z_0} \sum\limits_{n = 0}^{\infty}\frac{(z - z_0)^n}{n!}$.
    }
    \theorem{
        Сумма степенного ряда в открытом круге сходимости есть аналитическая функция в том же круге.
        \provehere{
            Пусть $R$ --- радиус сходимости. Определим \[f(z) = \sum\limits_{n \ge 0}a_n(z - z_0)^n, \qquad D = \bigdefset{z \in \C}{|z - z_0| < R}\]

            Рассмотрим $w_0 \in D$, докажем, что найдутся коэффициенты, такие, что $f(z) = \sum\limits_{n \ge 0}b_n(z - w_0)^n$ при условии $|z - w_0| < R - |w_0 - z_0|$.
            (Считаем, что $R$ конечно)
            Запишем
            \[f(z) = \sum\limits_{n \ge 0}a_n(z - z_0)^n = \sum\limits_{n \ge 0}a_n (z - w_0 - (w_0 - z_0))^n = \sum\limits_{n \ge 0}a_n\sum\limits_{k + j = n}\binom{n}{k}(z - w_0)^k(w_0 - z_0)^j\]
            Проверим, что можно переставить знаки суммирования, что семейство суммируемое. Ну, в самом деле,
            \[\sum\limits_{n \ge 0}\abs{a_n}\sum\limits_{k + j = n}\binom{n}{k}\abs{z - w_0}^k\abs{w_0 - z_0}^j = \sum\limits_{n \ge 0}|a_n|(|z - w_0| + |w_0 - z_0|)^n\]
            что сходится при данных $z: |z - w_0| < R - |w_0 - z_0|$.
            Значит, можно раскрыть скобки, для некоторых коэффициентов получится требуемое.
        }
    }
    \newlection{2 мая 2023 г.}
    \definition[Область]{Связное открытое множество}
    \theorem{
        Если $f: G \map \C$ --- аналитическая функция $f \not\equiv 0$ и $G$ --- область, то множество нулей функции не имеет предельных точек внутри $G$.
        \provehere{
            Обозначим $Z(f) = \defset{z \in G}{f(z) = 0}$.

            Пусть степенной ряд $g(z) = \sum\limits_{n \ge 0}c_n(z - z_0)$ сходится в круге $D \coloneqq D_r(z_0), 0 < r \le \infty$.

            Из равномерной сходимости степенного ряда получаем, что $g$ непрерывна на $D$.
            Заметим, что $c_0 = \lim_{z \to z_0}g(z)$. Если $c_0 \ne 0$, то у $g$ нет других нулей вблизи $z_0$.

            Иначе $c_0 = 0$, но ряд тривиальный $g(z) \not\equiv 0$.
            Выберем наименьшее $k \in \N$: $c_k \ne 0$. Получаем
            \[g(z) = (z - z_0)^k (\underbrace{c_k + c_{k + 1}(z - z_0) + c_{k + 2}(z - z_0)^2 + \dots}_{h(z)})\]
            $h(z)$ сходится в то же круге $D$, так как $h(z) = \frac{g(z)}{(z -z_0)^k}$, поделили на константу.

            Получается, $h(z) \ne 0$ вблизи $z_0$, значит и домноженная на $(z - z_0)^k$ --- тоже.

            Итак, если у функции $f$ есть нуль в точке $w$, то либо эта точка изолирована, либо $f(z) \equiv 0$ в окрестности $w$.

            Обозначим $A = \defset{w \in G}{f(z) \equiv 0 \text{ в некоторой окрестности }w}$.
            $A$, понятно, открыто.

            Мы доказали, что любая предельная точка для $Z(f)$ лежит в $A$, в частности, любая предельная точка $A$ лежит в $A$.
            Тем самым, $A$ замкнуто в $G$. $f(z) \not\equiv 0$, значит, $A \ne G \then A = \o$.
        }
    }


    \section{Дифференцировании по комплексному аргументу. Голоморфные функции}
    Пусть $\phi: \angles{a, b} \map \R, t_0 \in \angles{a, b}$.
    Тогда по определению $\phi'(t_0) = \lim\limits_{t \to t_0}\frac{\phi(t) - \phi(t_0)}{t - t_0}$.

    Пусть $G$ --- открытое множество в $\C$, $f: G \map \C, z_0 \in G$.
    \definition[$f$ дифференцируема в $z_0$ в комплексном смысле]{ $\exists \lim\limits_{z \to z_0}\frac{f(z) - f(z_0)}{z - z_0}$.
    }
    Данный предел называется \emph{производной}, обозначается $f'(z_0)$.
    Если предел существует, то ещё говорят, что $f$ голоморфна в $z_0$.

    \subsection{Связь комплексного дифференцирования и двумерного дифференцирования}
    \bullets{
        \item Пусть $h: (G \subset \R^2)\map \R^2$.
        И область аргументов, и область значений можно отождествить с $\C$ (с его подмножеством).
        По определению, $h$ дифференцируема в $z_0$, если $\exists A: \R^2 \map \R^2$ --- линейный оператор: \[h(z) - h(z_0) = A(z - z_0) + o(|z - z_0|)\]

        Запишем $h = \vect{h_1 & h_2}$, $h_1, h_2$ --- координатные функции
        Если $A$ существует, то $A = \vect{\der{h_1}{x} & \der{h_1}{y} \\ \der{h_2}{x} & \der{h_2}{y}}$.

        \item Теперь пусть $f: (G \subset \C) \map \C$.
        Для неё координатные функции --- $u, v: (G \subset \C) \map \R$, $f(z) = u(z) + i f(z)$.
        \[f(z) - f(z_0) = f'(z_0)(z - z_0) + o(|z - z_0|)\]
        Умножение на комплексное число --- частный случай линейного оператора.

        \item Таким образом, если $f$ дифференцируема в комплексном смысле, то и в вещественном смысле (как отображение $\R^2 \map \R^2$) тоже: $\d f(z_0, h) = f'(z_0) h$.

        \item Обратное неверно: пусть $f'(z_0) = \alpha + i \beta$, $h = t + i s$, где $\alpha, \beta, t, s\in \R$.
        Тогда \gather{f'(z_0)h = (\alpha + i \beta)(t + i s) = (\alpha t - \beta s) + i(\beta t + \alpha s) \\
        \vect{t \\ s} \mapsto \vect{\alpha & -\beta \\ \beta & \alpha}\vect{t \\ s}}
        и мы видим, что при комплексном дифференцировании матрица линейного оператора имеет специальный вид, для матриц не такого вида это неверно.
        \item Если $f$ дифференцируема в $z_0$ в комплексном смысле, то (считая $z = x_0 + i y_0$) необходимо и достаточно условий
        \[\der{u}{x}(x_0, y_0) = \der{v}{y}(x_0, y_0) \qquad \der{u}{y}(x_0, y_0) = -\der{v}{x}(x_0, y_0)\]
        Эти условия называются \emph{уравнения Коши-Римана}.
    }
    \examples[Безобидные функции, которые не голоморфны]{
        \item $h(z) = \Re (z); \quad h(x + iy) = x$.
        Здесь матрица Якоби $\smallvect{1 & 0 \\ 0 & 0}$, не удовлетворяет условиям Коши-Римана.
        Также несложно видеть, что предела $\lim\limits_{z \to 0}\frac{z}{\Re(z)}$ не существует.
        \item $h(z) = \overline{z}; \quad h(x + iy) = x - iy$.
        Здесь матрица Якоби $\smallvect{1 & 0 \\ 0 & -1}$, не удовлетворяет условиям Коши-Римана.
    }
    \ok
    \fact{Пусть $G, U$ открыты в $\C$, $f: G \map U, h: U \map \C$ --- функции, $f$ голоморфна в $z_0$, $h$ голоморфна в $w_0 \coloneqq f(z_0)$.

    Тогда $h \circ f$ голоморфна в $z_0$ и $(h \circ f)'(z_0) = h'(w_0)f'(z_0)$.\provehere{Оператор дифференцирования --- домножение на комплексное число.} }
    \fact{
        Пусть $f, g: G \map \C$ голоморфны в $z_0$, тогда $(fg)'(z_0) = f'(z_0)g(z_0) + f(z_0)g'(z_0)$.
        \provehere{
            Всякая голоморфная функция $\phi$ непрерывна по определению: \[\phi(z) = \phi(z_0) + \phi'(z)(z - z_0) + o(|z -z_0|) \underset{z \to z_0}\Map \phi(z_0)\]
            Тем самым, $\phi$ ограничена вблизи $z_0$.
            \[\frac{f(z)g(z) - f(z_0)g(z_0)}{z - z_0} = \frac{f(z) - f(z_0)}{z - z_0}g(z) + \frac{g(z) - g(z_0)}{z - z_0}f(z_0) \underset{z \to z_0}\Map f'(z_0)g(z_0) + g'(z_0)f(z_0)\]
        }
    }
    \fact{
        $(z^n)' = nz^{n - 1}$, $n \in \N_0$.
        \provehere{
            $1' = 0; \qquad  z' = 1: \frac{z - z_0}{z - z_0} \underset{z \to z_0}\Map 1$.\qquad
            Дальше индукция.
        }
    }
    Тем самым, дифференцируемы все комплексные многочлены $p(z) = a_0 + a_1 z + \dots + a_n z_n$, где $a_n \in \C, z \in \C$.
    А именно, \[p'(z_0) = a_1 + 2a_2 z_0 + \dots + n a_n z_0^{n - 1}\]

    \intfact[Теорема Коши]{
        Следующие условия эквивалентны:
        \numbers{
            \item $f$ голоморфна в $G$ (в каждой точке).
            \item $f$ аналитична в $G$.
        }
        \provehere{
            Докажем сильно более простую импликацию $2 \then 1$. Обратную докажем в IV семестре.

            Рассмотрим степенной ряд $\sum\limits_{n \ge 0}a_n (z - z_0)^n$, пусть его радиус сходимости $R > 0$.
            Положим $D \coloneqq D_R(z_0)$.

            Докажем, что $f'(z) = \sum\limits_{n = 1}^{\infty}n a_n z^{n - 1}$.
            Вспомним определение радиуса сходимости $\frac{1}R = {\varlimsup\limits_{n \to \infty}\sqrt[n]{|a_n|}}$.
            Для продифференцированного ряда $\frac{1}{\rho} = {\varlimsup\limits_{n \to \infty}\sqrt[n]{|na_{n-1}|}}$, это то же самое, значит, $R = \rho$.

            Степенной ряд в круге радиуса $R' < R$ сходится равномерно: $S_N(z) \coloneqq \sum\limits_{n = 0}^{N}a_n(z - z_0)^n$ сходятся равномерно к $f(z)$.
            Более того, $S_n'(z)\coloneqq \sum\limits_{n = 1}^{N}na_n(z - z_0)^{n-1}$ сходится равномерно к продифференцированному ряду.

            Разобьём функцию на координатные функции, изучим вещественные и мнимые части.
            Частные производные сходятся согласно вещественной теореме, значит, условия Коши-Римана в пределе выполняются, получается, степенной ряд голоморфен.
        }
    }
    \ok
    Рассмотрим ряд $\log(1 + z) = x - \frac{x^2}{2} + \frac{x^3}{3} - \dots$.
    Он сходится при $x \in (-1, 1)$, значит, сходится в круге радиуса 1.

    Обозначим $\phi(z) = z - \frac{z}{2} + \frac{z^3}{3} - \dots$ --- голоморфная функция при $|z| < 1$.

    Интересно, верно ли, что $e^{\phi(z)} = 1 + z$? Да.
    \provehere{
        $e^{\phi(z)}$ голоморфна. По теореме Коши она аналитична.
        Тогда разность данных функций аналитична, так как это 0 на $(-1, 1)$, то это 0 везде.
    }
    \fact{Если $f, g$ голоморфны в точке $z_0$, $g(z_0) \ne 0$, то для $h(z) = \frac{f(z_0)}{g(z_0)}$ верно: \[h'(z_0) = \frac{f'(z_0)g(z_0) - f(z_0)g'(z_0)}{g(z_0)^2}\]}
    \fact{
        Частное комплексных многочленов $\frac{p(z)}{q(z)}$ голоморфно там, где $q(z) \ne 0$.
    }
    \newlection{5 мая 2023 г.}


    \section{Суммирование последовательностей и рядов}
    Пусть последовательность $\{a_n\}_{n \ge 0}$ --- не сходится.

    Сопоставим ей последовательность $\{b_n\}_{n \ge 0}$ согласно некоему правилу.
    Если оказалось, что $b_n \underset{n \to \infty}\Map b$, то говорят, что $\{a_n\}$ суммируется к $b$ данным методом.

    \subsection{Метод Чезаро}
    $b_n = \frac{a_0 + \dots + a_n}{n + 1}$ --- метод средних арифметических.
    \ok
    \definition[Регулярный метод суммирования]{
        Сумма сходящейся последовательности данным методом --- её предел.
    }
    \fact{
        Метод Чезаро регулярен.
        \provehere{\ref{regularity}.}
    }
    \note{
        Метод Чезаро, хотя и регулярен, суммирует и расходящиеся последовательности, например, $0, 1, 0, 1, 0, \dots$ суммируется методом Чезаро к $\nicefrac{1}{2}$.
    }

    \subsection{Матричные методы суммирования. Метод Тёплица}
    Пусть $T = \{t_{i,j}\}_{i,j\ge0}$ --- матрица с неотрицательными коэффициентами --- \emph{матрица Тёплица}.

    Предположим, что $\forall i: \sum\limits_{j = 0}^{\infty}t_{i,j} < \infty$.

    Положим $b_i \coloneqq \sum\limits_{j = 0}^{\infty}t_{i,j}a_j$.

    На данном месте предположим, что $\{a_j\}$ ограничена.
    Если последовательность сходится, то она уж точна ограничена, а мы хотим немного расширить понятие сходящихся последовательностей.
    В случае $|a_j| < A$ все $b_i$ корректно определены.

    \definition[Последовательность $\{a_j\}$ суммируется $T$-методом к $b$]{
        $b_i \underset{n \to \infty}\Map b$.
    }
    Для метода Чезаро
    \[T = \vect{1 & 0 &\ddots &&\ \\ \frac{1}{2}&\frac{1}{2}&0 & \ddots& \\ \frac{1}{3} & \frac{1}{3} & \frac{1}{3} & 0 & \ddots  \\ \vdots&&&&\ddots }\]
    \theorem[Тёплиц]{
        Следующие условия эквивалентны:
        \numbers{
            \item $T$-метод регулярен.
            \item $\forall j: \lim\limits_{i \to \infty}t_{i,j} = 0\quad\land\quad \lim\limits_{i \to \infty}\sum\limits_{j = 0}^{\infty}t_{i,j} = 1$.
        }
        \provetwhen {
            Зафиксируем $j$, рассмотрим последовательность $\{\delta_{i,j}\}_{i \ge 0}$.
            Она сходится к нулю, но $b_i = t_{i,j}$.
            Значит, $t_{i,j} \underset{i \to \infty}\Map 0$ --- необходимое условие.

            Теперь рассмотрим $\{1\}_{i \ge 0}$. Она сходится к нулю, но $b_i = \sum\limits_{j = 0}^{\infty}t_{i,j}$.
            Значит, $\sum\limits_{j = 0}^{\infty}t_{i,j} \underset{i \to \infty}\Map 1$ --- тоже необходимое условие.
        }{
            Пусть $a_j \underset{j \to \infty}\Map a$. Докажем, что $b_i$ сходится туда же.
            \[b_i - a = \sum\limits_{j = 0}^{\infty}a_j t_{i,j} - a = \sum\limits_{j = 0}^{\infty}(a_j - a)t_{i,j} + \underbrace{a\left(\sum\limits_{j = 0}^{\infty}t_{i,j} - 1\right)}_{\underset{i \to \infty}\Map 0} \]
            Докажем, что и первое слагаемое стремится к нулю.

            Так как суммы сходятся $\sum\limits_{j = 0}^{\infty}t_{i,j} \underset{i \to \infty}\Map 1$, то они ограничены некой константой $A$.
            Выберем $\eps > 0, \exists N: \forall j > N: |a_j - a| < \eps$.
            \[\sum\limits_{j = 0}^{\infty}(a_j - a)t_{i,j} = \sum\limits_{j = 0}^{N}(a_j - a)t_{i,j} + \sum\limits_{j = N + 1}^{\infty}(a_j - a)t_{i,j}\]
            Теперь устремим $i \to \infty$, первое слагаемое для достаточно больших $i$ меньше $\eps$ --- конечная сумма произведений ограниченных и бесконечно малых.

            Второе оценивается как $\eps A$, получаем оценку $\eps(1 + A)$, её можно сделать сколь угодно малой.
        }
    }
    \corollary{\label{regularity}
    Метод Чезаро регулярен.
    }
    \note{
        Суммирование рядов устроено так же, как и последовательностей --- суммируем частичные суммы.
    }

    Если в матрице Тёплица бывают отрицательные коэффициенты или даже произвольные комплексные, то что?

    Хочется оставить формулу $b_i = \sum\limits_{j = 0}^{\infty}a_j t_{i,j}$.
    Для этого надо наложить условие $S_i \coloneqq \sum\limits_{j = 0}^{\infty}|t_{i,j}| < \infty$.
    Необходимость понятна: рассмотреть в $a_j \coloneqq \frac{\overline{t_{i,j}}}{|t_{i,j}|}$.

    Теорема Тёплица в таком случае звучит так:
    \intfact[Общая теорема Тёплица] {
        Следующие условия эквивалентны:
        \numbers{
            \item $T$-метод регулярен.
            \item \bullets{
                \item $\forall j: \lim\limits_{i \to \infty}t_{i,j} = 0$.
                \item $\lim\limits_{i \to \infty}\sum\limits_{j = 0}^{\infty}t_{i,j} = 1$.
                \item $\sup\limits_{i}S_i < +\infty$.
            }
        }
    }
    $(2) \then (1)$ доказывается примерно так же, как доказать, что $\sup\limits_{i}S_i < +\infty$ -- необходимое условие?

    Это можно доказать методом скользящего горба или теоремой Штейнгауза --- последнее из функционального анализа.

    \subsection{Метод Абеля --- Пуассона}
    Рассмотрим необязательно сходящийся ряд $\sum\limits_{k = 0}^{\infty}a_k$ с ограниченными частичными суммами $S_n \coloneqq a_0 + \dots + a_n$.

    Выберем $r \in [0, 1)$, составим ряды $\phi(r) = \sum\limits_{k = 0}^{\infty}r^k a_k$.
    Они сходятся.

    Если $r$ устремить к единице, то $\phi(r)$ <<как бы стремится к исходному ряду, что бы это не значило>>.
    \definition[Суммируемый методом Абеля --- Пуассона ряд]{
        Ряд $\sum\limits_{k = 0}^{\infty}a_k$, для которого $\exists \lim\limits_{r \to 1_-}\phi(r)$.
    }
    \example{
        Ряд $1 - 1 + 1 - 1 + \dots$ имеет сумму $\nicefrac{1}{2}$ и методом Абеля-Пуассона тоже: $\frac{1}{1 + r} = 1 - r + r^2 - \dots$
    }
    \theorem{
        Если исходный ряд сходится, то он суммируем методом Абеля-Пуассона с той же суммой.
        \provehere{
            Перепишем метод для последовательностей: рассмотрим $\{d_j\}_{j \ge 0}$.
            Ей соответствует ряд \[d_0 + (d_1 - d_0) + (d_2 - d_1) + \dots\]
            Запишем для $r \in [0, 1)$ ряд \[\phi(r) = d_0 + r(d_1 - d_0) + r^2(d_2 - d_1) + \dots \underset{\text{абсолютная сходимость}}{=} d_0(1 - r) + d_1(r - r^2) + d_2(r^2 - rr^3) + \dots\]
            Получили некоторый аналог методу Тёплица, но не дискретный, а непрерывный: в качестве $t_{i,j}$ выступает $r^j - r^{j + 1}$.

            Докажем, что если $d_j \underset{j \to \infty}\Map d$, то $\phi(r) \underset{r \to 1_-} d$.

            Достаточно доказать, что $\phi(r_i) \underset{i \to \infty}\Map d$ для любой последовательности $r_i \in [0, 1)$, стремящейся к 1.
            Это верно из теоремы Тёплица.
        }
    }
    \intfact{Всё суммируемое методом Чезаро суммируется методом Абеля --- Пуассона, но не наоборот.}

    \subsubsection{О произведении рядов}
    Пусть $\sum\limits_{j = 0}^{\infty}\alpha_j = \alpha; \qquad \sum\limits_{j = 0}^{\infty}\beta_j = \beta$, быть может, сходящихся условно.
    Рассмотрим семейство $\{\alpha_i \beta_j\}{i,j}$ и <<просуммируем по диагонали>>.
    Положим $\gamma_n \coloneqq \sum\limits_{i + j = n}\alpha_i \beta_j$.
    \fact{\label{product_convergence}
    Если $\sum\limits_{n = 0}^{\infty}\gamma_n$ сходится к $\gamma$, то обязательно $\gamma = \alpha \beta$.
    \provehere{
        Рассмотрим для $r \in [0, 1)$ два абсолютно сходящихся ряда $\phi(r) \coloneqq \sum\limits_{i = 0}^{\infty}r^i \alpha_i$ и $\psi(r)\coloneqq\sum\limits_{j = 0}^{\infty}r^j \beta_j$.

        Запишем \[\phi(r)\psi(r) = \sum\limits_{n \ge 0}\left(\sum\limits_{i + j= n}r^i\alpha_i r^j\beta_j\right) = \sum\limits_{n \ge 0}r^n\left(\sum\limits_{i + j= n}\alpha_i \beta_j\right) = \sum\limits_{n = 0}^{\infty}r^n \gamma_n \underset{r \to 1_-}\Map\gamma\qedhere\]
    }
    }
    \newlection{12 мая 2023 г.}


    \section{Перестановка предельных переходов}
    Вспомним теорему Стокса-Зайделя: $\{f_n\}$ --- последовательность непрерывных функций, $\forall x: f_n(x) \underset{n \to \infty}\Map f(x)$.

    Хочется, чтобы $f$ была непрерывной, то есть $\lim\limits_{x \to x_0}f(x) = f(x_0)$.
    Так как $f(x) = \lim\limits_{n \to \infty}f_n(x)$, то мы хотим, чтобы
    \[\lim\limits_{x \to x_0}\lim\limits_{n \to \infty}f_n(x) = f(x_0)\]
    С другой стороны, при переставленных пределах
    \[\lim\limits_{n \to \infty}\lim\limits_{x \to x_0}f_n(x) = f(x_0)\]
    очевидно верно.
    Теорема Стокса-Зайделя говорит о том, что пределы можно переставлять, если сходимость $f_n(x) \rightarrow f(x)$ равномерна.

    Запишем этот результат общо.
%    Пределы есть в произвольных топологических пространствах, а равномерность требует метрики.
%
%    Пусть $F: X \times Y \map Z$ --- отображение, причём $Y$ --- метрическое пространство с метрикой $\rho$.
%    $\forall \eps > 0: \exists U$ --- окрестность точки $a: \forall y \in B, \forall x \in U: \rho(F(x, y), \psi(y)) < \eps$.
    \theorem{
        Пусть $X, Y$ --- хаусдорфовы топологические пространства, $A \subset X, B \subset Y$.
        Введём также $Z$ --- полное метрическое пространство (с метрикой $\rho$).

        Пусть $a \in \Cl A, b \in \Cl B$, причём $a \notin A, b \notin B$. Пускай $F: A \times B \map Z$ --- отображение.

        Предположим, что $\forall x \in A: \exists \lim\limits_{y \to b}F(x, y) \eqqcolon \phi(x)$, сходимость не предполагается равномерной.

        Предположим, что $\forall y \in B: \exists \lim\limits_{x \to a}F(x, y) \eqqcolon \psi(y)$, причём сходимость равномерна по $y$: \[\forall \eps > 0: \exists U\text{ --- окрестность точки }a: \forall y \in B, \forall x \in U \cap A: \rho(F(x, y), \psi(y)) < \eps\]

        Тогда $ \exists \lim\limits_{x \to a}\phi(x), \exists \lim\limits_{y \to b}\psi(y)$, причём они равны.

        Более того, $(a, b) \in \Cl (A \times B)$, и функция $F$ имеет предел (в топологии произведения) в $(a, b)$.
        \provehere{
            \indentlemma[Критерий Коши для функций]{
                Пусть $W$ --- хаусдорфово, $Z$ --- полное метрическое. $C \subset W; h: C \map Z$, пусть $c \in \Cl C \sm C$.

                Если $\forall \eps > 0: \exists U \ni c: \forall u_1, u_2 \in U \cap C: \rho(h(u_1), h(u_2)) < \eps \then \exists \lim\limits_{u \to c}h(u)$.
            }{
                Выберем $\eps_n = \frac{1}{n}$ для $n \in \N$, подберём $U_n\ni c$, как в условии леммы.
                Можно считать, что $U_1 \supset U_2 \supset \dots$.
                Выберем $u_n \in C \cap U_n$.

                Так как пространство $Z$ полное, то $\exists z = \lim\limits_{n \to \infty}h(u_n)$.
                Эта точка и будет пределом $h$ --- согласно определению предела $z$, посылке леммы и неравенству треугольника.
            }
            Выберем $\eps > 0$, для него найдётся $U \ni a$ согласно равномерной сходимости: \[\forall x_0 \in U \cap A: \forall y \in B: \rho(F(x_0, y), \psi(y)) < \eps\]
            Зафиксируем произвольный $x_0 \in U \cap A$.

            Найдётся окрестность $V\ni b: \forall y \in V \cap B: \rho(F(x_0, y), \phi(x_0)) < \eps$.
            Рассмотрим $y, y' \in V \cap B$:
            \gather{\rho(\psi(y), \psi(y')) \le \rho(\psi(y), F(x_0, y)) + \rho(F(x_0, y), F(x_0, y')) + \rho(F(x_0, y'), y') \le \\
            2\eps + \rho(F(x_0, y), F(x_0, y')) \le  2\eps + \rho(F(x_0, y), \phi(x_0)) + \rho(\phi(x_0), F(x_0, y')) \le 4\eps}
            то есть отображение $\psi$ удовлетворяет условию Коши.

            По лемме $\exists \lim\limits_{y \to b}\psi(y) \eqqcolon u$.

            Перейдём к пределу $y \to b$ в неравенстве ${\rho(F(x_0, y), \psi(y)) < \eps}$:
            \[\rho(\phi(x_0), u) \le \eps\]
            Так как $x_0$ --- произвольная точка из $U \cap A$, то $\lim\limits_{x \to a}\phi(x) = u$.

            Теперь докажем существование двойного предела:
            \gather{\forall \eps > 0: \exists U\ni a: \forall x \in U \cap A, \forall y \in B: \rho(F(x, y), \psi(y)) < \eps \\
            \exists V \ni b: \forall y \in V \cap B: \rho(\psi(y), u) < \eps\\
            \Downarrow\\
            (x, y) \in (U \times V) \cap (A \times B) \then \rho(F(x, y), u) \le \rho(F(x, y), \psi(y)) + \rho(\psi(y), v) < 2\eps}
        }
    }
    \note{
        Хаусдорофовость тут наверно и не нужна, но в анализе нехаусдорфовы пространства крайне редко встречаются.
        Предположим на всякий случай.
    }

    \subsection{Применение}
    Возьмём интеграл \[\int\limits_{0}^{+\infty}\frac{\sin x}{x}\d x\]
    Как мы уже знаем~(\ref{b}), у него есть особенность на бесконечности, и он сходится лишь условно.

    Рассмотрим $F: \R_{\ge 0} \map \R; \quad F(a) = \int\limits_{0}^{\infty}e^{-ax}\frac{\sin x}{x}\d x$.

    Запишем несколько фактов, которые вскоре и докажем.
    \numbers{
        \item $F(a) \underset{a \to \infty}\Map 0$.
        \item $F(a) \underset{a \to 0}\Map F(0) = \int\limits_{0}^{\infty}\frac{\sin x}{x}\d x$.
        \item $F$ дифференцируема при $a > 0, F'(a) = -\frac{1}{1 + a^2}$.
        \[\frac{\d}{\d a}\left(\int\limits_{0}^{\infty}e^{-ax}\frac{\sin x}{x}\d x\right) \underset{\text{неформально}}= \int\limits_{0}^{\infty}\frac{\d}{\d a}\left(e^{-ax}\frac{\sin x}{x}\right)\d x =-\int\limits_{0}^{\infty}e^{-ax}\sin x~\d x \underset{\text{дважды по частям}}{= \dots =} -\frac{1}{1 + a^2}\]
    }
    Тем самым, $F(a) = -\arctg(a) + C$.
    Из первого пункта получаем $C = \frac{\pi}{2}$, из второго получаем \encircle{F(0) = \int\limits_{0}^{+\infty}\frac{\sin x}{x}\d x = \frac{\pi}{2}}
    \provehere{
        Обоснуем пункты.
        Для начала возьмём интеграл $\int\limits_{c}^{d}e^{-at}\sin t~\d t$ для $0 \le c < d, a > 0$.
        \gather{\int\limits_{c}^{d}e^{-at}\sin t\d t = -\int\limits_{c}^{d}e^{-at}\d \cos t = (-e^{-at}\cos t)\Big|_{c}^{d} - a\int\limits_{c}^{d}e^{-at}\cos t~\d t = \\
            = (-e^{-at}\cos t)\Big|_{c}^{d} - a\int\limits_{c}^{d}e^{-at}\d \sin t = (-e^{-at}\cos t)\Big|_{c}^{d} - (ae^{-at}\sin t)\Big|_c^d - a^2\int\limits_{c}^{d}e^{-at}\sin t~\d t
        }
        Отсюда получаем \[\int\limits_{c}^{d}e^{-at}\sin t~\d t = \frac{e^{-ac}\cos c - e^{-ad}\cos d - ae^{-ad}\sin d + ae^{-ac}\sin c}{1 + a^2}\]
        Эта штука замечательна тем, что ограничена по всем $a, c, d$.

        Заметим, что при $c \to 0, d \to \infty$ получается $\frac{1}{1 + a^2}$, то есть несобственный интеграл \encircle{\int\limits_{0}^{\infty}e^{-at}\sin t~\d t = \frac{1}{1 + a^2}}.
        \lemma{
            Пусть $G: A \times [\alpha, \beta) \map \R$ --- функция, такая, что $\forall u \in A; G(u, \cdot)$ интегрируема по Риману на всех отрезках $[\alpha, \beta']$ для $\beta' \in [\alpha, \beta)$.
            $A$ здесь играет роль индексного множества.

            Пусть $g: [\alpha, \beta) \map \R_{\ge 0}$, $\int\limits_{\alpha}^{\beta}g(x)\d x$ существует в несобственном смысле.
            Ещё пусть $\forall x \in [\alpha, \beta), u \in A: \abs{G(u,x)}\le g(x)$. Тогда \[\lim\limits_{\beta' \to \beta_-}\int\limits_{\alpha}^{\beta'}G(u, x)\d x\text{ существует равномерно по $u \in A$}\]
            \provehere{
                Пусть $t_1, t_2, \in [\alpha, \beta)$, для определённости считаем, что $t_1 < t_2$.
                \[\abs{\int\limits_{\alpha}^{t_1}G(u, x)\d x - \int\limits_{\alpha}^{t_2}G(u, x)\d x} = \abs{\int\limits_{t_1}^{t_2}G(u, x)\d x} \le \int\limits_{\alpha}^{t_1}g(x)\d x\]
                При $t_1 \to t_2$ эта штука стремится к 0.
            }}
        \newlection{13 мая 2023 г.}
        \numbers{
            \item Выберем $g(x) = e^{-x}$. При $a \ge 1$ действительно $\abs{e^{-ax}\frac{\sin x}{x}} \le g(x)$.
            Значит, предел $\lim\limits_{R \to \infty}\int\limits_{0}^{R}e^{-ax}\frac{\sin x}{x} \d x$ существует равномерно по $a \ge 1$, и $\forall R: \exists \lim\limits_{a \to \infty}\int\limits_{0}^{R}e^{-ax}\frac{\sin x }{x}\d x$.
            Значит, пределы можно переставить, получаем \[\lim\limits_{a \to \infty}\lim\limits_{R \to \infty}\int\limits_{0}^{R}e^{-ax}\frac{\sin x}{x}\d x = \lim\limits_{R \to \infty}\lim\limits_{a \to \infty}\int\limits_{0}^{R}e^{-ax}\frac{\sin x}{x}\d x\]
            Подпредельное выражение $\int\limits_{0}^{R}e^{-ax}\frac{\sin x}{x}\d x = 0$, так как подынтегральная функция на отрезке равномерно стремится к нулю.
            \item Из равномерной сходимости на отрезке получаем $\int\limits_{0}^R e^{-ax}\frac{\sin x}{x}\d x \underset{a \to 0}\Map \int\limits_0^R\frac{\sin x}x \d x$.
            \[\int\limits_{0}^{R}e^{-ax}\frac{\sin x}{x}\d x \underset{R \to \infty}\Map \int\limits_{0}^{\infty}e^{-ax}\frac{\sin x}{x}\d x\]
            Чтобы применить теорему о перестановке пределов надо показать, что один из пределов равномерен: например, при $R \to \infty$ --- равномерно по $a$.
            \fact{
                $\lim\limits_{R \to \infty}\int\limits_{0}^{R}e^{-ax}\frac{\sin x}{x} \d x$ существует равномерно по $a \in (0, 1)$.
                \provehere{
                    $\int\limits_{0}^{R}e^{-ax}\frac{\sin x}{x} \d x = \int\limits_{0}^{1}e^{-ax}\frac{\sin x}{x} \d x + \int\limits_{1}^{R}e^{-ax}\frac{\sin x}{x} \d x$, считаем, что $R > 1$.
                    Первое слагаемое от $R$ не зависит, на равномерность сходимости не влияет. Вторую проинтегрируем по частям:

                    Положим $h_a(x) = \int\limits_{1}^{x}e^{-at}\sin t~\d t$, заметим, что $\exists C: \forall a, x: |h_a(x)| \le C$.
                    \[\int\limits_{1}^{R}\frac{1}{x}\d h_a(x) = \underbrace{\frac{1}{x}h_a(x)\Big|_1^R}_{\to -h_a(1) \text{ равномерно по $a$}} + \underbrace{\int\limits_{1}^R \frac{h_a(x)}{x^2}\d x}_{\text{существует равномерно по $a$ согласно лемме}}\]
                }
            }
            Значит, опять же, можно переставить пределы.
            \item Теперь докажем, что можно дифференцировать под знаком интеграла, что \[F'(a) = \int\limits_0^\infty\frac{\d}{\d a}\left(e^{-ax}\frac{\sin x}{x}\right)\d x\]
        Обозначим для краткости производную по второму аргументу $\partial_2$.
            \lemma{Пускай $I = [\alpha, \beta]$, а ещё есть интервал $(c, d)$. Пусть $H: I \times (c, d) \map \R$ --- непрерывная функция, причём $\forall x \in I, t \in (c, d): \exists \partial_2 H(x, t) \eqqcolon \phi(x, t)$, и данная производная тоже непрерывна на $I \times (c, d)$.

            Определим $h(t) \coloneqq \int\limits_{\alpha}^{\beta}H(x, t)\d x$ --- существует, так как $H(x, t)$ непрерывна (и непрерывна при фиксированном втором аргументе).

            Тогда $h'(t) = \int\limits_{\alpha}^{\beta}\partial_2 H(x, t)\d x$.
            \provehere{
                Пусть $t_0 \in (c, d)$, $t_0 \in \Int \Delta, \Delta \subset (c, d)$. На $\Delta \partial_2 H(x, t) = \phi(x, t)$ равномерно непрерывна.
                \[\frac{h(t) - h(t_0)}{t - t_0} = \int\limits_{\alpha}^{\beta}\frac{H(x, t) - H(x, t_0)}{t - t_0}\d x\]
                Давайте применим формулу Лагранжа, но ни в коем случае не под интегралом: еси подставить $\frac{H(x, t) - H(x, t_0)}{t - t_0} = \phi(x, \xi_x)$, то под интегралом может оказаться вообще неинтегрируемая (даже неизмеримая, что бы это не значило) функция.

                Воспользуемся равномерной непрерывностью: ${\forall \eps > 0: \exists \delta: |t_1 - t_2| < \delta \then |\phi(x, t_1) - \phi(x, t_2)| < \eps}$.
                Выберем $\eps > 0$, считаем, что $t - t_0 < \delta$ --- всё равно придётся переходить к пределу. Теперь $|\phi(x, \xi_x) - \phi(x, t_0)| < \eps$, откуда
                \[\abs{\frac{H(x, t) - H(x, t_0)}{t - t_0} - \phi(x, t_0)} \le \eps \then \abs{\int\limits_{\alpha}^{\beta}\left(\frac{H(x, t) - H(x, t_0)}{t - t_0} - \phi(x, t_0)\right)\d x} < (\beta - \alpha)\eps\]
                Значит, при $t \to t_0$ интегралы становятся равны, что и требовалось.
            }
            }
            К сожалению, у нас промежуток бесконечный, теорема неприменима.

            Нас интересует интеграл \[\lim\limits_{a \to a_0}\int\limits_{0}^{\infty}\frac{e^{-ax} - e^{-a_0 x}}{a - a_0}\frac{\sin x}{x}\d x\]
            Согласно только что доказанной лемме
            \gather{\forall R > 0:\lim\limits_{a \to a_0}\int\limits_{0}^{R}\frac{e^{-ax} - e^{-a_0 x}}{a - a_0}\frac{\sin x}{x}\d x = -\int\limits_0^Re^{-a_0 x}\sin x~\d x \\
            \forall a \ne a_0: \exists \lim\limits_{R \to \infty}\int\limits_{0}^{R}\frac{e^{-ax} - e^{-a_0 x}}{a -a_0}\frac{\sin x}{x} \d x =\int\limits_{0}^{\infty}\frac{e^{-ax} - e^{-a_0 x}}{a -a_0}\frac{\sin x}{x} \d x}
            Докажем, что во втором равенстве предел достигается равномерно по $a \in (U \ni a_0)$.
            Рассмотрим $a < a_0$.
            \[\int\limits_0^{R}e^{-a_0 x}\cdot \frac{e^-{(a - a_0)x} - 1}{a - a_0} \frac{\sin x }{x}\d x\]
            Подынтегральная функция оценивается по модулю как $C e^{-a_0 x}$, интеграл сходится равномерно, где $|e^{-\xi} - 1| < C |\xi|$ или что-то вроде того.
            При $a > a_0$ тоже что-то пишется, надо понять, как это покороче расписать.
        }
    }


    \chapter{Выпуклые и вогнутые функции}
    Пусть $a < b \in \R$, все точки отрезка $[a, b]$ имеют вид $a + \lambda(b - a) = (1 -\lambda)a + \lambda b, \lambda \in [0, 1]$.
    \definition[Выпуклая функция $f: (\alpha, \beta) \map \R$]{
        $\forall \alpha < a < b < \beta, \forall \lambda \in [0, 1]$: \[f((1 - \lambda)a + \lambda b) \le (1 - \lambda)f(a) + \lambda f(b)\]
    }Например, $f(x) = x^2$.
    \definition[Строго выпуклая функция $f: (\alpha, \beta) \map \R$]{
        $\forall \alpha < a < b < \beta, \forall \lambda \in (0, 1)$: \[f((1 - \lambda)a + \lambda b) < (1 - \lambda)f(a) + \lambda f(b)\]
    }
    Например, $f(x) = -x^2$.
    \definition[$f$ вогнутая]{$-f$ выпуклая.}

    Рассмотрим хорду, соединяющую точки $(a, f(a))$ и $(b, f(b))$.
    Её угловой коэффициент равен $k(a, b)\coloneqq \frac{f(b) - f(a)}{b - a}$.
    \theorem{
        Следующие условия эквивалентны
        \numbers{
            \item Функция $f: (\alpha, \beta) \map \R$ выпукла.
            \item $\forall a < c < b \in (\alpha, \beta): k(a, c) \le k(c, b)$.
            \item $\forall a < c < b \in (\alpha, \beta): k(a, b) \le k(c, b)$.
            \item $\forall a < c < b \in (\alpha, \beta): k(a, c) \le k(a, b)$.
            \item Пусть $u < v$. Если $a \le u, b \le v, a < b$, то $k(a, b) \le k(u, v)$.
            \provebullets{
                \item[$5 \then 2,3,4$] Частные случаи.
                \item[$1 \then 2$] Пусть $c = (1 - \lambda)a + \lambda b$.
                Тогда \[f(c) \le (1 - \lambda)f(a) + \lambda f(b)\quad \then\quad (1 - \lambda)(f(c) - f(a)) \le \lambda (f(b) - f(c))\]
                Выразив $\lambda = \frac{c - a}{b - a}$ получаем необходимое неравенство.
                Заметим, что вычисления обратимы, значит, доказали ещё и $2 \then 1$.
                \item[$1 \iff 3, 1 \iff 4$] Аналогично.
                \item[$2,3,4 \then 5$]{$k(a, b) \le k(a, v) \le k(u, v)$.
                }
            }
        }
    }
    \corollary{
        Выпуклая функция на $(\alpha, \beta)$ непрерывна.
        \provehere{
            Пусть $x_0 \in (\alpha, \beta)$, $x$ близко к $x_0$. Пусть $a < b < x, x_0 < c < d$.
            \[\frac{f(b) - f(a)}{b - a} \le \frac{f(x) - f(x_0)}{x - x_0} \le \frac{f(d) - f(c)}{d - c}\]
            Значит, $\exists C: |f(x) -f(x_0)| \le C |x - x_0|$, то есть функция липшицева, если она задана где-то на большем замкнутом отрезке.
        }
    }
    \corollary{
        У выпуклой функции $\forall x_0 \in (\alpha, \beta)$ существует односторонняя производная: $\frac{f(x) - f(x_0)}{x - x_0}$ монотонна по $x$ и ограничена.
        Более того, $\forall x_0 \in (\alpha, \beta): f'_-(x_0) \le f'_+(x_0)$ и $\forall x_0, x_1 \in (\alpha, \beta): f'_+(x_0) \le f'_-(x_1)$.
    }
    \newlection{16 мая 2023 г.}
    \corollary{
        Если $f: (\alpha, \beta) \map \R$ дифференцируема, то $f$ выпукла $\iff f'$ возрастает.
        \provehere{
            В одну сторону уже доказано, в другую следует из теоремы Лагранжа: \[\forall u < v < w \in (\alpha, \beta): \frac{f(v) - f(u)}{v - u} = f'(\xi_1) \le f'(\xi_2) = \frac{f(w) - f(v)}{w - v}\quad\text{для неких $\xi_1 \in (u, v), \xi_2 \in (v, w)$}\]
        }
    }
    \corollary{
        Если $f$ выпукла на $(\alpha, \beta)$, то $\forall x, y \in (\alpha, \beta)$ функция лежит выше касательных:
        \[f(x) \ge f'_{\pm}(y)(x - y) + f(y)\]
        \provehere{
            Неравенство равносильно следующему
            \[\frac{f(x) - f(y)}{x - y}\left|\begin{aligned}
                                                 \ge f_{\pm}(y),\quad x > y\\\le f_{\pm}(y),\quad x < y
            \end{aligned}\right.\qedhere\]
        }
    }
    Верно и обратное, мы для простоты докажем лишь частичное обращение:
    \lemma{
        Если $f$ дифференцируема на $(\alpha, \beta)$ и $\forall x, y \in (\alpha, \beta): f(x) \ge f'(y)(x - y) + f(y)$, то $f$ выпукла.
        \provehere{
            Достаточно проверить, что $\phi(x) \coloneqq \frac{f(y) - f(x)}{y - x}$ возрастает при $x < y$.
            \[\phi'(x) = \frac{-f'(x)(y - x) + f(y) - f(x)}{(y - x)^2}\qedhere\]
        }
    }
    \examples{
        \item $f(x) = \sin(x)$, определённая на $\left[0, \nicefrac\pi2\right]$.
        Производная убывает, функция вогнута (граничные точки отрезка добавляем по непрерывности).

        Так как график лежит под любой касательной и над любой секущей, то получаем оценку
        \[\frac{2}{\pi}x \le \sin x \le x,\quad x \in \left[0, \nicefrac\pi2\right]\]
        \item $e^x$ --- выпуклая функция, производная возрастает. Получается, по определению
        \[\forall u, v \in \R, \alpha \in (0, 1): e^{(1 - \alpha)u + \alpha v} \le (1 - \alpha)e^u + \alpha e^v \]
        Заменим переменные: $e^{(1 - \alpha)u} =A, e^{\alpha v} = B, p = \frac{1}{1 - \alpha}, q = \frac{1}{\alpha}$.
        Замена обратима при условии $A, B> 0, p, q > 1, \frac{1}{p} + \frac{1}{q} = 1$ --- такие $p, q \in (1, \infty)$ называются \emph{сопряжёнными}.
        Неравенство превращается в \emph{неравенство Юнга}:\[AB \le \frac{A^p}{p} + \frac{B^q}{q}\]
    }
    У неравенства Юнга есть красивый геометрический смысл.
    Светло серая площадь --- площадь под $y = x^{p-1}$, равна $\frac{A^{p}}{p}$.
    Тёмно серая площадь --- площадь под (ну, точнее слева) кривой $x = y^{q - 1}$, равна $\frac{B^q}{q}$ --- здесь мы пользуемся тем, что $\frac{1}{p - 1} = q - 1$.
    \pic[0.3]{young}{Геометрический смысл неравенство Юнга}

    Из рисунка видно, что действительно $AB \le \frac{A^p}{p} + \frac{B^q}{q}$.

    \fact[Неравенство Гёльдера]{
        Пусть $1 < p, q$ --- сопряжённые показатели ($\nicefrac{1}{p} + \nicefrac{1}{q} = 1$). Тогда $\forall a_1, \dots, a_n, b_1, \dots, b_n \in \C$:
        \[\abs{\sum\limits_{j = 1}^{n}a_j b_j} \le \left(\sum\limits_{j = 1}^{n}|a_j|^p\right)^{\frac{1}{p}}\left(\sum\limits_{j = 1}^{n}|b_j|^q\right)^{\frac{1}{q}}\]
        \provehere{
            Усилим неравенство (докажем частный случай $a_j, b_j \ge 0$):
            \[\sum\limits_{j = 1}^{n}\abs{a_j} \abs{b_j} \le \left(\sum\limits_{j = 1}^{n}|a_j|^p\right)^{\frac{1}{p}}\left(\sum\limits_{j = 1}^{n}|b_j|^q\right)^{\frac{1}{q}}\]
            Можно считать, что $\sum\limits_{j = 1}^{n}\abs{a_j}^p = \sum\limits_{j = 1}^{n}\abs{b_j}^q = 1$: неравенство однородно, можно все $a_j$ домножить на одно и то же $\lambda$.
            Применим неравенство Юнга к каждому слагаемому, получаем \[\sum\limits_{j = 1}^{n}\abs{a_j} \abs{b_j} \le \sum\limits_{j = 1}^{n}\frac{1}{p}\abs{a_j}^p + \frac{1}{q}\abs{b_j}^q = \frac{1}{p}\sum\limits_{j = 1}^{n}\abs{a_j}^p + \frac{1}{q}\sum\limits_{j = 1}^{n}\abs{b_j}^q = 1\qedhere\]
        }
    }
    \corollary{
        При $p = q = 2$ неравенство Гёльдера обращается в КБШ.
    }
    \fact[Неравенство Минковского]{
        \[\left(\sum\limits_{j = 1}^{n}|a_j + b_j|^p\right)^{\frac{1}{p}} \le \left(\sum\limits_{j = 1}^{n}|a_j|^p\right)^{\frac{1}{p}}+\left(\sum\limits_{j = 1}^{n}|b_j|^p\right)^{\frac{1}{p}}\]
        \provehere{
            Если $p = 1$, то очевидно.
            \begin{gather*}
                \sum\limits_{j = 1}^{n}|a_j + b_j|^p=\sum\limits_{j = 1}^{n}|a_j + b_j|\cdot|a_j + b_j|^{p-1} \le \sum\limits_{j = 1}^{n}|a_j|\cdot|a_j + b_j|^{p-1} + \sum\limits_{j = 1}^{n}|b_j|\cdot|a_j + b_j|^{p-1} \le \\
                \le \left(\sum\limits_{j = 1}^{n}|a_j|^p\right)^{\frac1p}\left(\sum\limits_{j = 1}^{n}|a_j + b_j|^{(p-1)q}\right)^{\frac1q} + \left(\sum\limits_{j = 1}^{n}|b_j|^p\right)^{\frac1p}\left(\sum\limits_{j = 1}^{n}|a_j + b_j|^{(p-1)q}\right)^{\frac1q}
            \end{gather*}
            Воспользуемся тем, что $(p - 1)q = p$, поделив обе части неравенства на $\left(\sum\limits_{j = 1}^{n}|a_j + b_j|^{p}\right)^{\frac1q}$ получим требуемое неравенство.
        }
    }
    \note{
        Неравенства Гёльдера и Минковского также применимы для интегралов, упражнение читателю --- подумать, как они выглядит.
    }
    \corollary{
        $d_p(x, y) = \left(\sum\limits_{j = 1}^{n}|x_j - y_j|^p\right)^{\frac{1}{p}}$ --- метрика в $\R^n$ (неравенство треугольника --- неравенство Минковского).
    }
    \fact[Неравенство Йенсена]{
        Пусть $f: (\alpha, \beta) \map \R$ --- выпуклая функция, $x_1, \dots, x_k \in (\alpha, \beta), \lambda_1, \dots, \lambda_k \in [0, 1]$, причём $\sum\limits_{j=1}^{k}\lambda_i = 1$.
        Тогда \[f\left(\sum\limits_{j = 1}^k\lambda_j x_j\right) \le\sum\limits_{j = 1}^k\lambda_j f(x_j)\]
        \provehere{Индукция по $k$.

        \underline{База:} $k = 2$, определение выпуклости.

        \underline{Переход:} Если $\lambda_k = 0$, то работает индукционное предположение.
        Если $\lambda_k =1$, то остальные коэффициенты --- нули, неравенство обращается в $f(x_k) \le f(x_k)$.

        Положим $y \coloneqq \frac{\lambda_1 x_1 + \dots + \lambda_{k-1}x_{k-1}}{1 - \lambda_k}$, запишем выпуклость: \[f((1 - \lambda_k)y + \lambda_k x_k) \le (1 - \lambda_k)f(y) + \lambda_k f(x_k)\]
            Применив индукционное предположение $f(y) \le \sum\limits_{j=1}^{k-1}\frac{\lambda_j}{1 - \lambda_k}f(x_j)$, получаем искомое неравенство.
        }
    }
    \corollary{
        Логарифм --- вогнутая функция, так как производная убывает.
        Применим неравенство Йенсена для $\lambda_j = \frac{1}{k}$, $x_j > 0$:
        \[\log\left(\frac{x_1 + \dots + x_k}{k}\right) \ge \sum\limits_{j = 1}^{k}\frac{1}{k}\log(x_k)\]
        Взяв экспоненту от обеих частей, получаем неравенство о средних арифметическом и геометрическом:
        \[\frac{x_1 + \dots + x_k}{k} \ge \sqrt[k]{x_1 \proddots x_k}\]
    }
    \newlection{19 мая 2023 г.}
    \fact[Неравенство Йенсена для интегралов]{
        Пусть $h: [a, b] \map \R$ --- ограниченная функция ($|h| \le M$) интегрируемая по Риману-Дарбу.
        Пусть $f: (-M - \eps, M + \eps) \map \R$ --- выпуклая функция ($\eps > 0$ --- произвольный).

        Обозначив $[a, b] = \Delta$, утверждаем, что \[f\left(\frac{1}{|\Delta|}\int\limits_{\Delta}h(x)\d x\right) \le \frac{1}{|\Delta|}\int\limits_{\Delta}(f \circ h)(x)\d x\]
        \provehere{
            \indentlemma{
                Пусть $h: [a, b] \map \R$ --- ограниченная функция ($|h| \le M$) интегрируемая по Риману-Дарбу (всё так же), $\phi: [-M, M]$ --- $C$-липшицева функция.
                Тогда $\phi \circ h$ тоже интегрируема по Риману.
            }{
                Пусть $I \subset \Delta$ --- отрезок. \[\osc_I(\phi \circ h) = \sup\limits_{x, y \in I}|\phi(h(x)) - \phi(h(y))| \le C\sup\limits_{x, y \in I}|h(x) - h(y)| \le C \osc_I h\]
                Дальше применяем критерий интегрируемости по Риману-Дарбу.
            }
            Так как $f$ задана на большем интервале, то на $[-M, M]$ она липшицева.
            Тогда согласно лемме существуют оба интеграла.

            Выберем $\eps > 0$, так как $f$ равномерно непрерывна, то $\exists \delta > 0: t_1, t_2 \in [-M, M]$ и $|t_1 - t_2| < \delta \then |f(t_1) - f(t_2)| < \eps$.

            Напишем суммы Дарбу, не особо важно, верхние или нижние, начиная с некоторого места они все близки.
            Пусть верхние.
            $\exists \Delta_1, \dots, \Delta_k$ --- разбиение $\Delta$, такое, что ${\frac{1}{|\Delta|}\abs{\int\limits_\Delta{h(x)\d x} - \sum\limits_{j = 1}^{k}\sup\limits_{x \in \Delta_j}h(x)|\Delta_j|} < \delta}$ (давайте считать, что колебания $f(h(x))$ по данному разбиению тоже $\eps$).
            Таким образом, можно применить $f$ к обеим частям (и неравенство Йенсена), совершив ошибку не более, чем на $\eps$:
            \[f\left(\frac{1}{|\Delta|}\int\limits_\Delta{h(x)\d x}\right) - \eps \le f\left(\sum\limits_{j = 1}^{k}\frac{|\Delta_j|}{|\Delta|}\sup\limits_{x \in \Delta_j}h(x)\right) \le \sum\limits_{j = 1}^{k}\frac{|\Delta_j|}{|\Delta|}f\left(\sup\limits_{x \in \Delta_j}h(x)\right)\]
            Так как супремума может не существовать, то давайте сделаем оценку: $\exists t_j \in \Delta_j: \sup\limits_{x \in \Delta_j}h(x) \ge h(t) \ge \sup\limits_{x \in \Delta_j}h(x) - \delta$.
            Теперь запишем $\abs{f(\sup\limits_{x \in \Delta_j}h(x)) - f(h(t))} < \eps$, то есть $f(\sup\limits_{x \in \Delta_j}h(x)) \le f(h(t)) + \eps \le \sup\limits_{x \in \Delta_j}f(h(x)) + \eps$.

            Теперь можно продолжить неравенство
            \[\sum\limits_{j = 1}^{k}\frac{|\Delta_j|}{|\Delta|}f\left(\sup\limits_{x \in \Delta_j}h(x)\right) \le \frac{1}{|\Delta|}\sum\limits_{j = 1}^{k}|\Delta_j|\sup\limits_{x \in \Delta_j}f(h(x)) + \frac{1}{|\Delta|}\sum\limits_{j = 1}^{k}|\Delta_j|\eps\]
            Устремляя $\eps \to 0$ получаем искомое неравенство.
        }
    }


    \section{Бесконечные произведения}
    Пусть $a_1, \dots, \in \C$.
    Что логично считать под $\prod\limits_{j = 1}^{\infty}a_j$ --- <<бесконечным произведением>>?

    Если бы числа были положительными, то можно было бы их прологарифмировать и просуммировать ряд.

    Положим $\sigma_n = \prod\limits_{j = 1}^{n}a_j$.

    Если $\sigma_n \underset{n \to \infty}\Map 0$, то говорят, что \emph{произведение расходится к нулю} --- ведь гипотетический ряд логарифмов действительно расходится к $-\infty$.

    Если $\sigma_n \underset{n \to \infty}\Map \sigma \ne 0$, то говорят, что \emph{произведение сходится к $\sigma$}.

    Вспомним, что $e^{a + bi} = e^a \cdot e^{bi}$.
    Отсюда видно, что $\exp\left(\C\right) = \C \sm \{0\}$.

    Логарифм хочется определить, как обратную функцию к $z \mapsto e^z$.
    Есть одна проблема: $z \mapsto e^z$ не инъективно.
    А именно, оно периодично с периодом $2 \pi i$.

    Заметим, что \[\frac{\d}{\d z}e^z = \frac{\d}{\d z}\sum\limits_{k = 0}^{\infty}\frac{z^k}{k!} = \sum\limits_{k = 0}^{\infty}\frac{\d}{\d z}\frac{z^k}{k!} = \sum\limits_{k = 1}^{\infty}\frac{\d}{\d z}\frac{z^{k-1}}{(k-1)!} = e^z\]
    Таким образом, $\d \exp(z_0, h) = e^{z_0} \cdot h$.

    Таким образом, $\forall z_0 \in \C \sm \{0\}\exists \eps, \exists \phi: \forall |z - z_0| < \eps: e^{\phi(z)} = z$.
    Это отображение дифференцируемо, как обратное к невырожденно дифференцируемому: $\phi'(z_0) = \frac{1}{e^{w_0}} = \frac{1}{z}$, где $w_0 = \phi(z_0)$.

    Пусть $w = a + bi, a, b \in \R$.
    Каким должно быть $w$, чтобы $e^w = z_0$?
    \[e^a \cdot e^{ib} = z_0 \quad \then \quad \all{e^a = |z_0| \\ e^{ib} = \frac{z_0}{|z_0|} \eqqcolon \zeta}\]
    Первое уравнение мы умеем решать с помощью вещественного логарифма, решениями второго уравнения являются $\defset{b + 2k\pi}{k \in \Z}$, где $b$ --- какое-нибудь решение.
    Все такие решения называются аргументами.

    Множество всех аргументов $\Arg(\zeta)$ пишется с большой буквы.
    Множество всех обратных к экспоненте обозначают $\Log(z_0) = \log|z_0| + i \Arg\frac{z_0}{|z_0|}$

    Пусть $G \subset \C$ --- область.
    \definition[Ветвь логарифма]{
        Непрерывная функция $\phi: G \map \C$, такая, что $e^{\phi(z)} = z$.
    }
    Давайте найдём какие-нибудь большие области, в которых есть ветви логарифма.
    Например, подойдёт $\defset{x \in \C}{x \le 0}$ --- (запись $x \le 0$ может быть истинна только если $x \in \R$).

    Тогда в качестве $\arg(z)$ ($z$ нормируем делением на $|z|$) выбираем значения аргумента из $(-\pi, \pi)$.
    Понятно, что определённая таким образом функция будет непрерывна.
    Определённая функция $\arg(z)$ --- \emph{главная ветвь аргумента}, ей соответствует \emph{главная ветвь логарифма} $\log z = \log|z| + i \arg z$.

    Вообще говоря, $\log(ab) \ne \log a + \log b$ --- сумма значений аргументов $a$ и $b$ может лежать вне $(-\pi, \pi)$.
    \note{Достаточным условием равенства $\log(ab) = \log a + \log b$ является $\Re a, \Re b > 0$.}

    \subsection{О сходящихся произведениях}
    По определению, произведение сходится, если $\exists \sigma: \forall \eps > 0: \exists N: \forall n > N: |\sigma_n - \sigma| < \eps$.
    Согласно тривиальной части критерия Коши \[\forall k > n: |a_1 \proddots a_k - \sigma| < \eps \then |a_1 \proddots a_n - a_1 \proddots a_k| < 2\eps \then |1 - a_{n + 1}\proddots a_k| < \frac{2\eps}{|a_1 \proddots a_k|}\]
    Пусть $\eps < \frac{|\sigma|}{2}$, тогда $|1 - a_{n + 1}\proddots a_k| < \frac{2\eps}{\sigma - \frac{|\sigma|}{2}} \le 4\frac{\eps}{|\sigma|}$.

    Таким образом, $\forall \rho > 0: \exists N: \forall k > n > N: |1 - a_{n + 1}\proddots a_k| < \rho$.

    Выбрав $\rho < \frac{1}{2}$ видим, что если произведение сходится, то начиная с некоторого места все конечные произведения лежат в круге $B_{\nicefrac{1}{2}}(1)$, в частности, лежат в полуплоскости $\Re z > 0$.

    Пускай $n > N, k > n$.
    Сходимость исходного произведения $\prod\limits_{j =1}^{\infty}a_j$ эквивалентна сходимости $\prod\limits_{j =  n}^{\infty}a_j$ (разумеется, если среди $a_1, \dots, a_{n-1}$ нет нулей).
    А это эквивалентно тому, что $\exists \tilde{\sigma}: a_n \proddots a_k \underset{k \to \infty}\Map \tilde{\sigma}$.

    Произведение $a_n \proddots a_k$, как и все его $2^k$ сомножителей лежат в полуплоскости $\Re z > 0$, значит, можно расписать $\log(a_n \proddots a_k) = \log(a_n) + \dots + \log(a_k)$.
    Таким образом, сходимость произведения эквивалентна сходимости ряд $\sum\limits_{j = n}^{\infty}\log a_j$.

    Но можно добавить и первые слагаемые, которых конечное число.
    \theorem{
        Пусть $a_j \notin (\infty, 0]$.
        Тогда $\prod\limits_{j = 1}^{\infty}a_j$ сходится $\iff \sum\limits_{j = 1}^{\infty}\log a_j$ сходится.
    }
    \note{
        Пусть ряд $\sum\limits_{j = 1}^{\infty}a_j$ сходится к $s$, а $\prod\limits_{j = 1}^{\infty}a_j$ сходится к $\sigma$.

        Тогда $e^s = \sigma$, но равенство $\log \sigma = s$ вполне может не выполняться.
    }

\end{document}

