\documentclass[a4paper]{report}

\usepackage{../mathstemplate}
\usepackage{wasysym}

\date{II семестр, весна 2023 г.}
\title{Дискретная теория вероятностей. Неофициальный конспект}
\author{Лектор: Михаил Анатольевич Лифшиц \\ Конспектировал Леонид Данилевич}


\begin{document}
    \maketitle
    \tableofcontents
    \newpage
    \setcounter{lection}{0}


    \chapter{Дискретная теория вероятностей}
    \newlection{14 февраля 2023 г.}


    \section{Основные определения и понятия}

    \subsection{Вероятностное пространство. События}
    Рассмотрим конечное или счётное множество $\Omega$.

    Элементы множества $\omega \in \Omega$ называются \emph{элементарными исходами}, само множество $\Omega$ называется \emph{пространством элементарных исходов}.

    Всякое подмножество $A \subset \Omega$ является \emph{событием}.

    Введём функцию $p: \Omega \map \R_{\ge 0}$, сопоставляющую элементарному исходу <<его вероятность>>.
    Необходимым и достаточным условием является $\sum\limits_{\omega \in \Omega}p(\omega) = 1$.
    Так как $p(\omega) \ge 0$, то сумма конечного или счётного числа слагаемых корректно определена.
    А именно, сумма счётного числа слагаемых либо расходится при любой перестановке слагаемых, либо сходится к одному и тому же числу.
    \definition[Вероятностное пространство]{
        Пространство элементарных исходов $\Omega$ с заданной на нём вероятностью $p: \Omega \map \R_{\ge 0}$.
    }
    \definition[Вероятность события]{
        Сумма вероятностей элементарных исходов --- его элементов, как множества.

        Пишут $\P: 2^\Omega \map \R; \qquad \P(A) = \sum\limits_{\omega \in A}p(\omega)$.
    }
    \properties[Свойства вероятностей]{
        \item $0 \le \P(A) \le 1$.
        \item $A \subset B \then \P(A) \le \P(B)$.
        \item $\P(A) + \P\left(\overline{A}\right) = 1$, где $\overline{A} \bydef \Omega \sm A$.
        \item $\P\left(\bigsqcup\limits_{j = 1}^{n}A_j\right) = \sum\limits_{j = 1}^{n}\P(A_j)$.
    }
    Для пересекающихся событий посчитать вероятность их объединения сложнее.
    Используя формулу включений-исключений, можно записать
    \gather{
        \P(A \cup B) = \P(A) + \P(B) - \P(A \cap B) \\
        \P(A \cup B \cup C) = \P(A) + \P(B) + \P(C) - \P(A \cap B) - \P(A \cap C) - \P(B \cap C) + \P(A \cap B \cap C)
    }
    и так далее.
    \note{
        Иногда случается так, что все элементарные исходы равновероятны.
        Так как сумма их вероятностей --- 1, то в таком случае $|\Omega| < \infty$, и $\forall \omega \in \Omega: p(\omega) = \frac{1}{|\Omega|}$.
        Отсюда получаем, $\P(A) = \frac{|A|}{|\Omega|}$.
    }

    \subsection{Взаимосвязь событий}

    \subsubsection{Условная вероятность}
    Зафиксируем некоторое событие $B \subset \Omega$, такое, что $\P(B) > 0$.

    \definition[Условная вероятность события $A$ (при условии $B$)]{
        $\P(A | B) = \frac{\P(A \cap B)}{\P(B)}$.
    }
    Об этом удобно думать, как о вероятности того, что произошло $A$, \emph{при условии} того, что произошло $B$.
    \pic[0.1]{basic_set}{Про условную вероятность}

    Красное событие довольно вероятно, что произойдёт, но при условии того, что произошло зелёное событие, вероятность красного существенно понижается.

    Интуиция за этим определением следующая: все элементарные исходы, содержащиеся в $B$ могут как произойти, так и не произойти, но все, не содержащиеся в $B$ --- точно не произошли.

    Таким образом, вероятностное пространство <<сузилось>>, ввели новую вероятностную функцию
    \[\tilde{p}: \Omega \map \R_{\ge 0}; \qquad \tilde{p}: \omega \mapsto \all{\alpha \cdot p(\omega), &\omega \in B \\ 0,  \omega \notin B}\]
    где $\alpha$ --- коэффициент нормировки, необходимый для условия суммирования всех вероятностей в единицу. $\sum\limits_{\omega \in B}p(\omega) = \P(B)$, поэтому $\alpha = \frac{1}{\P(B)}$.

    \subsubsection{Независимость событий}
    Интуитивно, независимость событий --- это когда происхождение одного события не влияет на вероятность происхождения другого.

    Воспользовавшись языком условной вероятности, $\P(A | B) = \P(A)$.
    За определение принимают формулу, полученную из этой домножением на $\P(B)$ --- без деления.
    \definition[События $A$ и $B$ независимы]{
        $\P(A) \cdot \P(B) = \P(A \cap B)$.
    }
    \note{Приятным бонусом формулы оказалась симметричность относительно $A$ и $B$.}
    Можно доказать, что независимость $A$ и $B$ влечёт независимость $\overline{A}$ и $\overline{B}$.

    Независимость множества событий бывает \emph{попарная} и \emph{в совокупности}.

    Попарная независимость --- гораздо более слабое условие, оно означает лишь независимость любой пары событий.
    Независимость множества событий $\mathcal{A} = \{A_1, A_2, \dots\}$ в совокупности означает $\forall \mathcal{S} \subset \mathcal{A}: \prod\limits_{A \in \mathcal{S}}\P(A) = \P\left(\bigcap\limits_{A \in \mathcal{S}}A\right)$.

    \counterexample[Пирамидка Бернштейна]{
        Покажем, что попарная независимость отличается от независимости в совокупности.
        Рассмотрим четырёхгранную пирамидку (как кубик, только четыре грани, а не шесть), у которой грани белая, синяя, красная, бело-сине-красная.

        При её броске возможны 4 элементарных исхода --- выпала такая-то грань. Определим вероятностное пространство на этом множестве, введя вероятности каждого исхода $\nicefrac{1}{4}$.

        Рассмотрим три события $W, B, R$ --- выпала грань, на которой есть белое, синее или красное соответственно.
        Несложно заметить, что
        \gather{
            \P(W) = \P(B) = \P(R) = \frac{1}{2} \\
            \P(W \cap B) = \P(B \cap R) = \P(W \cap R) = \frac{1}{4} \\
            \P(W \cap B \cap R) = \frac{1}{4}
        }
    }


    \section{Случайные величины}
    \definition[Случайная величина] {
        Отображение $X: \Omega \map \R$.
    }
    \definition[Независимость случайных величин $X_1, \dots, X_n$]{
        $\forall r_1, \dots, r_n \in \R$: события $\{X = r_1\}, \dots, \{X_n = r_n\}$ независимы.
    }
    Запись $\{X = r_1\}$ является сокращением более длинной записи $\defset{\omega \in \Omega}{X(\omega) = r_1}$.


    \subsection{Схема Бернулли}
    Пусть $n \in \N, p \in [0, 1]$.

    Введём независимые события $A_1, \dots, A_n$, такие, что $\P(A_j) = p$.
    Назовём их \emph{испытаниями}, посмотрим, какие испытания завершились <<успехом>> (событие произошло), а какие --- нет.
    \example[Схема Бернулли для $n = 2$]{
        Обозначим $A_1 = \{\omega_1, \omega_2\}, A_2 = \{\omega_1, \omega_3\}$.
        Все вероятности элементарных исходов определены условием однозначно.
        Так, $p(\omega_1) = \P(A_1 \cap A_2) \underset{\text{независимость}}= \P(A_1)\P(A_2) = p \cdot p = p^2$.

        Рассмотрим случайную величины $S(\omega)$ --- количество успехов.

        $\begin{array}{|c|c|c|c|c|}
             \hline
             \omega   & A_1            & A_2            & p(\omega) & S(\omega) \\\hline
             \omega_1 & \text{Успех}   & \text{Успех}   & p^2       & 2         \\\hline
             \omega_2 & \text{Успех}   & \text{Неудача} & p(1 - p)  & 1         \\\hline
             \omega_3 & \text{Неудача} & \text{Успех}   & (1 - p)p  & 1         \\\hline
             \omega_4 & \text{Неудача} & \text{Неудача} & (1 - p)^2 & 0         \\\hline
        \end{array}$
    }
    Посчитаем для произвольного $n$ вероятность того, что количество успехов --- ровно $k$.
    Из базовой комбинаторики очевидно, что \[\P(S = k) = \sum\limits_{\omega \in \Omega: S(\omega) = k}p(\omega) = \sum\limits_{\omega \in \Omega: S(\omega) = k}p^k(1 - p)^{n - k} = \binom{n}{k}p^k(1 - p)^{n - k}\]

    Для всякой случайной величины $S$, удовлетворяющей формуле выше, говорят, что она подчинена \emph{биномиальному распределению} $\mathcal{B}(n, p)$.

    Заметим, что $\Omega = \bigsqcup\limits_{k = 0}^{n}\{S = k\}$, откуда мы получаем тождество
    \[\sum\limits_{k = 0}^{n}\P(S = k) = 1 \quad \sum\limits_{k = 0}^{n}\binom{n}{k}p^k(1 - p)^{n - k} = 1\]
    \theorem[Пуассон]{
        Пусть $k \in \N_{\ge 0}, a \in \R_{> 0}$.

        Рассмотрим последовательность схем Бернулли с параметрами $(n, p_n)$, где $n \cdot p_n \underset{n \to \infty}\Map a$.

        Тогда $\P(S_n = k) \underset{n \to \infty}\Map e^{-a}\frac{a^k}{k!}$.
        Случайные величины, удовлетворяющие этой формуле, имеют \emph{распределение Пуассона} $\mathcal{P}(a)$.

        \provehere{
            \[\P(S_n = k) = \frac{n!}{(n - k)!k!}p_n^k(1 - p_n)^{n - k} = \frac{1}{k!} \cdot \underbrace{\frac{n!}{(n - k)! \cdot n^k}}_{\to 1} \cdot (\underbrace{n p_n}_{\to a})^k \cdot\underbrace{(1 - p_n)^{\frac{1}{p_n}\cdot}}_{e^{-1}}\underbrace{{}^{p_n(n - k)}}_{\to a} \Map e^{-a}\frac{a^k}{k!}\]
        }
    }
    \newlection{20 февраля 2023 г.}

    Введём в схеме Бернулли ещё одну случайную величину $T$ --- момент первого успеха, наименьший номер первого успешного события (и формальный элемент $\infty$ иначе).

    ${T \in \{1, \dots, n, \infty\}}$. (Эта запись не совсем формальна: она означает, что $T$, как отображение, принимает значения в данном множестве).
    Несложно по определению почитать \[\P(T = k) = \P\left(\overline{A_1}, \dots, \overline{A_{k - 1}}, A_k\right) = (1 - p)^{k - 1} \cdot p, 1 \le k \le n\]
    Если же ни одно испытание не закончилось успехом, то $T = \infty$, $\P(T = \infty) = (1 - p)^{n}$.

    Рассмотрим случай $n = \infty$.
    Тогда событие <<ни одно испытание не закончилось успехом>> исключается, а сумма вероятностей остальных событий равна 1:
    \[\sum\limits_{k = 1}^{\infty}\P(T = k) = \sum\limits_{k = 1}^{\infty}(1 - p)^{k - 1}p = \frac{1}{1 - (1 - p)}\cdot p = 1\]
    Говорят, что $T$ имеет \emph{геометрическое распределение}.

    На самом деле дискретная теория вероятностей не позволяет создать схему Бернулли со счётным (любым бесконечным) количеством испытаний (при $0 < p < 1$).
    Таким образом, рассматривая случай $n = \infty$, мы ведём себя неформально, в любом случае выходя за рамки дискретной теории вероятностей.

    \provehere[Доказательство невозможности счётной схеме Бернулли в дискретной теории вероятностей]{
        Рассмотрим произвольный элементарный исход $\omega$.
        Если ему соответствует бесконечное число успехов, то для любого $m$ рассмотрим $m$ успешных событий.
        Пусть это какие-то фиксированные $A_{i_1}, \dots, A_{i_m}$. Так как они произошли, то $\P(m) \le p^m$, то есть на самом деле $\P(\omega) = 0$. (В случае бесконечного числа неуспехов опять же можно оценить $\forall m \in \N: \P(\omega) \le (1 - p)^m$).
        Но раз вероятность каждого элементарного исхода равна 0, то они не могут суммироваться в 1, противоречие.
    }
    Это произошло из-за того, что в схеме Бернулли со счётным числом испытаний континуум возможных исходов.

    Чтобы это обойти, можно рассматривать последовательность конечных схем, как в теореме Пуассона, или же просто закрыть на это глаза --- в непрерывной теории вероятностей такое распределение возможно.


    \subsection{Случайные блуждания}
    Введём случайные величины $S_n: S_0 = 0, S_{n + 1} = S_n + X_n$, где $X_n = \all{1, &\text{с вероятностью }p\\-1, &\text{с вероятностью }1 - p}$, и все $\{X_n\}$ независимы.

    Это та же схема Бернулли, просто успехам соответствуют движения в положительную сторону оси, и неуспехам --- в отрицательную.

    Исследуем распределение $S_n$.
    Очевидно, возможные значения $S_n$ --- это $[-n; n]$, причём $k \equiv n \pmod{2}$.

    Событие $\{S_n = k\}$ эквивалентно событию <<$m$ величин равны 1 (остальные -1)>>, где $k = m - (n - m) \then m = \frac{n + k}{2}$.

    Отсюда согласно схеме Бернулли получаем $\P(S_n = k) = \binom{n}{\nicefrac{(n + k)}{2}}p^{\nicefrac{(n + k)}{2}}(1 - p)^{\nicefrac{(n - k)}{2}}$.

    В симметричном случае, при $p = \nicefrac{1}{2}$ формула упрощается, $\P(S_n = k) = \binom{n}{\nicefrac{(n + k)}{2}} \cdot \frac{1}{2^n}$.

    \subsection{Про условные вероятности}
    Вероятность происхождения $A$ при условии $B$: $\P(A | B) = \P_B(A) = \frac{\P(A \cap B)}{\P(B)}$ (при $\P(B) > 0$).

    Применение условных вероятностей:
    \bullets{
        \item Вычисление вероятностей вложенных событий. Пусть $A_1 \supset A_2 \supset \dots A_n$.
        \[\P(A_n) = \P(A_1) \cdot \P(A_2 | A_1) \proddots \P(A_n | A_{n - 1})\]
        \provehere{
            По индукции. \[\P(A_n) \underset{\text{события вложены}}{=} \P(A_n \cap A_{n - 1}) = \P(A_{n - 1}) \cdot \P(A_n | A_{n - 1})\]
        }
        \item Формула полной вероятности
        Пусть вероятностное пространство $\Omega$ разбито на конечное (или счётное) число дизъюнктных события $H_1, \dots, H_n$.
        \pic[0.2]{disjunction}{Разбиение вероятностного пространства}

        Рассмотрим произвольное событие $A \subset \Omega$. \[\P(A) = \sum\limits_{i = 1}^{n}\P(A \cap H_i) = \sum\limits_{i = 1}^{n}\P(A|H_j)\P(H_i)\]
        \item Формула Байеса.
        Пусть вероятностное пространство $\Omega$ разбито на конечное (или счётное) число дизъюнктных события $H_1, \dots, H_n$.
        Теперь мы хотим узнать вероятность $H_i$ для некоего $i$ при условии наступления события $A$.

        Запишем \[\P(H_i | A) \underset{\text{по определению}}{=} \frac{\P(H_i \cap A)}{\P(A)} = \frac{\P(A | H_i) \P(H_i)}{\P(A)} = \frac{\P(A | H_i) \P(H_i)}{\sum\limits_{j = 1}^{n}\P(A | H_i)\P(H_i)}\]
    }


    \section{Матожидание, дисперсия}
    Говорят, что $X$ и $Y$ \emph{одинаково распределены}, если $\forall r \in \R: \P(X = r) = \P(Y = r)$.
    Например, в схеме Бернулли из 6 испытаний случайные величины <<количество успехов на первых 2 испытаниях>> и <<количество успехов на последних 2 испытаниях>> одинаково распределены.

    Если $X$ и $Y$ определены на одном и том же вероятностном пространстве, то можно определить арифметические действия (сумму, произведение\ldots) случайных величин, как соответствующие арифметические действия над отображениями поточечно.

    \definition[Математическое ожидание случайной величины $X$]{
        Обозначается \[\E X \bydef \sum\limits_{\omega \in \Omega}X(\omega)p(\omega)\]
    }
    Математическое ожидание довольно неплохо описывает случайную величину одним числом:~(\ref{best_approximation}).

    После приведения подобных членов, можно записать $\E(X) = \sum\limits_{r}\P(X = r) r$
    Если $\Omega$ конечно, то сумма считается;
    если же $\Omega$ --- бесконечное вероятностное пространство, то матожидание может быть не определено, как сумма бесконечного ряда (тем не менее, сумма всегда существует, если $X$ всегда принимает неотрицательные значения).
    Чтобы было удобно оперировать с матожиданиями, будем считать, что матожидание определено, если и только если ряд сходится \textbf{абсолютно}.

    Чтобы исследовать существование $\E X$, введём функции положительной и отрицательной частей числа:
    \begin{gather*}
        x_+ \bydef \max \{x, 0\} \\
        x_- \bydef \max \{-x, 0\}
    \end{gather*}
    Несложно видеть, что равенство $x = x_+ - x_-$ выполнено всегда.

    Посчитав матожидание положительной и отрицательной частей $X$, $\E(X_+)$ и $\E(X_-)$, можно утверждать, что $\E(X)$ существует, если и только если хотя бы одно из $\E(X_+)$ и $\E(X_-)$ конечно.
    Если же $\E(X_+) = \E(X_-) = +\infty$, то $\E(X)$ не определено.
    (Если ровно одно из $\E(X_+)$ или $\E(X_-)$ бесконечно, то $\E X$ тоже можно мыслить, как бесконечность того или иного знака)

    \subsection{Простейшие свойства матожидания}
    \bullets{
        \item $X \ge 0 \then \E(X) \ge 0$.
        \item $\forall c \in \R: \E(cX) = c \E(X)$.
        \item $\E(X + Y) = \E(X) + \E(Y)$.
        \provehere{
            \begin{gather*}
                \E(X) + \E(Y) = \sum\limits_{r_1}r_1 \P(X = r_1) + \sum\limits_{r_2}r_2 \P(Y = r_2) = \\
                = \sum\limits_{r_1}r_1 \sum\limits_{r_2}\P(X = r_1 \land Y = r_2) + \sum\limits_{r_2}r_2\sum\limits_{r_1} \P(X = r_1 \land Y = r_2) = \\
                = \sum\limits_{r_1, r_2}(r_1 + r_2)\P(X = r_1 \land Y = r_2)\qedhere
            \end{gather*}
        }
        Здесь важно заметить, что $X$ и $Y$ лишь должны быть определены на одном вероятностном событии;\ они не обязаны быть, например, независимы.
        \item $X \ge Y \then \E(X) \ge \E(Y)$.
        Для доказательства можно записать $Y = X + (Y - X)$. Тогда $\E Y = \E X + \E(Y - X)$.
    }

    \examples[Матожидания случайных величин]{
        \item $X$ имеет распределение Бернулли с параметром $p$, записываемое $\mathcal{B}(p)$. Это по определению значит
        \[\all{\P(X = 1) = p \\ \P(X = 0) = 1 - p}\]
        В таком случае $\E X = 1 \cdot \P(X = 1) + 0 \cdot \P(X = 0) = p$.
        \item Пусть $S$ имеет распределение $\mathcal{B}(n, p)$--- число успехов в схеме Бернулли.
        \[\P(S = k) = \binom{n}{k}p^k(1 - p)^{n - k}\]

        Матожидание $S$ можно посчитать по определению: $\E S = \sum\limits_{k = 0}^{n}k\binom{n}{k}p^k(1 - p)^{n - k}$.

        Но это неоправданно сложно.
        Для упрощения работы запишем $S = \1_1 + \dots + \1_n$, где $\1_1, \dots, \1_n$ --- индикаторы событий $A_1, \dots, A_n$ соответственно.
        По определению $\1_i = \all{1, & A_i \text{ успешно} \\ 0,&A_i \text{ неуспешно}}$

        Каждый индикатор по отдельности имеет распределение Бернулли с параметром $p$, таким образом,
        \[\E S = \sum\limits_{i = 1}^{n}\E X_i = n \cdot p\]

        \item Пусть $X$ имеет распределение Пуассона $\mathcal{P}(a)$:
        \[\P(X = k) = e^{-a}\frac{a^k}{k!}\]
        Матожидание такой случайной величины равно \[\sum\limits_{k = 0}^{\infty}ke^{-a}\frac{a^k}{k!} = e^{-a} \cdot a\sum\limits_{k = 1}^{\infty}\frac{a^{k - 1}}{(k - 1)!} = e^{-a} a e^a = a\]
        Оказывается, параметр $a$ в Пуассоновском распределении --- матожидание данной случайной величины.
    }
    \newlection{27 февраля 2023 г.}
    Известно, что $\E(X + Y) = \E(X) + \E(Y)$.
    Верно ли, что $\E(X \cdot Y) = \E(X) \cdot \E(Y)$?

    Выберем в качестве $X$ величину, распределённую по закону $\P(X = 1) = \P(X = -1) = \frac{1}{2}$.

    В качестве $Y$ возьмём эту же случайную величину: $Y = X$.

    Тогда замечаем, что $\E X = 0, \E Y = 0, \E XY = \E X^2 = 1$, равенство не выполняется.
    <<Увы, так устроен мир>>

    К счастью, можно наложить дополнительные условия, а именно, о \textbf{независимости} случайных величин $X$ и $Y$.

    В таком случае формула выполняется: \[\P(X = r_1, Y = r_2) \underset{\text{определение независимости}}{=} \P(X = r_1)\cdot \P(Y = r_2)\]
    откуда
    \[\sum\limits_{r_1, r_2}r_1 r_2 \P(X = r_1, Y = r_2) = \sum\limits_{r_1, r_2}r_1 r_2 \P(X = r_1)\cdot\P(Y = r_2) = \left(\sum\limits_{r_1}r_1\P(X = r_1)\right)\left(\sum\limits_{r_2}r_2\P(X = r_2)\right) = \E X \cdot \E Y\]

    Конечно, можно доказать по индукции формулу для любого конечного числа сомножителей: \[\E\left(X_1 \proddots X_n\right) = \prod\limits_{i = 1}^{n}\E X_i\] для независимых событий $X_1, \dots, X_n$.

    Рассмотрим следующую задачу, показывающее, что матожидание --- число, наилучшим образом приближает случайную величину:
    \problem{\label{best_approximation}
    Дана случайная величина $X: \E X^2 < \infty$.
    Надо найти число $r$, минимизирующее $\E((X - r)^2)$.

    Значит, надо минимизировать $\E\left(X^2 - 2rX + r^2\right) = \E\left(X^2\right) - 2r\E(X) + r^2$.
    Это квадратный трёхчлен по $r$, минимум достигается при $r = \E(X)$.
    }

    \subsection{Неравенства, связанные с математическим ожиданием}
    Пусть $f: \R \map \R$ --- неубывающая неотрицательная функция.

    \fact{\label{expected_value_inequality}
        $\forall X$ --- случайная величина и $\forall r \in \R$ имеет место неравенство:
        \[\P(X \ge r) \le \frac{\E f(X)}{f(r)}\]
        \provehere{
            Рассмотрим вторую функцию $g(x) = \all{0,& x < r \\ f(r),& x \ge r}$.
            Несложно проверить, что $g(x) \le f(x)$.
            Отсюда $g(X) \le f(X)$ ($f(X)$ --- композиция двух функций), и, как следствие, $\E(g(X)) \le \E(f(X))$.
            Но несложно видеть, что $\E(g(X)) = 0 \cdot \P(X < r) + f(r) \cdot \P(X \ge r) = f(r) \cdot \P(X \ge r)$, и неравенство выполнено.
        }
    }
    \bullets{
        \item \up \corollary[Экспоненциальное неравенство Чебышёва]{\label{exponential_Tchebycheff_inequality}
        Рассмотрим $f(x) = e^{\lambda x}$, где $\lambda > 0$.

        Тогда $\P(X \ge r) \le \frac{\E\left(e^{\lambda X}\right)}{e^{\lambda r}}$.

        Более того, здесь возможна более сильная форма --- оптимизация по $\lambda$:
            \[\P(X \ge r) \le \inf\limits_{\lambda > 0}\frac{\E\left(e^{\lambda X}\right)}{e^{\lambda r}}\]
        }
        \item \up \corollary[Неравенство Маркова]{\label{Markoff_inequality}
            $\forall r > 0: \P(|X| \ge r) \le \frac{\E(|X|)}{r}$.
            \provehere{
                Применим неравенство \ref{expected_value_inequality} для $f(x) = \all{x,&x > 0 \\ 0,&x \le 0}$ и случайной величины $|X|$.
                Получим \[\P(|X| \ge r) \le \frac{\E f(|X|)}{r} = \frac{\E |X|}{r}\]
                что и требовалось доказать.
            }
        }
        \item       \up \corollary{\label{Markov-inequality-corollary}
            $\P(|X| \ge r) \le \frac{\E\left(X^2\right)}{r^2}$
            \provehere{
                Следует из предыдущего применением $\P(|X| \ge r) \iff \P(X^2 \ge r^2)$.
            }
            \note{Несмотря на то, что это практически то же, что и выше, в мире случайных величин нам будет удобно оценивать не случайную величину, а её квадрат.}
        }
        \item \up \corollary[Вероятностное неравенство Йенсена]{\label{Jensen_inequality}
        Пусть $X$ --- случайная величина с конечным матожиданием, а $\phi: \R \map \R$ выпукла вниз (как $x^2$).

        Тогда $\E(\phi(X)) \ge \phi(\E X)$. (картинка, где $X$ принимает два значения).
        \provehere{
            Пусть $X$ принимает конечное число значений. Тогда \[\E(\phi(X)) = \sum\limits_{\omega \in \Omega}p(\omega)\phi(X(\omega)) \underset{\text{по неравенству Йенсена}}{\ge} \phi\left(\sum\limits_{\omega \in \Omega}p(\omega)X(\omega)\right) = \phi(\E X)\]

            Если $X$ принимает счётное число значений, то можно устроить предельный переход.
        }
        }
    }

    \subsection{Медиана}
    Ещё одно число, которым можно характеризовать случайную величину --- \emph{медиана}.
    \definition[Медиана случайной величины $X$]{
        Такое число $m$, что $\P(X \ge m) \ge \frac{1}{2}$ и $\P(X \le m) \ge \frac{1}{2}$.
    }
    \numbers{
        \item Можно доказать, что медиана (в отличие от матожидания) всегда существует.
        \item Медиана необязательно единственна.
        Так, в случае случайной величины $X$, распределённой по закону $\P(X = 1) = \P(X = -1) = \frac{1}{2}$ медианой является любое число $m \in [-1, 1]$.
        \item Пусть $X$ --- случайная величина, такая, что $\P(X = -1) = \P(X = 0) = \P(X = 1) = \frac{1}{3}$.
        Единственная медиана --- это $0$, причём $\P(X \ge 0) = \frac{2}{3}$, и $\P(X \le 0) = \frac{2}{3}$ тоже.
        \item На самом деле, медиана --- плохая метрика, которой никто не пользуется.
        Так, только матожидание линейно: медиана суммы вообще не выражается через медианы слагаемых.
        \item \up \intfact{
            Если в задаче \ref{best_approximation} заменить $\E((X - r)^2)$ на $\E(|X - r|)$, то минимизирующим $r$ окажется не матожидание, но медиана.
        }
    }

    \subsection{Дисперсия}
    <<Слово дисперсия знакомо тем, кто имеет дело с садоводством.
    Садоводы используют так называемую дисперсионную краску>>

    Вообще говоря, дисперсия описывает <<меру разброса>> данной случайной величины.

    Пусть $X$ -- случайная величина, такая, что $\E(X^2) < \infty$.
    \definition[Дисперсия $X$]{
        $\D(X) = \E((X - \E(X))^2) = \E(X^2) - (\E X)^2$.
    }
    Докажем эквивалентность двух определений:
    \provehere{
        \[\E(X - \E X)^2 = \E(X^2 - 2X\E X + (\E X)^2) = \E(X^2) - 2\E X \cdot \E X + (\E X)^2 = \E(X^2) - (\E X)^2\qedhere\]
    }
    \note{
        В англоязычных текстах дисперсию обозначают $\text{Var}(X)$ --- от слова Variance.
    }
    \numbers{
        \item $\D(X) \ge 0$, как матожидание неотрицательной величины.
        \item У константы нет дисперсии: $\D(C) = 0$
        \item Из определения очевидно $\D(X + C) = \D X$.
        \item Из определения очевидно $\D(C \cdot X) = C^2\cdot\D(X)$. В частности, $\D(-X) = \D(X)$.
        \item Аддитивность: для \textbf{независимых} случайных величин $X, Y: \D(X + Y) = \D(X) + \D(Y)$.
        \provehere{
            \begin{gather*}
                \D(X + Y) = \E(X + Y)^2 - (\E(X + Y))^2 = \E(X^2 + 2XY + Y^2) - (\E X + \E Y)^2 = \\
                = \left(\E X^2 - (\E X)^2 \right) + \left(\E Y^2 - (\E Y)^2\right) + \underbrace{(2\E(XY) - 2\E X \cdot \E Y)}_{\text{0 из-за независимости}} = \D(X) + \D(Y) \qedhere
            \end{gather*}
        }
        \item Определение дисперсии без вычитания матожидания:
        пусть $X, X'$ независимы и одинаково распределены.

        Тогда $\D X = \frac{1}{2}\E(X - X')^2$.
        \provehere{
            \[\frac{1}{2}\E(X - X')^2 = \frac{1}{2}\E(X^2 + X'^2 - 2XX') = \frac{1}{2}\left(\E X^2 + \E X'^2 - 2(\E X \cdot \E X')\right) = \E X^2 - (\E X)^2\qedhere\]
        }
        \item <<Элементарное, но нетривиальное свойство>>.

        Пусть $f: \R \map \R$ --- $1$-липшицева функция, то есть $|f(x) - f(y)| \le |x - y|$.

        Тогда для любой случайной величины $X: \D(f(X)) \le \D(X)$.
        \provehere{
            Воспользоваться свойством $\D X = \frac{1}{2}\E(X - X')^2$, а также тем, что \\ $(X - X')^2 \ge (f(X) - f(X'))^2$ (поточечно).
        }
        \item \up \fact[Неравенство Чебышёва]{\label{Tchebycheff_inequlity}
        Пусть $X$ --- случайная величина, такая, что ${\D(X) < \infty}$.

        Тогда $\P(|X - \E X| \ge r) \le \frac{\D X}{r^2}$.
        \provehere{
            \[\P(|X - \E X| \ge r) \underset{\text{согласно \ref{Markov-inequality-corollary}}}{\le} \frac{\E(X - \E X)^2}{r^2} = \frac{\D X}{r^2}\qedhere\]
        }
        }
    }
    \note[О единицах измерения]{
        Если случайная величина принимает значения некой размерности (рубли, очки, километры), то матожидание имеет ту же размерность, а дисперсия --- размерности квадрата измеряемой величины.
        Чтобы избавиться от такого неудобства, вводят \emph{среднеквадратическое отклонение}.
    }
    \definition[Среднеквадратическое отклонение случайной величины $X$]{
        $\sigma(X) \bydef \sqrt{\D(X)}$.
    }
    \example{
        Пусть $X$ имеет распределение Пуассона $\mathcal{P}(a)$.

        По формуле $\D(X) = \E(X^2) - (\E X)^2$ получаем, что для вычисления дисперсии надо получить $\E(X^2)$ (нам уже известно, что $(\E X)^2 = a^2$).

        Необыкновенным образом получаем, что легче посчитать $\E(X(X - 1)) = \E(X^2) - \E X$.
        \[\E(X(X - 1)) = \sum\limits_{k = 2}^{\infty}k(k - 1)\frac{a^k}{k!} = a^2\sum\limits_{k = 2}^{\infty}e^{-a}\frac{a^{k -2}}{(k - 2)!} = a^2\]
        Отсюда $\E(X^2) = \E (X(X - 1)) + \E (X) = a^2 + a$, и, наконец, $\D X = \E X^2 - (\E X)^2 = a + a^2 - a^2 = a$.
    }
    \newlection{6 марта 2023 г.}
    Пусть $X, Y$ --- случайные величины.
    \definition[Ковариация $X$ и $Y$] {
        \[\cov(X, Y) = \E(XY) - \E(X)\E(Y) = \E[(X - \E(X))(Y - \E(Y))]\]
    }
    Про ковариацию говорят, что это \emph{мера линейной зависимости} $X$ и $Y$.

    Ковариация билинейна (линейна по обоим аргументам) и симметрична.

    \definition[$X$ и $Y$ некоррелированы] {
        Ковариация $X$ и $Y$ равна 0, т. е. $\E(XY) = \E(X)\E(Y)$.
    }
    В частности, независимые величины с конечным матожиданием модуля некоррелированы.
    Из ковариации следует, что для некоррелированных случайных величин $X, Y: \D(X + Y) =\D(X) + \D(Y)$.

    Когда говорят про некоррелированность случайных величин, то имеют в виду попарную некоррелированность.

    \subsection{Моменты}
    Для $k \in \N$ определяют $k$\emph{-й момент случайной величины} $X$, он по определению равен $\E(X^k)$.
    Для $k = 1$ это матожидание.

    Также определяют $k$\emph{-й центральный момент случайной величины} $X$, он по определению равен $\E(X - \E X)^k$.
    Для $k = 2$ это дисперсия.

    Если в определении звучит слово \emph{абсолютный}, то матожидание берётся от модуля аргумента ($k$-й абсолютный момент, $k$-й абсолютный центральный момент).

    $k$-й момент однороден --- при домножении случайной величины на $c$ он домножается на $c^k$ или $|c|^k$.
    Для чётных $k$ абсолютные моменты совпадают с обычными.


    \section{Законы больших чисел (ЗБЧ)}
    Если сложить много случайных величин, то в сумме получится что-то близкое к сумме их матожиданий.

    \theorem[Закон больших чисел Чебышёва]{
        Пусть $X_1, X_2 \dots, X_n$ --- некоррелированные случайные величины, такие, что $\E X_i^2 < \infty$. Запишем это как $\exists \sigma \in \R: \sup\limits_{i} \D X_i \le \sigma^2$.

        Тогда
        \[\forall \eps > 0: \qquad \P\left(\left|\frac{\sum\limits_{i = 1}^{n}X_i}{n} - \frac{\sum\limits_{i = 1}^{n}\E X_i}{n}\right| > \eps\right)\underset{n \to \infty}\Map 0\]
        \provehere{
            \[\P\left(\left|\frac{\sum\limits_{i = 1}^{n}X_i}{n} - \frac{\sum\limits_{i = 1}^{n}\E X_i}{n}\right| > \eps\right) = \P\left(\left|\sum\limits_{i = 1}^{n}(X_i - \E X_i)\right| > n\eps\right)\]
            Согласно неравенству Чебышёва~(\ref{Tchebycheff_inequlity}), это оценивается следующим образом:
            \[\P\left(\left|\sum\limits_{i = 1}^{n}(X_i - \E X_i)\right| > n\eps\right) \le \frac{\D\left( \sum\limits_{i = 1}^{n}X_i\right)}{(n\eps)^2}\le {\frac{n \sigma^2}{(n \eps)^2} \underset{n \to \infty}\Map 0}\]

        }
    }
    \corollary{
        Пусть $X_1, \dots, X_n$ --- независимые одинаково распределённые случайные величины.

        Если $\E X_i^2 < \infty, \E X_i = a$, то \[\forall \eps > 0: \qquad \P\left(\left|\frac{\sum\limits_{i = 1}^{n}X_i}{n} - a\right| \ge \eps\right) \underset{n \to \infty}\Map 0\]
    }
    \note{
        В заключении следствия ничего не говорится про второй момент величин $X_j$, и, на самом деле, следствие как теорема верно и без оценки $\E X_i^2$ в посылке.
        Это мы докажем через пару лет совсем не тривиальной математикой.
    }
    \corollary[Закон больших чисел Бернулли]{
        Пусть $S_n$ --- число успехов в схеме Бернулли с параметрами $n, p$.
        Тогда \[\forall \eps > 0: \qquad \P\left(\left|\frac{S_n}{n} - p\right| > \eps\right) \underset{n \to \infty}\Map 0\]
    }

    На самом деле, в 1613 году Бернулли доказал закон больших чисел, названный позднее в честь него, используя довольно сложные вычисления.

    Лишь только в 1870 году Чебышёв доказал общий закон больших чисел и следствие из него.

    Докажем полученными средствами теорему из матанализа, не использующую в своей формулировке ничего случайностного.
    \theorem[Вейерштрасс]{
        Пусть $f: [0, 1] \map \R$ --- непрерывная функция.
        Тогда \[\exists \{P_n\}_{n = 1}^{\infty}: \max\limits_{t \in [0, 1]}\left|f(t) - P_n(t)\right| \underset{n \to \infty}\Map 0\]
        \provehere{
            \indentlemma[О математических ожиданиях]{
                Пусть $\{Z_n\}_{n = 1}^{\infty}$ --- последовательность случайных величин, такая, что $\exists a \in \R:$
                \[\forall \eps > 0: \P(|Z_n - a| > \eps) \underset{n \to \infty}\Map 0\]
                Пусть дана функция $f$, заданная в окрестности точки $a$, непрерывная в $a$ и ограниченная неким числом $M \in \R$.

                Тогда $\E (f(Z_n)) \underset{n \to \infty}\Map f(a)$.
            }{%
                \begin{gather*}
                    |\E f(Z_n) - f(a)| = |\E (f(Z_n) - f(a))| \underset{\text{например, по неравенству Йенсена для модуля}}{\le}  \\
                    \le \E|f(Z_n) - f(a)| \le \E\left[\underbrace{|f(Z_n) - f(a)| \cdot \chi_{\{|Z_n - a| \ge \eps\}}}_{\le 2M \cdot \P(|Z_n - a| \ge \eps)} + \underbrace{|f(Z_n) - f(a)| \cdot \chi_{\{|Z_n - a| < \eps\}}}_{\le w(f, a, \eps)}\right]
                \end{gather*}
                где $w(f, a, \eps) = \sup\limits_{|s - a| < \eps}|f(s) - f(a)|$. В силу непрерывности $f$ это сходится к 0 при $s \to 0$.

                Устремив $\eps$ к нулю, получаем, что $\left|\E f(Z_n) - f(a)\right| < \delta(\eps)$, где $\delta(\eps) \underset{\eps \to 0}\Map 0$, $\delta > 0$.

                Левая часть не зависит от $\eps$, получается $|\E f(Z_n) - f(a)| = 0$.
            }
            Рассмотрим последовательность случайных величин $S_n$ --- число успехов в схеме Бернулли с параметрами $(n, p)$, где $p$ --- фиксированное число из $[0, 1]$.

            Согласно закону больших чисел Бернулли $\P\left(\left|\frac{S_n}{n} - p\right| > \eps\right) \underset{n \to \infty}\Map 0$.

            Применим лемму для $p$ и $f$: $\E f\left(\frac{S_n}{n}\right) \underset{n \to \infty}\Map f(p)$.
            Подставим определение матожидания, отсюда \[\sum\limits_{k = 0}^{n}\P(S_n = k)f\left(\frac{k}{n}\right) = \sum\limits_{k = 0}^{n}\binom{n}{k}p^k(1 - p)^{n - k}f\left(\frac{k}{n}\right)\underset{n \to \infty}\Map f(p)\]

            Осталось сказать, что сходимость к $f(p)$ равномерна при всех $p \in [0, 1]$.
            Для этого улучшим оценку: заметим, что из леммы на самом деле следует, что \[\abs{\E f\left(\frac{S_n}{n}\right) - f(p)} \le 2M\cdot\P\left(\abs{\frac{S_n}{n}-p}\le \eps\right) + w(f, p, \eps)\]
        Первое слагаемое оценивается сверху в виде \[2M\cdot\P\left(\abs{\frac{S_n}{n}-p}\le \eps\right) = 2M\cdot\P\left(\abs{S_n-np}\le n\eps\right) \le 2M\frac{np(1 - p)}{(n \eps^2)} \le \frac{2M}{n \eps^2}\]
        Чтобы показать, что $\abs{\E f\left(\frac{S_n}{n}\right) - f(p)} \le \delta$, выберем $\eps > 0$ такой, что $\forall p \in [0, 1]: w(f, p, \eps) < \frac\delta2$ (это можно сделать, так как согласно теореме Кантора непрерывная на отрезке функция равномерно непрерывна), затем выберем настолько большое $n$, что $\frac{2M}{n \eps^2} \le \frac\delta2$.
        }
    }


    \section{Производящие функции}
    Пусть $X$ --- случайная величина, принимающая целые неотрицательные значения.

    \definition[Производящая функция величины $X$]{
        Степенной ряд \[\phi_{X}(z) = \E(z^{X}) = \sum\limits_{k = 0}^{\infty}\P(X = k)z^k\]
    }
    Так как $\sum\limits_{k = 0}^{\infty}$, то ряд сходится при $|z| \le 1$.

    При рассмотрении производящих функций мы будем брать аргументы $z \in [0, 1]$.

    Заметим, что $\phi_{X}(0) = \P(X = 0)$, $\phi_{X}(1) = 1$, а сама функция неубывает и выпукла вниз (как $x^2$).
    Это следует из того, что $\phi_{X}(z)$ --- линейная стандартных мономов, каждый из которых неубывает и выпуклый вниз.

    Если $X$ и $Y$ независимы, то $\phi_{X + Y}(z) = \phi_{X}(z)\phi_{Y}(z)$.
    \provehere{
        \[\phi_{X + Y}(z) = \E(z^{X + Y}) = \E(z^{X} \cdot z^{Y}) \underset{\text{$X$ и $Y$ независимы}}{=} \E(z^X) \cdot \E(z^Y) = \phi_{X}(z) \cdot \phi_{X}(z)\]
    }
    \newlection{13 марта 2023 г.}
    Обобщим данную формулу.
    \numbers{
        \item Пусть $X_1, \dots, X_n$ независимы.
        Тогда $\phi_{S_n}(z) = \prod\limits_{j = 1}^{n}\phi_{X_j}(z)$, где $S_n \coloneqq \sum\limits_{j = 1}^{n}X_j$ --- тоже случайная величина.
        \item В частности, если $X_1, \dots, X_n$ независимы и одинаково распределены, то $\phi_{S_n}(z) = \phi_{X_1}(z)^n$.
        \item Пусть $X_1, \dots, X_n, \dots$ --- независимы (независимо любое конечное подмножество) и одинаково распределены.
        Пусть $N \in \N_0$ --- случайная величина (формальнее, $N: \Omega \map \N_0$, где $\Omega$ --- вероятностное пространство), не зависящая от всех $X$-ов.

        Положим $S \coloneqq \sum\limits_{i = 1}^{N}X_i$.

        Тогда $\phi_{S}(z) = \phi_{N}(\phi_{X_1}(z))$.

        \note{
            Предыдущий пункт --- частный случай данного.
            В самом деле, для неслучайной величины $N$, всегда равной $n$, производящая функция равна $z^n$.
        }
        \provehere{
            \[\phi_{S}(z) = \sum\limits_{k = 0}^{\infty}\P(S = k)z^k = \sum\limits_{k = 0}^{\infty}\sum\limits_{n = 0}^{\infty}\P(S = k, N = n)z^k = \P(S_n = k, N = n)z^k = \]
            Воспользуемся независимостью, продолжив равенство
            \begin{gather*}
                = \sum\limits_{k = 0}^{\infty}\sum\limits_{n = 0}^{\infty}\P(S_n = k)\P(N = n)z^k = \sum\limits_{n = 0}^{\infty}\P(N = n)\underbrace{\sum\limits_{k = 0}^{\infty}\P(S_n = k)z^k}_{\phi_{S_n}(z)} =\\
                = \sum\limits_{n = 0}^{\infty}\P(N = n) \cdot \phi_{X_1}(z)^n = \phi_S(\phi_{X_1}(z))
            \end{gather*}
        }
    }

    \subsection{Производящие функции и моменты}
    \proposal{
        $\phi_{X}^{(k)}(1) = \E\left(X(X - 1)\proddots(X - k + 1)\right)$.

        В частности, для $k = 1: \phi_{X}'(1) = \E X$;\qquad
        для $k = 2: \phi_{X}''(1) = \E(X(X - 1)) = \E X^2 - \E X$.

        \provehere{
            Докажем для $k = 1$.

            Формально продифференцировав ряд, получаем $\phi_{X}'(z) = \left(\sum\limits_{k = 0}^{\infty}\P(X = k)z^k\right)' = \sum\limits_{k = 1}^{\infty}\P(X = k)k \cdot z^{k - 1}$.
            При подстановке $z = 1$ действительно получается $\E X$, но надо обосновывать, почему производная ряда в граничной точке круга сходимости равна сумме производных слагаемых ряда.
        }
        \provehere[Другой вариант доказательства]{
            Данный вариант тяжелее в смысле выкладок, но легче --- в смысле теорем, на которые опирается доказательство.

            Рассмотрим $z \in (0, 1)$, близкое к единице.
            \[\frac{\phi_{X}(1) - \phi_{X}(z)}{1 - z} = \frac{1 - \phi_{X}(z)}{1 - z} = \frac{1 - \sum\limits_{k = 0}^{\infty}\P(X = k)z^k}{1 - z} = \sum\limits_{k = 0}^{\infty}\P(X = k)\frac{1 - z^k}{1 - z}\]
            По теореме Коши найдутся точки $\tilde{z}_k \in (z, 1)$, такие, что $\frac{1 - z^k}{1 - z} = k\tilde{z}_k^{k - 1}$.

            Отсюда получаем оценку $\frac{\phi_{X}(1) - \phi_{X}(z)}{1 - z} \le \sum\limits_{k = 0}^{\infty}\P(X = k) \cdot k$ (пользуемся тем, что все $\tilde{z}_k \le 1$).
            В пределе $\phi_{X}'(X)\le \sum\limits_{k = 0}^{\infty}\P(X = k) \cdot k$.

            Чтобы получить оценку с другой стороны, заменим сумму на конечную, совершим предельный переход, получим $\phi_{X}'(X) \ge \sum\limits_{k = 0}^{K}\P(X = k)\cdot k \cdot \tilde{z}^{k - 1}$.
            Устремив $z$ к единице, получаем оценку $\phi_{X}'(X) \ge \sum\limits_{k = 0}^{K}\P(X = k)\cdot k$, затем можно перейти к предельному переходу по $K \to \infty$.
        }
    }
    \note{
        Производная бесконечна $\iff$ матожидание бесконечно.
    }


    \section{Ветвящиеся процессы}

    \subsection{Процесс Гальтона-Ватсона}
    График: в момент времени $t = 0$ есть частица (человек, электрон), которая в каждый момент времени порождает случайное число потомков.

    Получается, если можно так выразиться, дерево.
    Будем считать, что числа потомков у каждой частицы --- независимые одинаково распределённые случайные величины.

    Гальтон и Ватсон интересовались генеалогией знатных родов, но потом внезапно оказалось, что процесс прекрасно описывает ядерные реакции.

    \definition[Процесс Галтона-Ватсона]{
        Пусть $(X_{n,j})_{n \ge 0, j \ge 1}$ --- независимые одинаково распределённые случайные величины.

        Последовательность случайных величин определяется формулой $M_0 = 1, \quad M_{n + 1} = \sum\limits_{j = 1}^{M_n}X_{n,j}$ и называется \emph{ветвящимся процессом}.
    }
    Согласно рекурсивной формуле, $M_n$ не зависит от $X_{n,1}, X_{n, 2}, \dots$.

    Значит, $\phi_{M_{n + 1}}(z) = \phi_{M_n}(\phi_X(z))$, где $\phi_{X}$ --- производящая функция любой из величин $X_{n,j}$.

    Получаем $\phi_{M_0}(z) = z, \phi_{M_1}(z) = \phi_{X}(z), \phi_{M_2}(z) = \phi_{X}(\phi_{X}(z))$.
    Вообще, $\phi_{M_n}(z) = \phi_{X}^{\circ n}(z)$.

    \subsubsection{Задача о выживании и вырождении ветвящегося процесса}
    Определим вероятность того, что на $n$-м шаге процесс не выжил $q_n = \P(M_n = 0)$.

    Очевидно, $q_{n + 1} \ge q_n$, так как если процесс выродился, то так потом и будет, но он может выродиться на $n + 1$-м шаге впервые.

    Так как $q_n \le 1$, то последовательность $\{q_n\}_{n \in \N}$ имеет предел $q$.

    Говорят, что \emph{процесс вырождается}, если $q = 1$.

    \ok
    Нарисуем график $\phi_X(z)$ при $z \in [0, 1]$.
    \proposal{
        $q$ --- наименьший корень уравнения $\phi_X(z) = z$.
        \provehere{
            Рассмотрим $M$ --- множество корней уравнения. $1 \in M$, $M$ замкнуто --- прообраз нуля некоторого непрерывного отображения.

            Отсюда следует, что в $M$ существует наименьший элемент $z_*$.

            Так как $q_n = \P(M_n = 0) = \phi_{M_n}(0) = \phi_X^{\circ n}(0)$, то $q_{n + 1} = \phi_X^{\circ n + 1}(0) = \phi_X(q_n)$.

            Запишем $0 \le z_*$, откуда $\phi_X(0) \le \phi_X(z_*) = z_*$.
            Так можно применять много раз, получаем $\forall n \in \N: \phi_X^{\circ n}(0) \le z_*$.

            Перейдя к пределу у $q_{n + 1} = \phi_X(q_{n})$ получаем $q = \phi_X(q)$.

            Используя $q \le z_*$ и $\phi_X(q) = q$, получаем $q = z_*$.
        }
    }
    \ok
    Обозначим $m = \E X$ --- среднее число потомков частицы.
    \theorem{
        Процесс $M_n$ не вырождается $\iff$ либо $m > 1$, либо $X = 1$ всегда, то есть $X$ --- величина неслучайная.
        \provebullets{
            \item Рассмотрим $m > 1$.
            При $z$, близком к единице, $\phi_X(z) = 1 - m(1 - z) + o(1 - z)$, что при $z$ достаточно близких к 1 меньше $z$.

            Таким образом, нашлась точка $z: \phi_X(z) < z$.
            С другой стороны, $\phi_X(0) \ge 0$, значит, существует корень уравнения $\phi_X(z) = z$, строго меньший единицы.
            Отсюда следует, что процесс не вырождается.

            \item Рассмотрим $m < 1$.
            Функция $\phi_X(z)$ выпукла вниз, поэтому $\forall z \in [0, 1]: \phi_X(z) \ge 1 + m(z - 1)$.

            Таким образом, единственный корень уравнения $\phi_X(z) = z$ --- $z = 1$.
            \item Рассмотрим $m = 1$.
            Касательная прямая к $\phi_X(z)$ проходит по диагонали $y = z$.

            Рассмотрим наименьший корень уравнения $\phi_X(z) = z$. Есть варианты:
            \numbers{
                \item Касание единицы происходит только в самом конце: $\phi_X(z) > z$ для $z < 1$.
                Это случай вырождения процесса.

                \item $\forall z \in [0, 1]: \phi_X(z) = z$.
                Процесс не вырождается, $X_{n,j} = 1$ всегда.

                \item Остался один случай, которого не бывает.
                Для некоего $a \in (0, 1)$, совпадение $\phi_X(z) = z$ происходит только при $z \in [a, 1]$.

                На самом деле, с производящими функциями такое невозможно: если $\phi_X(z) = z$ в окрестности 1, то $\phi_X''(1) = 0$.

                Но $\phi_X''(1) = \E(X(X - 1)) = \E X^2 - \E X$, а мы знаем, что $\E X = 1$.
                Получается, $\E X^2 = 1$, и дисперсия этой величины нулевая: $\D X = \E X^2 - (\E X)^2 = 0$.
                Таким образом, $X$ --- величина неслучайная.

            }
        }
    }

    \subsection{Некоторые другие виды процессов}

    \subsubsection{Процессы Беллмана-Харриса}
    Отличие от процессов Гальтона-Ватсона состоит в том, что каждый субъект живёт случайное время.
    В конце своего жизненного времени частица распадается на случайное количество частиц.

    \subsubsection{Многотиповые процессы}
    Распределение числа потомков зависит от типа данной частицы: синяя частица порождает либо два синие, либо две красные, а красная -- одну жёлтую, и, возможно, одну зелёную.

    \subsubsection{Процессы с иммиграцией}
    На каждом поколении число частиц меняется каким-то фиксированным образом --- частицы <<прибывают откуда-то снаружи>>.


    \section{Предельные теоремы Муавра-Лапласа}

    \subsection{Локальная}
    Запишем число успехов в схеме Бернулли $\mathcal{B}(n, p)$.
    Зафиксируем $p$ и изучим $\P(S_n = k)$ для <<типичных>> значений $k$ при $n \to \infty$.

    Вспомним, что $\E S_n = np$, $\D S_n = n p (1 - p)$ для любого $n \in \N$.

    Так как дисперсия --- это квадрат <<типичного отклонения>>, то для некой константы $C$ величина $S_n$ должна часто отклоняться от своего матожидания не больше, чем на $C\sqrt{n}$.
    \definition[Последовательности $A_{n,k}$ и $B_{n,k}$ равномерно эквивалентны при $n \to \infty$ на некоторой области $k \in C_n$]{
        \[\max\limits_{k \in C_n}\left|\frac{A_{n,k}}{B_{n,k}} - 1\right| \underset{n \to \infty}\Map 0\]
    }
    \theorem[Локальная предельная теорема Муавра-Лапласа]{
        Локальность означает, что в рассмотрении находится фиксированное $k$.

        Пусть последовательность $\eps_n$ стремится к нулю.
        Утверждается, что
        \[\P(S_n = k) \sim \frac{1}{\sqrt{2 \pi n p (1 - p)}} \cdot \exp\left\{-\frac{(k - np)^2}{2p (1 - p)n}\right\}\]
        равномерно по области $\bigdefset{k \in \N}{|k - np| \le \eps_n \cdot n^{\nicefrac{2}{3}}}$.
        <<Название теоремы --- историческое недоразумение. Теорему Муавра-Лапласа доказал Муавр, а Лаплас --- лишь включил её в свой учебник.
        Впрочем, к распространению этой теоремы он всё-таки имел какое-то отношение>>
        \provehere{
            Запишем \gather{\P(S_n = k) = \binom{n}{k}p^k (1 - p)^{n -k} = \frac{n!}{(n - k)!k!}p^k (1 - p)^k\\
            \frac{n!}{(n - k)!k!}p^k (1 - p)^k \sim \frac{(\nicefrac{n}{e})^n \sqrt{2 \pi n} \cdot p^k (1 - p)^{n - k}}{(\nicefrac{(n - k)}{e})^{n - k} \sqrt{2 \pi (n - k)} \cdot (\nicefrac{k}{e})^k \sqrt{2 \pi k}} \sim \frac{n^n p^k (1 - p)^{n - k}}{\sqrt{2 \pi np(1 - p)}\cdot(n - k)^{n - k}k^k}}
            Преобразовав ещё чуть-чуть выражение, получаем
            \[\frac{1}{\sqrt{2 \pi np(1 - p)}} \cdot \frac{n^n p^k (1 - p)^{n - k}}{(n - k)^{n - k}k^k} = \frac{1}{\sqrt{2 \pi np(1 - p)}} \cdot \left(\frac{np}{k}\right)^k \cdot \left(\frac{n(1 - p)}{n - k}\right)^{n - k}\]
            Определим новую переменную $v$ таким образом: $k = np + v$.
            В таком случае $\left(\frac{k}{np}\right)^k = \left(\frac{np + v}{np}\right)^{np + v} = \left(1 + \frac{v}{np}\right)^{np + v} = \exp\left(\log\left(1 + \frac{v}{np}\right)(np + v)\right)$.
            Разложим $\log$ в ряд с точностью до второго члена: $\exp\left(\left(\frac{v}{np} - \frac{v^2}{2 (np)^2} + \bigO\left(\frac{v^3}{(np)^3}\right)\right)\left(np + v\right)\right) = \exp\left(v - \frac{v^2}{2np} + \frac{v^2}{np} - \frac{v^3}{2(np)^2}+ \bigO\left(\frac{v^3}{(np)^2}\right)\right) = \exp\left(v + \frac{v^2}{2 np} + o(1)\right)$
            Слагаемое под $\bigO$ стремится к нулю, так как $|v| \le \eps_n \cdot n^{\nicefrac{2}{3}}$ по условию на рассматриваемую область $k$.

            Таким образом, $\left(\frac{np}{k}\right)^k = \exp\left(-(k-np) - \frac{(k-np)^2}{2 np} + o(1)\right)$.
            Аналогично (подставив $p \leftrightsquigarrow (1 - p); k \leftrightsquigarrow (n - k); v \leftrightsquigarrow -v$) получаем $\left(\frac{n(1 - p)}{n - k}\right)^{n - k} = \exp\left(-(np-k) - \frac{(np-k)^2}{2 n(1 - p)} + o(1)\right)$

            Перемножив, получаем \[\left(\frac{np}{k}\right)^k \cdot \left(\frac{n(1 - p)}{n - k}\right)^{n - k} = \exp\left\{- \frac{(k-np)^2}{2n}\left(\frac{1}{p} + \frac{1}{1 - p}\right) + o(1)\right\} = \exp\left\{- \frac{(np-k)^2}{2np(1-p)}\right\} + o(1)\]
        }
    }

    \subsection{Интегральная}
    Что можно сказать о вероятности попадания числа успехов в определённый интервал?

    \theorem[Интегральная теорема Муавра-Лапласа]{
        Пусть $a < b$.\[\P\left(S_n \in \left[np + a \sqrt{p(1 - p)n}; np + b\sqrt{p(1 - p)n}\right]\right) \sim \frac{1}{\sqrt{2\pi}}\int\limits_{a}^{b}e^{-\frac{x^2}{2}}\d x\]
        Вероятность переписывается в виде $\P\left(a \le \frac{S_n - np}{\sqrt{p (1 - p)n}} \le b\right) = \P\left(a \le \frac{S_n - \E S_n}{\sqrt{\D S_n}}\le b\right)$
        \provehere{
            \[\P\left(S_n \in \left[np + a \sqrt{p(1 - p)n}; np + b\sqrt{p(1 - p)n}\right]\right) = \sum\limits_{k \in \left[np + a \sqrt{p(1 - p)n}; np + b\sqrt{p(1 - p)n}\right]}\P(S_n = k)\]
            Так как $k - np \sim \bigO\left(\sqrt{n}\right)$, то все последующие оценки равномерны по $k$.
            \[\sum\limits_{k }\P(S_n = k) \sim \sum\limits_{k}\frac{1}{\sqrt{2 np(1 - p)}}\exp\left\{-\frac{(k - np)^2}{2p(1 - p)n}\right\}\]

            Слагаемые в сумме можно заменить на эквивалентные, так как оценка равномерна.
            Заменим сумму интегралом: для начала покажем
            $\frac{1}{\sqrt{2 np(1 - p)}}\exp\left\{-\frac{(k - np)^2}{2p(1 - p)n}\right\} \sim \int\limits_{k}^{k + 1}\frac{1}{\sqrt{2 np(1 - p)}}\exp\left\{-\frac{(x - np)^2}{2p(1 - p)n}\right\}\d x$.
            Покажем корректность этой эквивалентности, заменив $x = k + \theta$.
            $\frac{1}{\sqrt{2 np(1 - p)}}\exp\left\{-\frac{(x - np)^2}{2p(1 - p)n}\right\} = \frac{1}{\sqrt{2 np(1 - p)}}\exp\left\{-\frac{(k - np)^2 + 2(k - np)\theta + \theta^2}{2p(1 - p)n}\right\}$
            Так как $(k - np)\theta = \bigO\left(\sqrt{n}\right)$, то этими слагаемыми действительно можно пренебречь --- знаменатель порядка $n$, эти слагаемые --- $o(1)$.
            \[\sum\limits_{k }\P(S_n = k) \sim \int\limits_{np + a\sqrt{n p(1 - p)}}^{np + b\sqrt{n p (1 - p)}} \frac{1}{\sqrt{2 \pi n p (1 -p)}} \exp\left(-\frac{(x - np)^2}{2n p (1 - p)}\right)\d x + o(1)\]
            Сделаем замену переменной: $u = \frac{x - np}{\sqrt{n p(1 - p)}}$. Тогда $\d u = \frac{\d x}{\sqrt{n p (1 - p)}}$.

            Интеграл упрощается до $\frac{1}{\sqrt{2 \pi}}\int\limits_{a}^{b}\exp\left(-\frac{u^2}{2}\right)\d u$
        }
    }
    \corollary{
        \[\P\left(S_n \le np + b \sqrt{np (1 - p)}\right) \underset{n \to \infty}\Map \frac{1}{\sqrt{2 \pi}} \int\limits_{-\infty}^{b}e^{-\frac{x^2}{2}}\d x\]
        \provebullets{
            \item Докажем, что $\lim\limits_{n \to \infty}\P(S_n < np) = \frac{1}{2}$.
            Для этого покажем $\forall \eps > 0: \abs{\lim\limits_{n \to \infty}\P(S_n < np) - \frac{1}{2}} \le \eps$.

            Воспользуемся тем, что $\frac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^{+\infty}e^{-\frac{x^2}{2}}\d x = 1$.
            Значит, найдётся $M > 0$:
            \[\frac{1}{\sqrt{2\pi}}\int\limits_{-M}^{0}e^{-\frac{x^2}{2}}\d x = \frac{1}{\sqrt{2\pi}}\int\limits_{0}^{+M}e^{-\frac{x^2}{2}}\d x \ge \frac12 - \eps\]
            Отсюда
            \gather{
                \P\left(np - M\sqrt{np(1 - p)} \le S_n < np\right) \le \P(S_n < np) \le 1 - \P\left(np \le S_n \le np + M\sqrt{np(1 - p)}\right)\\
                \downarrow n \to \infty\\
                \int\limits_{-M}^{0}e^{-\frac{x^2}{2}}\d x \le \lim\limits_{n \to \infty}\P(S_n < np) \le 1 - \int\limits_{0}^{M}e^{-\frac{x^2}{2}}\d x
            }

            \item Теперь осталось посчитать $\P\left(S_n \le np + b\sqrt{np(1 - p)}\right)$.
            Без потери общности $b \ge 0$, тогда
            \multline{\P\left(S_n \le np + b\sqrt{np(1 - p)}\right) = \P(S_n < np) + \P\left(np \le S_n \le np + b\sqrt{np(1 - p)}\right) \underset{n \to \infty}\Map\\\Map \frac{1}{2} + \frac{1}{\sqrt{2\pi}}\int\limits_{0}^{b}e^{-\frac{x^2}{2}}\d x = \frac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^{b}e^{-\frac{x^2}{2}}\d x}
%            Обозначим $q_n = \P\left(S_n \le np + b\sqrt{np(1 - p)}\right)$.
%            Посчитав в схеме Бернулли не количество успехов, а количество неуспехов, получаем \[q_n = \P\left(n - S_n \le n(1 - p) + b\sqrt{np(1 - p)}\right) = \P(S_n \ge np - b\sqrt{np(1 - p)})\]
%
%            Таким образом, можно записать $q_{n,p} + q_{n,1-p} = 1 + \P\left(np - b\sqrt{np(1 - p)} \le S_n \le np + b\sqrt{np(1 - p)}\right)$.
%
%        Используя интегральную теорему Муавра-Лапласа, получаем
%        \[2q_{n,p} \sim \]
%
%
%            Пусть \[F(n, a)\coloneqq \frac{\P\left(S_n \in \left[np + a \sqrt{p(1 - p)n}; np + b\sqrt{p(1 - p)n}\right]\right)}{\frac{1}{\sqrt{2\pi}}\int\limits_{a}^{b}e^{-\frac{x^2}{2}}\d x}\]
%            Разложим $F$ в произведение: \[F(n, a) = \frac{\P\left(S_n \in \left[np + a \sqrt{p(1 - p)n}; np + b\sqrt{p(1 - p)n}\right]\right)}{\P\left(S_n \le np + b\sqrt{p(1 - p)n}\right)}\cdot \frac{\P\left(S_n \le np + b\sqrt{p(1 - p)n}\right)}{\frac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^{b}e^{-\frac{x^2}{2}}\d x}\cdot\frac{\int\limits_{-\infty}^{b}e^{-\frac{x^2}{2}}\d x}{\int\limits_{a}^{b}e^{-\frac{x^2}{2}}\d x}\]
%
%            Покажем, что есть предел $\lim\limits_{(n, a) \to (\infty, -\infty)}F(n, a)$.
%            \bullets{
%                \item Согласно неравенству Чебышёва
%                \[\frac{\P\left(S_n \in \left[np + a \sqrt{p(1 - p)n}; np + b\sqrt{p(1 - p)n}\right]\right)}{\P\left(S_n \le np + b\sqrt{p(1 - p)n}\right)} - 1 \le  \frac{\P\left(|S_n - np| \ge a\sqrt{p(1 - p)n}\right)}{\P\left(|S_n - np| \le b\sqrt{p(1 - p)n}\right)} \le \frac{\frac{1}{a^2}}{1 - \frac{1}{b^2}}\]
%                откуда первый множитель стремится к 1 равномерно по $n$.
%                \item Третий множитель не зависит от $n$, стремится к 1 (при $a \to -\infty$) равномерно по $n$.
%                \item Второй множитель не зависит от $a$;\ так как $\lim\limits_{n \to \infty}F(n, a) = 1$, то (учитывая предыдущие два пункта) этому множителю ничего не остаётся, кроме как стремиться к 1.
%            }
%            Таким образом, согласно теореме о перестановке пределов, каждый множитель стремится к 1 при $(n, a) \to (\infty, -\infty)$.
%            В том числе, $\lim\limits_{n \to \infty}\lim\limits_{a \to -\infty}F(n, a) = 1$.
        }
    }
    \intfact{
        Интеграл в правой части описывает нормальное распределение, он не берётся.
    }
    Теорема Леви <<выросла>> из интегральной теоремы Муавра-Лапласа.
    \intfact[Теорема Леви]{
        Пусть $X_1, \dots, X_n, \dots$ --- независимо распределённые случайные величины, $S_n \coloneqq X_1 + \dots + X_n$.
        Предположим, что $\E X_j^2 < \infty$ для любого $j$.

        Тогда для $\forall a < b: \P\left(a \le \frac{S_n - \E S_n}{\sqrt{\D S_n}}\le b\right) \underset{n \to \infty}\Map \frac{1}{\sqrt{2 \pi}}\int\limits_{a}^{b}e^{-\frac{x^2}{2}}\d x$.
    }
    \newlection{22 марта 2023 г.}


    \section{Цепи Маркова}
    Лекция пропущена.
    \newlection{27 марта 2023 г.}


    Было: $\mathcal{X}$ --- множество состояний. $X_0, X_1, \dots, \in \mathcal{X}$.
    $\pi_n(x) = \P(X_n = x), x \in \mathcal{X}$.
    Вероятность перехода $p(x \to y) = \P(X_{n + 1} = y | X_n = x)$.
    $\pi_0, p$ определяют состояние цепи. $\P(X_0 = x_0, \dots, X_n = x_n) = \pi_0 p(x_0 \to x_1) \proddots$
    $\pi_n = \pi_0 \cdot p^n$.

    \subsection{Инвариантные (стационарные) распределения}
    \definition[Распределение на множестве $\mathcal{X}$]{Такое отображение $\pi: \mathcal{X} \map [0, 1]$, что $\sum\limits_{x \in \mathcal{X}} \pi(x) = 1$.   }
    \definition[Инвариантное распределение]{Такое распределение $\pi$, что $\pi \cdot p = \pi$.}

    $\forall y \in \mathcal{X}: \pi(y) = \sum\limits_{x \in \mathcal{X}}\pi(x)p(x \to y)$.

    Если $\pi_0$ инвариантно, то $\forall n \ge 0: \pi_n = \pi \cdot p^n = \pi_0$.
    Следует из ассоциативности умножения матриц.

    \examples{
        \item <<Хороший пример>>: блуждание по конечному неориентированному графу.

        Обозначим за $E$ общее число рёбер, $\deg x$ --- число рёбер, инцидентных $x$. Очевидно. $\sum\limits_{x \in \mathcal{X}}\deg x = 2E$.

        Рассмотрим цепь Маркова, где $\forall y: p(x \to y) = \all{\frac{1}{\deg x},& \exists (x, y) \\ 0,  & \nexists (x, y)}$.

        Выберем распределение $\pi(x) = \frac{\deg(x)}{2 E}$. Покажем, что оно инвариантно:
        \[\frac{\deg(y)}{2 E} = \pi(y) = \sum\limits_{x \in \mathcal{X}}\pi(x)p(x \to y) = \sum\limits_{x \in \mathcal{X}, \exists (x, y)}\frac{\deg(x)}{2E} \cdot \frac{1}{\deg x} = \sum\limits_{x \in \mathcal{X}, \exists (x, y)}\frac{1}{2E} = \frac{\deg y}{2E}\]
        \item <<Плохой пример>>:
        случайное блуждание на множестве целых чисел $\Z$. Вероятности перехода $p(n \to n + 1) = p(n \to n - 1) = \frac{1}{2}$.

        Граф бесконечный. и это всё разрушает. Поищем инвариантное распределение. Пусть это $\pi$.

        Тогда $\pi(y) = \frac{1}{2}(\pi(y - 1) + \pi(y + 1))$. Отсюда можно выразить $\forall y \in \Z: \pi(y) = \pi(0) + k y$, где $k$ --- некая константа.
        Несложно видеть, что во всех трёх случаях ($k < 0, k > 0, k = 0$) $\pi$ не является распределением.

        Таким образом, для случайного блуждания на $\Z$ нет инвариантного распределения.
    }
    \theorem[Марков]{\label{Markoff_theorem}
    Пусть $\mathcal{X}$ --- конечная цепь, причём вероятность любого перехода ненулевая: ${\delta \coloneqq \min\limits_{x, y \in \mathcal{X}}p(x \to y) > 0}$.

    Тогда $\exists \pi$ --- такое распределение, что \begin{equation}
                                                         \label{eq:star}\forall x, y \in \mathcal{X}, n \in \N: |p^n(x \to y) - \pi(y)| \le (1 - \delta)^n
    \end{equation}

        При этом $\pi$ --- единственное инвариантное распределение цепи. Любое начальное распределение $\pi_0$ влечёт $\pi_n \underset{n \to \infty}\Map \pi$.
        \provehere{
            В предположении истинности~\eqref{eq:star} получаем \[\pi_n(y) = (\pi_0 p^n)(y) = \sum\limits_{x \in \mathcal{X}}\pi_0(x)p^n(x \to y) \underset{n \to \infty}\Map \underbrace{\left(\sum\limits_{x \in \mathcal{X}}\pi_0(x)\right)}_{1} \pi(y) = \pi(y)\]
            Предположим, что $\tilde{\pi}$ --- произвольное инвариантное распределение. Рассмотрим цепь для $\pi_0 = \tilde{\pi}$.
            С одной стороны, в таком случае $\forall n \in \N: \pi_n = \tilde{\pi}$. С другой стороны, $\pi_n \underset{n \to \infty}\Map \pi$.
            Значит, $\tilde{\pi} = \pi$. Таким образом, все инвариантные распределения совпадают с $\pi$.

            Теперь докажем что-то. Запишем в координатном виде $p^{n+1} = p^n \cdot p$.
            \begin{gather*}
                p^{n + 1}(x \to y) = \sum\limits_{z \in \mathcal{X}}p^n(x \to z)p(z \to y)\\
                \downarrow n \to \infty\\
                \pi(y)  =  \sum\limits_{z \in \mathcal{X}}\pi(z)p(z \to y)
            \end{gather*}
        Интересно, что мы доказали?

            Покажем, что $\pi$ --- распределение, то есть сумма $\sum\limits_{x \in \mathcal{X}}\pi(x) = 1$. Для любого фиксированного $x \in \mathcal{X}$\[1 = \sum\limits_{y \in \mathcal{X}}p^n(x \to y) \underset{n \to \infty}\Map \sum\limits_{y \in \mathcal{X}}\pi(y)\]
            \ok
            Осталось доказать~\eqref{eq:star}.
            Зафиксируем $y \in \mathcal{X}$. Рассмотрим последовательности ${m_n = \min\limits_{x \in \mathcal{X}}p^n(x \to y)}$ и $M_n = \max\limits_{x \in \mathcal{X}}p^n(x \to y)$.

            $m_n$ неубывает, $M_n$ невозрастает:
            \[p^{n + 1}(x \to y) = \sum\limits_{z \in \mathcal{X}}p(x \to z)p^n(z \to y)\]
            Так как $p^n(z \to y) \in [m_n, M_n]$, то $p^{n + 1}(x \to y)$, как барицентрическая комбинация таких вероятностей, тоже лежит в $[m_n, M_n]$. Отсюда действительно $m_n$ неубывает, $M_n$ невозрастает.

            Ещё докажем их сближение: $(M_{n + 1} - m_{n + 1}) \le (1 - \delta)(M_n - m_n)$:
            Выберем такие $x_1, x_2$, что максимум и минимум достигаются: $M_{n + 1} = p^{n+1}(x_1 \to y), m_{n + 1} = p^{n + 1}(x_2 \to y)$.
            \[M_{n+1} - m_{n + 1} = p^{n + 1}(x_1 \to y) - p^{n + 1}(x_2 \to y) = \sum\limits_{z \in \mathcal{X}}[p(x_1 \to z) - p(x_2 \to z)]p^n(z \to y)\]
            Оценим эту сумму следующим образом:
            \[\sum\limits_{z \in \mathcal{X}}[p(x_1 \to z) - p(x_2 \to z)]p^n(z \to y) \le \sum\limits_{z \in \mathcal{X}}[p(x_1 \to z) - p(x_2 \to z)]_+ M_n - \sum\limits_{z \in \mathcal{X}}[p(x_1 \to z) - p(x_2 \to z)]_- m_n\]
            Покажем равенство \[ \sum\limits_{z \in \mathcal{X}}[p(x_1 \to z) - p(x_2 \to z)]_+ = \sum\limits_{z \in \mathcal{X}}[p(x_1 \to z) - p(x_2 \to z)]_-\]
            Это верно, так как \gather{ \sum\limits_{z \in \mathcal{X}}[p(x_1 \to z) - p(x_2 \to z)]_+  - \sum\limits_{z \in \mathcal{X}}[p(x_1 \to z) - p^n(x_2 \to z)]_- =\\
            \sum\limits_{z \in \mathcal{X}}(p(x_1 \to z) - p(x_2 \to z)) = \sum\limits_{z \in \mathcal{X}}p(x_1 \to z) - \sum\limits_{z \in \mathcal{X}}p(x_2 \to z) = 1 - 1 = 0
            }
            Таким образом \[M_{n + 1} - m_{n + 1} \le \sum\limits_{z \in \mathcal{X}}[p(x_1 \to z) - p(x_2 \to z)]_+(M_n - m_n)\]
            Если все слагаемые $[p(x_1 \to z) - p(x_2 \to z)]_+$ равны нулю, то доказывать нечего.
            Иначе найдётся положительное слагаемое $p(x_1 \to z) - p(x_2 \to z) > 0$.
            Согласно определению $\delta: p(x_1 \to z) - p(x_2 \to z) \le p(x_1 \to z) - \delta$.

            Доказали сближение $(M_{n + 1} - m_{n + 1}) \le (1 - \delta)(M_n - m_n)$.

            Таким образом, $m_n$ неубывает, $M_n$ невозрастает, $M_n - m_n \underset{n \to \infty}\Map 0$.
            Назначим за $\pi(y)$ общий предел последовательностей $m_n$ и $M_n$.
            Так как $|p^n(x \to y) - \pi(y)| \le M_n - m_n \le (1 - \delta)^n$, то~\eqref{eq:star} доказана.
        }
    }
    \examples[Теорема Маркова здесь неприменима]{
        \item <<Бесконечно плохой пример>>: случайное блуждание на квадрате из четырёх вершин. Вероятность перехода в диагонально противоположную вершину равна 0, вероятности $p^n(x \to y)$ не сходятся --- они периодично меняются с $\frac{1}{2}$ до $0$.
        \item Случайное блуждание по пятиугольнику из пяти вершин. Есть рёбра с вероятностью перехода 0, напрямую теорема неприменима.
        Но здесь за четыре шага можно попасть в любую вершину: $\forall x, y: p^4(x \to y) > 0$.

        \fact{
            Пусть цепь Маркова такова, что для некоторого $m \in \N: \forall x, y \in \mathcal{X}: p^m(x \to y) > 0$.
            Тогда $\exists !$ инвариантное распределение $\pi: p^n(x \to y) \underset{n \to \infty}\Map \pi(y)$.
            \provehere{
                Доказательство Маркова применимо к прореженной цепи $X_0, X_m, \dots$ с матрицей перехода $p^m$.
                Согласно ему, $p^{mn}(x \to y) \underset{n \to \infty}\Map \pi(y)$.

                \[p^k(x \to y) = p^{mn + l}(x \to y) = \sum\limits_{z \in \mathcal{X}}p^l(x \to z)p^{mn}(z \to y) \underset{n \to \infty}\Map \underbrace{\left(\sum\limits_{z \in \mathcal{X}}p^l(x \to z)\right)}_{1}\pi(y) = \pi(y)\]

            }
        }
    }
    \newlection{3 апреля 2023 г.}

    \subsection{Классификация состояний в цепях Маркова}
    Рассмотрим для примера цепь Маркова на таком графе:
% https://q.uiver.app/?q=WzAsOCxbMCwxLCJDIl0sWzEsMSwiQiJdLFsxLDAsIkQiXSxbMiwxLCJFIl0sWzIsMCwiRiJdLFszLDAsIkciXSxbMywxLCJIIl0sWzEsMiwiQSJdLFswLDEsIiIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6ImFycm93aGVhZCJ9fX1dLFsxLDIsIiIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6ImFycm93aGVhZCJ9fX1dLFsyLDAsIiIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6ImFycm93aGVhZCJ9fX1dLFszLDQsIiIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6ImFycm93aGVhZCJ9fX1dLFs0LDUsIiIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6ImFycm93aGVhZCJ9fX1dLFs1LDYsIiIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6ImFycm93aGVhZCJ9fX1dLFs2LDMsIiIsMCx7InN0eWxlIjp7InRhaWwiOnsibmFtZSI6ImFycm93aGVhZCJ9fX1dLFs3LDFdLFs3LDNdXQ==
    \[\begin{tikzcd}[ampersand replacement=\&]
          \& D \& F \& G \\
          C \& B \& E \& H \\
          \& A
          \arrow[tail reversed, from=2-1, to=2-2]
          \arrow[tail reversed, from=2-2, to=1-2]
          \arrow[tail reversed, from=1-2, to=2-1]
          \arrow[tail reversed, from=2-3, to=1-3]
          \arrow[tail reversed, from=1-3, to=1-4]
          \arrow[tail reversed, from=1-4, to=2-4]
          \arrow[tail reversed, from=2-4, to=2-3]
          \arrow[from=3-2, to=2-2]
          \arrow[from=3-2, to=2-3]
    \end{tikzcd}\]

    \subsubsection{Существенные и несущественные состояния}
    \definition[Состояние $y$ достижимо из $x$]{
        Существует такая последовательность состояний $x_0, \dots, x_m$, такая, что \[x_0 = x; x_m = y; \quad p(x_i \to x_{i + 1}) > 0\]
        Обозначается $x \dots \rightarrow y$
    }
    \definition[Существенное состояние $x$]{
        $\forall y$ такого, достижимого из $x$, можно вернуться: \[(x \dots \rightarrow y) \then (y \dots \rightarrow x)\]
    }
    \example{
        $A$ --- единственное несущественное состояние в графе в начала раздела.
    }
    \fact{
        Из существенного состояния можно перейти только в существенное.
        \provehere{
            От противного: $\exists z \in \mathcal{X}: (y \dots \rightarrow z) \land \neg (z \dots \rightarrow y)$. Тогда в частности $\neg (z \dots \rightarrow x)$, но $x \dots \rightarrow z$. Противоречие.
        }
    }
    \fact{
        В конечной цепи Маркова всегда найдётся хотя бы одно существенное состояние.
        \provehere{
            Рассмотрим цепочку состояний. Если $x_0\in \mathcal{X}$ (произвольный элемент) --- существенное состояние, то доказывать нечего.
            Иначе выберем $x_{1}$ как такое состояние, что $x_0 \dots \rightarrow x_1$, но не наоборот.

            Так дальше продолжим цепочку: $x_n \dots \rightarrow x_{n + 1}$.
            От противного: пусть она стала бесконечной, никакие состояния в ней не оказались существенными.
            Если в какой-то момент окажется, что $x_i = x_j$, то значит мы нашли цикл $x_i \dots \rightarrow \ldots \dots \rightarrow x_j$, и получили противоречие.
        }
    }
    \counterexample{
        В бесконечной цепи $p(n \to n + 1) = p(n \to n + 2) = \frac{1}{2}$ существенных состояний нет.
        Но, она, конечно, бесконечная.
    }
    \ok
    На множестве существенных состояний можно ввести отношение эквивалентности: \[x \sim y \iff x \dots \rightarrow y \lor x = y\]

    Симметричность: по определению того, что $x$ --- существенное состояние: $(x \dots \rightarrow y) \then (y \dots \rightarrow x)$.
    Транзитивность и рефлексивность очевидны из определения.
    \corollary{
        Множество существенных состояний распадается на классы достижимых --- \emph{эргодические классы}.
    }
    \fact{
        Каждый эргодический класс замкнут: из любого эргодического класса нельзя выйти.
        \provehere{
            Из всякого $x$ из данного эргодического класса можно попасть только в существенные $y$, которые по определению эквивалентны $x$.
        }
    }
    \example{В графе выше эти классы --- треугольник $BCD$ и четырёхугольник $E F G H$.}
    \definition[Неприводимая цепь Маркова]{
        В данной цепи нет замкнутых множеств кроме всего пространства $\mathcal{X}$.
    }
    Рассмотрим произвольное состояние $x \in \mathcal{X}$.
    По определению, множество точек, достижимых из $x$ (обозначим его $T_x$), замкнуто.

    В неприводимой цепи $\forall x \in \mathcal{X}: T_x = \mathcal{X}$, значит, эквивалентным определением неприводимой цепи является то, что из любого состояния можно добраться до любого другого.

    В частности, в неприводимой цепи все состояния --- существенны, образуют один эргодический класс.

    \subsection{Периодичность}
    Рассмотрим произвольное состояние $x \in \mathcal{X}$, обозначим $I_x \coloneqq \defset{k \in \N}{p^k(x \to x) > 0}$.
    Будем считать, что $I_x$ непустое.

    \definition[Период состояния $x$]{
        $d(x) = \gcd(I_x)$.
    }
    \note{Для произвольного $x$: $I_x$ --- полугруппа по сложению.}
    \fact{
        Существует конечное подмножество $I_x' \subset I_x$, такое, что $\gcd(I_x) = \gcd(I_x')$.
        \provehere{
            Положим $d_M \coloneqq \gcd(I_x \cap [1, M])$.
            С ростом $M$ последовательность множеств увеличивается по включению, $d_M$ убывает.

            Так как $d_M$ --- натуральные числа, то последовательность стабилизируется: $\exists M_0: \forall M > M_0: \gcd(I_x \cap [1, M]) = d_{M_0}$.
            Очевидно, в таком случае $I_x \cap [1, M]$ --- искомое подмножество.
        }
    }
    \fact{
        $\exists k_0 \in \N$:
        \[\defset{k \cdot d(x)}{k \in \N, k \ge k_0} \subset I_x \subset \defset{k\cdot d(x)}{k \in \N}\]
        \provehere{
            Правое включение очевидно верно независимо от $k_0$.
            \numbers{
                \item Найдём конечное множество $I_x' \subset I_x$, такое, что $\gcd(I_x') = d(x)$.
                \item Найдём линейную комбинацию элементов $I_x'$, такую, что $d(x) = \sum\limits_j{v_j \lambda_j}, v_j \in I_x', \lambda_j \in \Z$.
                \item Выберем $b \coloneqq \sum\limits_j{v_j |\lambda_j|}$.
                $b \in I_x$, как линейная комбинация его элементов с неотрицательными коэффициентами $|\lambda_j|$.

                Значит, $b$ представимо в виде $b = \beta \cdot d(x)$.
                \item Заметим, что $(\beta + 1)d(x) = \sum\limits_j{v_j \cdot (\lambda_j + |\lambda_j|)}$, что опять-таки линейная комбинация с неотрицательными коэффициентами, лежит в $I_x$.
                \item Рассмотрим достаточно большое $k \in \N$. Разделив на $\beta$ с остатком, получаем $k = r \beta + v$, где $0 \le v < \beta$.
                \[k = r \beta + v(\beta + 1) - v \beta = (r - v)\beta + v(\beta + 1)\]
                Для $r - v \ge 0$, например, для $k \ge \beta^2$: $k\cdot d(x) \in I_x$, как линейная комбинация $\beta \cdot d(x)$ и $(\beta + 1)\cdot d(x)$.

                Таким образом, $k_0 = \beta^2$ подходит.
            }
        }
    }
    \corollary{\label{trivial}
    В частности, $\exists k \in \N: kd \in I_x \land (k + 1)\cdot d(x) \in I_x$ (например, $k = \beta$).
    }
    \fact{
        Если два состояния сообщаются: $x \dots \rightarrow y$ и $y \dots \rightarrow x$, то $d(x) = d(y)$.
        \provehere{
            Пусть $p^a(x \to y) > 0$. Воспользуемся~(\ref{trivial}) применительно к $y$: есть два цикла, содержащих $y$, длин $k \cdot d(y)$ и $(k + 1)\cdot d(y)$.

            Тогда $a + k \cdot d(y) \in I_x$ и $a + (k + 1) \cdot d(y) \in I_x$ тоже. Отсюда сразу получаем $d(x) \divs d(y) = (a + (k + 1)\cdot d(y) - a - k \cdot d(y))$. Аналогично $d(y) \divs d(x)$, значит они равны.
        }
    }

    \subsection{Связь периодов и эргодических классов}
    Для произвольного эргодического класса $\mathcal{C} \subset \mathcal{X}$: $x, y \in \mathcal{C} \then d(x) = d(y)$.
    \provehere{
        $x$ и $y$ сообщаются, так как они в одном эргодическом классе.
    }

    \subsubsection{Циклические подклассы}
    Рассмотрим один эргодический класс, например, $\mathcal{C} = \{E, F, G, H\}$.
    Заметим, что для $\mathcal{C}_0 = \{E, G\}$ и $\mathcal{C}_1 = \{F, H\}$: из одного класса на следующем шаге можно попасть только в другой.

    Пусть $\mathcal{C}$ --- эргодический класс с периодом $d$.
    Тогда существует разбиение $\mathcal{C} = \mathcal{C}_0 \sqcup \mathcal{C}_1 \sqcup \dots \sqcup \mathcal{C}_{d - 1}$, такое, что вероятность перехода из $\mathcal{C}_i$ в $\mathcal{C}_{(i + 1) \pmod{d}}$ равна 1.

    Иными словами, $\forall x \in \mathcal{C}_i: p(x \to y) > 0 \then y \in \mathcal{C}_{(i + 1) \pmod{d}}$.
    Это называется \emph{разбиением на циклические подклассы}.

    \provehere{
        Выберем произвольное $x_0 \in \mathcal{C}$. Для всякого $y \in \mathcal{C}$ найдём такое $l(y): p^{l(y)}(x_0 \to y) > 0$.

        Положим $j(y) = l(y) \pmod{d}$ ($0 \le j(y) < d$).

        Определим $\forall j = 0 .. d - 1: \quad \mathcal{C}_j \coloneqq \defset{y \in \mathcal{C}}{j(y) = j}$.
        Ясно, что $\bigcup\limits_{j}\mathcal{C}_j = C$.

        Заметим, что если $p(y \to z) > 0$, то $p^{l(y)}(x_0 \to y) > 0 \then p^{l(y) + 1}(x_0 \to z) > 0$.
        Значит, действительно, $p(x \to y) > 0 \then y \in \mathcal{C}_{(i + 1) \pmod{d}}$.

        Осталось показать, что $\mathcal{C}_j$ не пересекаются.

        Пойдём от противного: пусть $y \in \mathcal{C}_{j_1} \cap \mathcal{C}_{j_2}$. Тогда $\exists l_1, l_2\in \N: p^{l_1}(x_0 \to y) > 0, p^{l_2}(x_0 \to y) > 0$.
        Так как $x_0$ и $y$ в одном эргодическом классе, то для некоторого $b \in \N: p^b(y \to x_0)$.
        значит, $l_1 + b \in I_{x_0}$ и $l_2 + b \in I_{x_0}$. Значит, они оба делятся на $d$, их разность делится на $d$, значит, $l_1 \equiv l_2 \pmod{d}$.
    }
    \newlection{10 апреля 2023 г.}
    \theorem[Марков]{
        Самая общая формулировка, которая у нас покамест встречалась, звучит так:

        Если для конечной цепи $\mathcal{X}$ существует $m \in \N: \forall x, y \in \mathcal{X}: p^m(x \to y) > 0$, то

        $\exists \pi$ --- распределение, такое, что $p^n(x \to y) \underset{n \to \infty}\Map \pi$, а ещё $\pi \cdot p = \pi$ и $\forall \pi_0: \pi_n(y) \underset{n \to \infty}\Map \pi$.
    }
    На этой лекции мы рассмотрим ещё две теоремы, далее обобщающие теорему Маркова.
    \theorem[Марков, для апериодических цепей]{
        Пусть $\mathcal{X}$ конечно и состоит из единственного эргодического класса с периодом 1.

        Утверждается, что тогда верно утверждение предыдущей теоремы (истинна посылка).
        \provehere{
            Пусть $x$ --- произвольное состояние.
            Тогда, согласно предыдущей лекции, существует достаточно большое $K(x): \forall k \ge K(x): p^k(x \to x) > 0$.

            По определению эргодического класса, $\exists a(x, y): p^{a(x, y)}(x \to y) > 0$.
            Тогда \[\forall k \ge K(x) + a(x, y): p^{k}(x \to y) > p^{k - a(x, y)}(x \to x)\cdot p^{a(x, y)}(x \to y) > 0\]

            Так как пар конечное число, то $m \coloneqq \max\limits_{x, y}\left(K(x) + a(x, y)\right)$ подойдёт.
        }
    }
    \note{
        Рассмотрим цепь, в которой есть один эргодический класс $\mathcal{C}$ и много несущественных состояний, из которых достижим данный класс.

        Формально, под условие теоремы эта цепь не подходит.
        Тем не менее, доказательство работает и здесь.
    }
    \textbf{Упражнение.} Если $\mathcal{X}$ конечно, и содержит единственный эргодический класс $\mathcal{C}$, причём его период --- 1, то утверждение теоремы Маркова тоже верно (правда, посылка в записанной форме не истинна), причём предельное распределение сосредоточено на эргодическом классе: $\sum\limits_{{y \in \mathcal{C}}}\pi(y) = 1$.

    \theorem[Марков, для периодических цепей]{
        Пусть $\mathcal{X}$ конечно и состоит из единственного эргодического класса с периодом $d > 1$.

        Для краткости записи обозначим $i \oplus j \coloneqq (i + j \pmod{d})$.

        Тогда, как уже доказано, $\mathcal{X} = \mathcal{C}_0 \sqcup \dots \sqcup \mathcal{C}_{d - 1}$, таких, что \[p(x \to y) > 0 \then \exists j \in [0, d): x \in \mathcal{C}_j, y \in \mathcal{C}_{j \oplus 1}\]
        Утверждается, что $\exists \{\pi_j\}_{j = 0}^{d - 1}$ --- система распределений, такая, что $\forall j: \pi_j$ сосредоточено на $\mathcal{C}_j$, и
        \[\forall x \in \mathcal{C}_i, y \in \mathcal{C}_{i\oplus j}: \lim\limits_{n \to \infty}p^{nd + j}(x \to y) = \pi_{i \oplus j}(y)\]
        Кроме того, условие инвариантности заменяется на условие $\pi_j \cdot p =\pi_{j \oplus 1}$.
        \provehere{
            Зафиксируем подкласс $\mathcal{C}_{i}$ и рассмотрим на нём марковскую цепь с переходной вероятностью $q \coloneqq p^d$.
            Заметим, что тогда $\mathcal{C}_i$ --- эргодический класс в новой цепи, причём его период --- 1.
            В самом деле, \gather{\forall x \in \mathcal{C}_i: \exists K: \forall k \ge K: p^{kd}(x \to x) > 0\\q^k(x \to x) > 0}
            Таким образом, период новой цепи равен 1, откуда получаем, что к новой цепи применима предыдущая теорема.

            А именно, существует распределение $\pi_i$ на $\mathcal{C}_i$:\[\forall x, y \in \mathcal{C}_i: q^n(x \to y) \underset{x \to y}\Map \pi_i(x \to y) \iff p^{nd}(x \to y) \underset{x \to y}\Map \pi_i(x \to y)\]
            Теперь рассмотрим два подкласса $\mathcal{C}_i$ и $\mathcal{C}_{i \oplus j}$ и произвольные $x \in \mathcal{C}_i, y \in \mathcal{C}_{i \oplus j}$.
            \[p^{nd + j}(x \to y) = p^{nd}p^j(x \to y) = \sum\limits_{z \in \mathcal{C}_{i \oplus j}}p^j(x \to z)\cdot p^{nd}(z \to y)\]
            Так как $p^{nd}(z \to y) \underset{n \to \infty}\Map \pi_{i \oplus j}(y)$, то $p^{nd + j}(x \to y)\underset{n \to \infty}\Map \left(\sum\limits_{z \in \mathcal{C}_{i \oplus j}}p^j(x \to z)\right) \cdot \pi_{i \oplus j}(y) = \pi_{i \oplus j}(y)$.

            Осталось доказать, что $\pi_j \cdot p = \pi_{j \oplus 1}$. Положим $y \in \mathcal{C}_{j + 1}$, запишем
            \[\pi_{j \oplus 1}(y) = \sum\limits_{x \in \mathcal{C}_j}\pi_j(x) \cdot p(x \to y)\]
            Для этого вспомним, что $\forall x_0 \in \mathcal{C}_j: \pi_j(x) = \lim\limits_{n \to \infty}p^{nd}(x_0 \to x)$.
            Тогда
            \[\pi_{j \oplus 1}(y) = \lim\limits_{n \to \infty}\sum\limits_{x \in \mathcal{C}_j}p^{nd}(x_0 \to x) \cdot p(x \to y)= \lim\limits_{n \to \infty}p^{nd + 1}(x \to y) \underset{\text{предыдущее утверждение для $j = 1$}}= \pi_{j \oplus 1}(y)\]
        }
    }

    \subsection{Возвратность}
    Пусть $\mathcal{X}$ --- быть может бесконечное пространство состояний.

    Выберем $x_0 \in \mathcal{X}$, обозначим за $f_i$ вероятность вернуться в $\mathcal{X}$ на $i$-м шаге:
    \[f_i(x_0) \coloneqq \P((x_1 \ne x_0) \land \dots \land (x_{i - 1} \ne x_0) \land (x_i = x_0))\]
    Так как события несовместны, то $\sum\limits_{i = 1}^{\infty}f_i(x_0) \le 1$.
    \definition[$x_0 \in \mathcal{X}$ --- возвратное состояние]{
        Такое состояние, для которого ${\sum\limits_{i = 1}^{\infty}f_i(x_0) = 1}$.

        При этом говорят, что $x_0$ --- \emph{положительно возвратно}, если $\sum\limits_{i = 1}^{\infty}i \cdot f_i(x_0) < \infty$, то есть матожидание времени возврата конечно.
        Иначе $x_0$ называется \emph{нуль-возвратным}.
    }
    \theorem[Критерий возвратности]{
        $x \in \mathcal{X}$ возвратно $\iff\sum\limits_{n = 1}^{\infty}p^n(x \to x) = \infty$.
        \provehere{
            Запишем двумя способами вероятность события пройти цикл из $x$ в $x$.
            \[p^n(x \to x) = \sum\limits_{i = 1}^{n}f_i(x) \cdot p^{n - i}(x \to x)\]
            Введём производящие функции $\mathcal{F}(z) = \sum\limits_{i = 1}^{\infty}f_i(x)z^i$ и $\mathcal{P}(z) = \sum\limits_{n = 0}^{\infty}p^n(x \to x)z^n$, действующие на $z \in [0, 1)$. Для них \[\mathcal{P}(z) = 1 + \mathcal{F}(z)\mathcal{P}(z)\]
            Таким образом, \[1 - \frac{1}{\mathcal{P}(z)} = \mathcal{F}(z)\]
            Перейдём к пределу при $z \to 1$. Равенство обратится в \[1 - \frac{1}{\sum\limits_{n = 1}^{\infty}p^n(x \to x)} = \sum\limits_{i = 1}^{\infty}f_i(x)\qedhere\]
        }
    }
    \fact{
        Если $x$ и $y$ сообщаются, то они либо оба возвратны, либо оба --- невозвратны.
        \provehere{
            $\exists a, b \in \N: p^a(x \to y) > 0$ и $p^b(y \to x) > 0$.
            Тогда запишем \[p^{n + a + b}(x \to x) \ge p^a(x \to y)p^n(y \to y)p^b(y \to x)\]
            Отсюда видим, что ряды $\sum\limits_{n = 1}^{\infty}p^n(x \to x)$ и $\sum\limits_{n = 1}^{\infty}p^n(y \to y)$ сходятся (или нет) одновременно.
        }
    }
    \corollary{
        Если в цепи все состояния сообщаются, то они все одновременно либо возвратны, либо нет.
    }
    \example[Самый знаменитый пример]{
        \textbf{Простое симметричное случайное блуждание на $\Z^d$.}

        Пусть мы находимcя в произвольной точке пространства $\Z^d \ni \vect{x_1 & \dots & x_d}$.
        На каждом шагу меняется произвольная координата с вероятностью $\frac{1}{2d}$ --- на $\pm 1$.

        Все точки сообщаются, значит, все они возвратны или невозвратны одновременно.
    }
    \newlection{17 апреля 2023 г.}
    \theorem[Пойа]{
        Симметричное случайное блуждание на целочисленной решётке $\Z^d$ возвратно $\iff d \le 2$.
        \provehere{
            Будем пользоваться не определением возвратности, а критерием --- про сходимость ряда.
            Идея состоит в том, что ${p^n(x \to x) \asymp n^{-\nicefrac{d}{2}}}$.
            Этот ряд сходится при $d \ge 3$.

            $p^{2n + 1}(0 \to 0) = 0$, поэтому для проверки расходимости ряда будем рассматривать чётные индексы.
            \numbers{
                \item[$d = 1.$] \[p_1^n(0 \to 0) = \binom{2n}{n}\left(\frac{1}{2}\right)^{2n} = \frac{(2n)!}{n!n!2^{2n}} \sim \frac{(\nicefrac{2n}{e})^n\sqrt{2\pi 2 n}}{(\nicefrac{n}{e})^{n}(\nicefrac{n}{e})^{n}\cdot\sqrt{2 \pi n}\sqrt{2 \pi n}\cdot 2^{2n}} = \frac{1}{\sqrt{\pi n}}\]
                Так как ряд расходится, то блуждание возвратно.
                \item[$d = 2.$] Представим себе блуждание по плоскости $x, y$ и рассмотрим замену переменных: $\all{u = x + y \\ v = x - y}$.
                Теперь обе координаты ($u, v$) независимы: \[\all{x \rightsquigarrow x + 1 \quad u \rightsquigarrow u + 1, v \rightsquigarrow v + 1 &\nicefrac{1}{4}\\x \rightsquigarrow x - 1 \quad u \rightsquigarrow u - 1, v \rightsquigarrow v - 1 &\nicefrac{1}{4}\\y \rightsquigarrow y + 1 \quad u \rightsquigarrow u + 1, v \rightsquigarrow v - 1 &\nicefrac{1}{4} \\ y \rightsquigarrow y - 1 \quad u \rightsquigarrow u - 1, v \rightsquigarrow v + 1 &\nicefrac{1}{4}}\]
                Таким образом, случайные блуждания по заменённым координатам независимы, откуда:
                \[p_2^{2n}(0 \underset{(x y)}\to 0) = p_2^{2n}(0 \underset{(u v)}\to 0) = p_1^{2n}(0 \underset{u}\to 0)\cdot p_1^{2n}(0 \underset{v}\to 0) = \frac{1}{\pi n}\]
                Ряд расходится, блуждание возвратно.
                \item[$d = 3.$]
                Введём $M_1, M_2, M_3$ --- число шагов вдоль осей $1, 2, 3$ --- случайные величины, такие, что $M_1 + M_2 + M_3 = 2n$.
                Также введём событие \[A_{m_1, m_2, m_3} = \{M_1 = 2m_1, M_2 = 2m_2, M_3 = 2m_3\}\]
                Запишем $p_3^{2n}(0 \to 0) = \sum\limits_{m_1, m_2, m_3}p_3^{2n}(0 \to 0 \land A_{m_1, m_2, m_3})$ --- формулу полной вероятности.
                Здесь есть плохие слагаемые, в которых одно из $m_1, m_2, m_3$ слишком мало.
                \[\E M_1 = \E M_2 = \E M_3 = \frac{2n}{3}; \qquad \D M_1 = \D M_2 = \D M_3 \sim \const\cdot n\]
                Согласно неравенству Чебышёва \[\P\left(M_1 \le \frac{n}3\right) = \P\left(M_1 - \E M_1 \le -\frac{n}{3}\right) \le \P\left(\abs{M_1 - \E M_1} \ge \frac{n}{3}\right) \le \frac{\D M_1}{(\nicefrac{n}3)}^2 = \frac{\const}{n}\]
                Эта оценка слишком слабая, она расходится и не помогает доказать сходимость.

                Воспользуемся лучше экспоненциальным неравенством Чебышёва:
                \gather{\P\left(M_1 \le \frac{n}{3}\right) = \P\left(-M_1 \ge -\frac{n}{3}\right) \le \frac{\E\left(e^{-M_1}\right)}{e^{-\nicefrac{n}{3}}} = \\
                    = \E\left(e^{-M_1}\right)\cdot e^{\nicefrac{n}{3}} = \left(\frac{2}{3} + \frac{1}{3}\cdot e^{-1}\right)^{2n} \cdot e^{\nicefrac{n}{3}} = \left(\left(\frac{2 + e^{-1}}{3}\right)^2 e^{\nicefrac{1}{3}}\right)^n \approx 0.87^n}

                Теперь \[\sum\limits_{m_1, m_2, m_3}p_3^{2n}(0 \to 0 \land A_{m_1, m_2, m_3}) \le \underset{m_1, m_2\text{ или }m_3\text{ меньше }\nicefrac{n}{3}}{\sum\limits_{m_1, m_2, m_3}}\P(A_{m_1, m_2, m_3}) + \underset{\text{иначе}}{\sum\limits_{m_1, m_2, m_3}}\P(0 \to 0 \land A_{m_1, m_2, m_3})\]
                Первая сумма сходится: оценивается суммой $\P\left(m_1 \le \frac{n}{3}\right) + \P\left(m_2 \le \frac{n}{3}\right) + \P\left(m_3 \le \frac{n}{3}\right)$, где каждое слагаемое оценено выше.

                Вторая сумма оценивается из формулы полной вероятности: $p_3^{2n}(0 \to 0\land A_{m_1, m_2, m_3}) = p_3^{2n}(0 \to 0| A_{m_1, m_2, m_3})\cdot \P(A_{m_1,m_2,m_3})$.
                Дальше $p_3^{2n}(0 \to 0| A_{m_1, m_2, m_3})$ раскладывается на три множителя по каждой координате:
                \[p_3^{2n}(0 \to 0| A_{m_1, m_2, m_3}) = p_1^{m_1}(0 \to 0) p_2^{m_1}(0 \to 0) p_1^{m_3}(0 \to 0) \le \frac{\const}{\sqrt{m_1}}\cdot \frac{\const}{\sqrt{m_2}}\cdot \frac{\const}{\sqrt{m_3}} \le \frac{\const}{n^{\nicefrac{3}{2}}}\]
                Таким образом, $\sum\limits_{m_1, m_2, m_3\text{, одно меньше }\nicefrac{n}{3}}p_3^{2n}(0 \to 0| A_{m_1, m_2, m_3})\cdot \P(A_{m_1,m_2,m_3}) \le  \frac{\const}{n^{\nicefrac{3}{2}}}$ --- события $A_{m_1, m_2, m_3}$ не пересекаются.
%
                Итак, ряд сходится, блуждание невозвратно.
                \item[$d > 3.$] Доказывается аналогично $d = 3$.
            }
        }
    }
    \section{Случайное блуждание в $\Z^1$}
    Случайное блуждание на $\Z$ можно воспринимать либо как сумму независимых случайных величин $X_j$, распределённых по закону $X_{i,j} = \all{+1,&\text{с вероятностью }p \\ -1,&\text{с вероятностью }q}$ (и $S_n = X_1 + \dots + X_n$), или как марковскую цепь
    \gather{\P(S_{n+1}=s+1|S_n = s) = p\\\P(S_{n+1}=s-1|S_n = s) = q}

    Исследуем некоторые параметры данного случайного блуждания.

    Обозначим за $R_n$ количество шагов вправо среди первых $n$ шагов.
    Это величина с биномиальным распределением $\mathcal{B}(n, p)$.
    $S_n = R_n - (n - R_n) = 2R_n - n$, откуда вероятность $\P(S_n \ge m)$ переписывается в виде $\P(2R_n - n \ge m) = \P(R_n \ge \frac{n + m}{2})$.

    Интегральная теорема Муавра-Лапласа говорит, что $\P\left(R_n \ge np + b\sqrt{np(1 - p)}\right) \underset{n \to \infty}\Map \frac{1}{\sqrt{2\pi}}\int\limits_{b}^{\infty}e^{-\frac{x^2}{2}}\d x$.
    В частности, для $p = \nicefrac{1}{2}$ получаем $\P(S_n \ge b\sqrt{n}) = \P(R_n \ge \frac{n}{2} + \frac12b\sqrt{n}) \underset{n \to \infty}\Map \frac{1}{\sqrt{2\pi}}\int\limits_{b}^{\infty}e^{-\frac{x^2}{2}}\d x$.

    Отсюда получаем следствие: характерное значение $S_n$ при $p = \nicefrac12$ имеет порядок $\bigO(\sqrt{n})$:
    \encircle{\P\left(b_1 \sqrt{n} \le S_n \le b_2\sqrt{n}\right) \underset{n \to \infty}\Map \frac{1}{\sqrt{2\pi}}\int\limits_{b_1}^{b_2}e^{-\frac{x^2}{2}}\d x}
    \subsection{Распределение максимума. Принцип отражения}
    Рассмотрим симметричное случайное блуждание на $\Z^1$.
    Обозначим за $M_n \coloneqq \max\limits_{0 \le j \le n}S_j$.
    Только что мы оценили, что характерное значение $S_n$ имеет порядок $\sqrt{n}$, а какого максимума следует ожидать?

    Разобьём событие на три дизъюнктных:
    \multline{\P(M_n \ge r) = \P(M_n \ge r, S_n > r) + \P(M_n \ge r, S_n = r) + \P(M_n \ge r, S_n < r) =\\= \P(S_n > r) + \P(S_n = r) + \P(M_n \ge r, S_n < r)}
    \fact{
    $\P(S_n > r) = \P(M_n \ge r, S_n < r)$.
    \provehere{
    Рассмотрим произвольное случайное блуждание, в котором $\{M_n \ge r, S_n < r\}$. На картинке ниже оно схематично изображено сплошными линиями.
    % https://q.uiver.app/#q=WzAsMTUsWzAsMywiXFxidWxsZXQiXSxbOCwzLCJrIl0sWzEsMiwiXFxidWxsZXQiXSxbMywyLCJcXGJ1bGxldCJdLFswLDAsIlNfayJdLFs0LDEsIlxcYnVsbGV0Il0sWzUsMCwiXFxidWxsZXQiXSxbNiwxLCJcXGJ1bGxldCJdLFs3LDAsIlxcYnVsbGV0Il0sWzUsMiwiXFxidWxsZXQiXSxbNywyLCJcXGJ1bGxldCJdLFsyLDMsIlxcYnVsbGV0Il0sWzgsMV0sWzAsMSwiclxccXVhZCJdLFs0LDMsIlxcYXJye2N9e1xcXFxrXzB9Il0sWzAsMV0sWzAsMiwiIiwyLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFswLDRdLFszLDUsIiIsMix7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XSxbNSw2LCIiLDIseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJub25lIn19fV0sWzYsNywiIiwyLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFs3LDgsIiIsMix7InN0eWxlIjp7ImJvZHkiOnsibmFtZSI6ImRhc2hlZCJ9LCJoZWFkIjp7Im5hbWUiOiJub25lIn19fV0sWzUsOSwiIiwyLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZGFzaGVkIn0sImhlYWQiOnsibmFtZSI6Im5vbmUifX19XSxbOSw3LCIiLDIseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkYXNoZWQifSwiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFs3LDEwLCIiLDIseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJub25lIn19fV0sWzIsMTEsIiIsMix7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XSxbMTEsMywiIiwyLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFsxMiwxMywiIiwyLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZG90dGVkIn0sImhlYWQiOnsibmFtZSI6Im5vbmUifX19XV0=
        \[\begin{tikzcd}[ampersand replacement=\&]
        {S_k} \&\&\&\&\& \bullet \&\& \bullet \\
        r\quad \&\&\&\& \bullet \&\& \bullet \&\& {} \\
        \& \bullet \&\& \bullet \&\& \bullet \&\& \bullet \\
        \bullet \&\& \bullet \&\& {\arr{c}{\\k_0}} \&\&\&\& k
        \arrow[from=4-1, to=4-9]
        \arrow[no head, from=4-1, to=3-2]
        \arrow[from=4-1, to=1-1]
        \arrow[no head, from=3-4, to=2-5]
        \arrow[no head, from=2-5, to=1-6]
        \arrow[no head, from=1-6, to=2-7]
        \arrow[dashed, no head, from=2-7, to=1-8]
        \arrow[dashed, no head, from=2-5, to=3-6]
        \arrow[dashed, no head, from=3-6, to=2-7]
        \arrow[no head, from=2-7, to=3-8]
        \arrow[no head, from=3-2, to=4-3]
        \arrow[no head, from=4-3, to=3-4]
        \arrow[dotted, no head, from=2-9, to=2-1]
        \end{tikzcd}\]
    Выделим минимальное $k_0$, такое что $S_{k_0} = r$ --- оно очевидно существует, так как $M_n \ge r$.
    Отразим от оси $S_k = r$ всю часть графика при $k > k_0$.

    Получили новый вариант развития случайного блуждания.
        Так как блуждание симметричное, то вероятность его появления такая же, как и у исходного.
    Более того, нетрудно видеть, что данное отражение задаёт биекцию между всеми событиями $\{S_n > r\}$ и $\{S_n < r, M_n \ge r\}$.
    }
    }
        Таким образом, получаем, что $\P(M_n \ge r) = 2\P(S_n > r) + \P(S_n = r)$.
    При стремлении $n \to \infty$ для любого конкретного $r: \P(S_n = r) \Map 0$, так как даже для $r = 0$ вероятность эквивалентна $\frac{1}{\sqrt{\pi n}}$, а из биномиальной формулы ясно, что $r = 0$ --- наиболее вероятно.

    Таким образом, применяя интегральную теорему Муавра-Лапласа, получаем
    \encircle{\P(M_n \ge b\sqrt{n}) \underset{n \to \infty}\Map \frac{2}{\sqrt{2\pi}}\int\limits_{b}^{\infty}e^{-\frac{x^2}{2}}\d x}



    \newlection{15 мая 2023 г.}


    \subsection{Время пребывания на полуоси (закон арксинуса)}
    Рассмотрим симметричное блуждание с $p = q = \frac{1}{2}$.
    Изобразим на своеобразном графике точки $(k, S_k)$, соединив последовательные отрезками.
% https://q.uiver.app/?q=WzAsMTAsWzAsMywiXFxidWxsZXQiXSxbOCwzLCJrIl0sWzEsMiwiXFxidWxsZXQiXSxbMiwxLCJcXGJ1bGxldCJdLFszLDIsIlxcYnVsbGV0Il0sWzUsNCwiXFxidWxsZXQiXSxbNCwzLCJcXGJ1bGxldCJdLFs2LDMsIlxcYnVsbGV0Il0sWzAsMCwiU19rIl0sWzcsNCwiXFxkZG90cyJdLFswLDFdLFswLDIsIiIsMix7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XSxbMiwzLCIiLDIseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJub25lIn19fV0sWzMsNCwiIiwyLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFs1LDYsIiIsMix7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XSxbNiw0LCIiLDEseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJub25lIn19fV0sWzcsNSwiIiwyLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFswLDhdLFs3LDksIiIsMCx7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XV0=
    \[\begin{tikzcd}[ampersand replacement=\&]
    {S_k}
          \\
          \&\& \bullet \\
          \& \bullet \&\& \bullet \\
          \bullet \&\&\&\& \bullet \&\& \bullet \&\& k \\
          \&\&\&\&\& \bullet \&\& \ddots
          \arrow[from=4-1, to=4-9]
          \arrow[no head, from=4-1, to=3-2]
          \arrow[no head, from=3-2, to=2-3]
          \arrow[no head, from=2-3, to=3-4]
          \arrow[no head, from=5-6, to=4-5]
          \arrow[no head, from=4-5, to=3-4]
          \arrow[no head, from=4-7, to=5-6]
          \arrow[from=4-1, to=1-1]
          \arrow[no head, from=4-7, to=5-8]
    \end{tikzcd}\]
    Назовём временем, проводимым на положительной оси $T_n = \sum\limits_{k = 1}^{n}\1_{\{s_k\ge 0, s_{k-1}\ge 0\}}$.
    Пусть $a, b \in (0, 1)$, найдём, чему пропорциональна вероятность $\P(a \le \frac{T_n}{n} \le b)$.

    Будем рассматривать чётные $n$, то есть обозначим их $2n$.
    Интересно заметить, что $T_{2n}$ всегда чётно: точки $S_k = 0$ появляются всегда при чётных $k$, и между соседними точками либо всё время --- пребывание на положительной полуоси, либо всё время --- пребывание на отрицательной полуоси.

    Будем использовать без доказательства факт $\P(T_{2n} = k) = \P(S_{2k} = 0) \cdot \P(S_{2(n-k)} = 0)$. (доказательство можно найти в учебнике Ширяева <<Вероятность>>, глава 1, параграф 10).

    Таким образом, мы можем выразить $(T_{2n} = k)$ с помощью простых методов:
    \gather{\P(S_{2k} = 0) = 2^{-2k}\binom{2k}{k} = \frac{1}{\sqrt{\pi k}}(1 + o(1))\\
    \P(S_{2(n-k)} = 0) = \frac{1}{\sqrt{\pi(n-k)}}(1 + o(1))}
    Теперь можно записать
    \[\P\left(a < \frac{T_n}{n} < b\right) = \sum\limits_{a < \frac{k}{n} < b}\frac{1}{\sqrt{\pi k}} \cdot \frac{1}{\sqrt{\pi(n - k)}}(1 + o(1)) = \frac{1}{\pi}\cdot\sum\limits_{a < \frac{k}{n} < b}\frac{1}{\sqrt{\frac{k}{n}}} \cdot \frac{1}{\sqrt{1 - \frac{k}{n}}} \cdot \frac{1}{n}(1 + o(1))\]
    Заметим, что теперь под суммой стоит сумма Римана-Дарбу, можем записать свойство интеграла Римана
    \[\frac{1}{\pi}\cdot\sum\limits_{a < \frac{k}{n} < b}\frac{1}{\sqrt{\frac{k}{n}}} \cdot \frac{1}{\sqrt{1 - \frac{k}{n}}} \cdot \frac{1}{n}(1 + o(1)) \underset{n \to \infty}\Map \frac{1}{\pi}\int\limits_{a}^{b}\frac{\d u}{\sqrt{u(1 - u)}} = I(b) - I(a)\]
    где в качестве $I$ подойдёт любая первообразная.
    Любопытно, что здесь есть две разные естественно выглядящие первообразные
    \gather{I_1(x) = \frac{1}{\pi}\arcsin(2x - 1) \\ I_2(x) = \frac{2}{\pi}\arcsin(\sqrt{x})}
    Это можно видеть из тождества $\arcsin(2x - 1) + \frac{\pi}{2} = 2\arcsin(\sqrt{x})$ при $x \in [0, 1]$.
    (Проверяется взятием косинуса от обоих частей)

    График $\frac{1}{\sqrt{u (1 - u)}}$ выглядит, как U-образная кривая, с концами, уходящими в бесконечность, поэтому распределение сосредоточено около границ.

    Если рассмотреть случайную величину $Z$ с распределением $\P(Z \in [a, b]) = \frac{1}{\sqrt{\pi}}\int\limits_{a}^{b}\frac{\d u}{\sqrt{u(1 - u)}}$, то окажется, что она с очень большой вероятностью распределена близко к краю:
    \[\P(Z \le 0.024) \approx 0.1 \qquad \P(Z \le 0.006) \approx 0.05\]

    \subsection{Задача о разорении игрока}
    Пусть у I игрока есть $|A|$ монет (мы будем считать $A < 0$), у II игрока --- $B$ монет, и пусть они играют в азартную игру.
    У I игрока вероятность выигрыша $p$, у II игрока --- $q = 1 - p$.
    По выигрышу проигравший платит одну монету другому, игра заканчивается, когда один из них разорится.

    Исследуем эту модель.
    Заметим, что это на самом деле тоже случайное блуждание, заканчивающееся когда $S_k$ выходит из интервала $[A, B]$:
    % https://q.uiver.app/?q=WzAsMTYsWzEsNCwiXFxidWxsZXQiXSxbMiwzLCJcXGJ1bGxldCJdLFszLDIsIlxcYnVsbGV0Il0sWzQsMywiXFxidWxsZXQiXSxbNiw1LCJcXGJ1bGxldCJdLFs1LDQsIlxcYnVsbGV0Il0sWzcsNCwiXFxidWxsZXQiXSxbOCw1LCJcXGJ1bGxldCJdLFsxLDcsIlxcYnVsbGV0Il0sWzAsMSwiQiJdLFsxMCwxXSxbOSw2LCJcXHRleHR7SSDQv9GA0L7QuNCz0YDQsNC7fSJdLFsxMSw0LCJcXGJ1bGxldCJdLFswLDYsIkEiXSxbMTAsNl0sWzEsMCwiU19rIl0sWzAsMSwiIiwyLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFsxLDIsIiIsMix7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XSxbMiwzLCIiLDIseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJub25lIn19fV0sWzQsNSwiIiwyLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFs1LDMsIiIsMSx7InN0eWxlIjp7ImhlYWQiOnsibmFtZSI6Im5vbmUifX19XSxbNiw0LCIiLDIseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJub25lIn19fV0sWzYsNywiIiwwLHsic3R5bGUiOnsiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFs5LDEwLCIiLDAseyJzdHlsZSI6eyJib2R5Ijp7Im5hbWUiOiJkb3R0ZWQifSwiaGVhZCI6eyJuYW1lIjoibm9uZSJ9fX1dLFs3LDExLCIiLDAseyJzdHlsZSI6eyJoZWFkIjp7Im5hbWUiOiJub25lIn19fV0sWzAsMTJdLFsxMywxNCwiIiwwLHsic3R5bGUiOnsiYm9keSI6eyJuYW1lIjoiZG90dGVkIn0sImhlYWQiOnsibmFtZSI6Im5vbmUifX19XSxbOCwxNV1d
    \[\begin{tikzcd}[ampersand replacement=\&]
          \& {S_k} \\
          B \&\&\&\&\&\&\&\&\&\& {} \\
          \&\&\& \bullet \\
          \&\& \bullet \&\& \bullet \\
          \& \bullet \&\&\&\& \bullet \&\& \bullet \&\&\&\& \bullet \\
          \&\&\&\&\&\& \bullet \&\& \bullet \\
          A \&\&\&\&\&\&\&\&\& {\text{I проиграл}} \& {} \\
          \& \bullet
          \arrow[no head, from=5-2, to=4-3]
          \arrow[no head, from=4-3, to=3-4]
          \arrow[no head, from=3-4, to=4-5]
          \arrow[no head, from=6-7, to=5-6]
          \arrow[no head, from=5-6, to=4-5]
          \arrow[no head, from=5-8, to=6-7]
          \arrow[no head, from=5-8, to=6-9]
          \arrow[dotted, no head, from=2-1, to=2-11]
          \arrow[no head, from=6-9, to=7-10]
          \arrow[from=5-2, to=5-12]
          \arrow[dotted, no head, from=7-1, to=7-11]
          \arrow[from=8-2, to=1-2]
    \end{tikzcd}\]
    Положим $\beta_k(x)$ --- вероятность выйти на $B$ раньше, чем на $A$ не более чем за $k$ шагов, исходя из точки $x$.
    Эти величины мы можем рассматривать в дискретной теории вероятностей, так как бесконечных траекторий несчётное количество.

    Заметим, что $\beta_k(x)$ монотонно возрастает по $k$, но, очевидно, $\beta_k(x)$ ограничена.
    Значит, имеется предел, который мы и хотим вычислить.

    Запишем своеобразную рекурренту на $\beta$: с вероятностью $p$ первый шаг --- в положительном направлении, с вероятностью $q$ --- в отрицательном
    \[\beta_k(x) = p \beta_{k - 1}(x + 1) + q \beta_{k - 1}(x - 1)\]
    Перейдя к пределу по $k$ получаем \gather{\beta(x) = p\beta(x + 1) + q\beta(x - 1)\\
    p\beta(x) + q\beta(x) = p\beta(x +1) + q\beta(x - 1) \\ q(\beta(x) - \beta(x - 1)) = p(\beta(x + 1) - \beta(x)) \\
    \beta(x + 1) - \beta(x) = \frac{q}{p}(\beta(x) - \beta(x - 1))}
    Таким образом, последовательные разности $\beta(x + 1) - \beta(x)$ образуют геометрическую прогрессию.
    Воспользовавшись начальными условиями $\all{\beta(B) = 1\\\beta(A) = 0}$ можно получить точную формулу.
    В частности, для $p = q = \frac{1}2$ получается неожиданно простая формула
    \[\beta(0) = \frac{|A|}{B + |A|}\]
    Если $p \ne q$, то можно решить систему из $B + |A| + 1$ линейных уравнений, результатом будет \[\beta(x) = \frac{\left(\nicefrac{q}{p}\right)^x  - \left(\nicefrac{1}{p}\right)^A}{\left(\nicefrac{q}{p}\right)^B  - \left(\nicefrac{1}{p}\right)^A}\]
    \note{
        Случайное блуждание не может бесконечное время болтаться внутри ограниченного отрезка.
        Вероятность того, что рано или поздно кто-то выиграет стремится к единице.
        Доказательство остаётся читателю в качестве упражнения.
    }

    \subsection{Матожидание времени разорения}
    Задача прежняя --- есть два игрока с капиталами $|A|$, $B$, $p, q$ --- вероятности их выигрышей соответственно.

    Обозначим $T(x)$ --- время разорения одного из игроков, если блуждание началось в точке $x$.
    Чему равно $\E T(x)$?

    Как и в предыдущей задаче, ограничим игру конечным числом ходов: $T_k(x) = \all{T(x),&T(x) \le k \\ k,&T(x) \ge k}$.
    Используемая выше $T(x)$ --- величина, которую мы не можем рассматривать в дискретной теории вероятностей.
    Чтобы этого избежать, рассмотрим величины $T_k(x)$ и найдём $\lim\limits_{k \to \infty}\E T_k(x)$.

    Обозначим $m_k(x) \coloneqq \E T_k(x)$. $m_k(x)$ тоже монотонно возрастет по $k$.
    Более того, у него есть предел --- вероятность того, что $T(x) > n$ экспоненциально убывает, но выкладок, обосновывающих это, нет.
    \[m_k(x) = \all{p m_{k-1}(x + 1) + qm_{k-1}(x - 1) + 1,&x \in (A, B)\\0,&x = A \lor x = B}\]
    Преобразуем первое равенство, перейдя в нём к пределу по $k \to \infty$.
    \gather{
        pm(x) + qm(x) = pm(x + 1) + qm(x - 1) + 1 \\
        p(m(x + 1) - m(x)) = q(m(x) - m(x - 1)) - 1 \\
        m(x + 1) - m(x) = \frac{q}{p}(m(x) - m(x - 1)) - \frac{1}{p}
    }
    Это опять же решаемая система, но для экономии времени лекции приведём лишь решение для $p = q = \frac{1}{2}$:
    \[m(x + 1) - m(x) = (m(x) - m(x - 1)) - 2\]
    Решением является многочлен второй степени с корнями в $A$ и $B$.
    $m(x) = K(x - A)(x - B)$.
    Подгоняя $K$ так, чтобы выполнялось уравнение $m(x + 1) - m(x) = (m(x) - m(x - 1)) - 2$ понимаем, что $K = -1$.
    \[m(x) = (B - x)(x - A)\text{; в частности, } m(0) = |A|\cdot B\]
    Если $p \ne q$, то ответ чуть более противный:
    \[m(0) = \frac{B - A}{p - q}\cdot\frac{1 - \left(\nicefrac{q}{p}\right)^A}{\left(\nicefrac{q}{p}\right)^B - \left(\nicefrac{q}{p}\right)^A} + \frac{A}{p - q}\]


    \section{Случайные графы}
    В нашей жизни есть огромное множество графов: графов друзей социальных сетей, граф аэропортов и авиалиний, граф совместных научных публикаций и граф цитирований\ldots

    small world --- маленькость мира, диаметры реальных графов (длина пути --- количество рёбер) очень малы.
    Так, в графе совместных публикаций научного мира диаметр порядка 10.

    Графы бывают статические и динамические --- во времени меняются последние.

    Типичная статическая модель: граф Эрдёша-Реньи на $n$ вершинах $G(n, p)$, в котором каждое из $\binom{n}2$ рёбер проведено с вероятностью $p$.

    Самая знаменитая динамическая модуль: модель преимущественного присоединения.
    Начнём с какого-то простого графа, на каждом шаге добавляем вершину и одно ребро из неё, ведущее к какой-нибудь из существующих вершин, причём вероятность пропорциональна степени вершины.
\newlection{22 мая 2023 г.}
    \subsection{Граф Эрдёша-Реньи}
    Рассмотрим множество из $n$ вершин, каждое из $\binom{n}2$ рёбер проведено в вероятностью $p$ независимо от других --- случайный граф $G(n, p)$.

    Рассмотрим последовательность $p_n$ и изучим поведение $G(n, p)$ при $n \to \infty$.

    \intfact[Условие связности]{\down
    \bullets{
        \item Если $\varliminf\limits_{n \to \infty} \frac{p_n}{\nicefrac{\log n}{n}} > 1$, то $\P(G(n, p_n)\text{ связен}) \underset{n \to \infty}\Map 1$.
        \item Если $\varlimsup\limits_{n \to \infty} \frac{p_n}{\nicefrac{\log n}{n}} < 1$, то $\P(G(n, p_n)\text{ связен}) \underset{n \to \infty}\Map 0$.
    }
    }
    Обозначим за $M_n$ размер максимальной компоненты связности в $G(n, p_n)$.
    \intfact[О гигантской компоненте]{\down
    \bullets{
        \item Если $\varliminf\limits_{n \to \infty} \frac{p_n}{\nicefrac{1}{n}} \eqqcolon \gamma > 1$, то $\exists a(\gamma): \P(M_n > a(\gamma)\cdot n) \underset{n \to \infty}\Map 1$.
        \item Если $\varlimsup\limits_{n \to \infty} \frac{p_n}{\nicefrac{1}{n}} \eqqcolon \gamma < 1$, то $\exists b(\gamma): \P(M_n \le b(\gamma)\cdot \log n) \underset{n \to \infty}\Map 1$.
    }
    }

    \subsection{power law for degrees (степенной закон для степеней (вершин))}
    Рассмотрим большой граф из $n$ вершин;\ обозначим за $V_n^{(d)}$ количество вершин степени $d$.

    Оказывается, часто имеет место приближение $V_n^{(d)} \approx (ad^{-\alpha})n$, где $\alpha \in (2, 5)$ --- для разных графов предлагались разные значения.
    $a$ и $\alpha$ --- константы, зависящие от типа графа, но не зависящие от $d$, иначе было бы совсем неинтересно.
    Тем не менее, $\alpha$ меняется не очень сильно, а $a$ находится из уравнения $V_n^{(0)} + V_n^{(1)} + \dots + V_n^{(n)} = n$.

    \subsection{Дерево преимущественного присоединения}
    Рассмотрим в качестве начального состояния граф $K_2$, состоящий из двух вершин и одного ребра.

    На $k$-м шаге в граф добавляется вершина с номером $k + 2$, и из неё добавляется ровно одно случайное ребро, причём оно проведено к вершине $i \in [1, k + 1]$ с вероятностью, пропорциональной $\deg(i)$, где $\deg$ --- степень в графе на первых $k + 1$ вершинах.

    После шага $n$ в графе $n + 2$ вершины, $n + 1$ ребро, несложно видеть, что граф связен и является деревом.
    \subsubsection{Поведение степеней вершин}
    Обозначим за $X_n^{(m)}$ степень вершины $m$ после шага $n$.

    <<Кто не успел, тот опоздал>>

    Рассмотрим $m = 1$. $X_0^{(1)} = 1$ --- после 0-го шага величина пока неслучайная.
    Запишем уравнения на развитие случайной переменной $X_n^{(1)}$.
    \gather{
        \P\left(X_{n + 1}^{(1)} - X_n^{(1)} = 1 \middle| X_n^{(1)} = k\right) = \frac{k}{2(n + 1)}\\
        \P\left(X_{n + 1}^{(1)} - X_n^{(1)} = 0 \middle| X_n^{(1)} = k\right) = 1 - \frac{k}{2(n + 1)}
    }
    Посчитаем от величины $X_n^{(1)}$ только её матожидание.
    \[\E\left(X_{n + 1}^{(1)}\right) - \E\left(X_n^{(1)}\right) = \E\left(X_{n + 1}^{(1)} - X_n^{(1)}\right) = \P\left(X_{n + 1}^{(1)} - X_n^{(1)} = 1\right) = \sum\limits_{k = 1}^{\infty}\P\left(X_n^{(1)} = k\right)\frac{k}{2(n + 1)}\]
    В этом месте чудесным образом появляется матожидание, получаем рекурренту на матожидание
    \[\E\left(X_{n + 1}^{(1)}\right) - \E\left(X_n^{(1)}\right) = \E\left(X_n^{(1)} \cdot \frac{1}{2(n + 1)}\right)\]
    откуда $\E X_{n + 1}^{(1)}  = \E X_n^{(1)} \left(1 + \frac{1}{2(n + 1)}\right) = \E X_n^{(1)} \cdot \frac{2n + 3}{2(n + 1)} = \frac{(2n + 3)!!}{(2n+2)!!}$.
    Используя формулу Стирлинга, получаем
    \[(2n)!! = 2^n n! \sim 2^n \sqrt{2 \pi n}\left(\frac{n}{e}\right)^n\qquad (2n + 1)!! = \frac{(2n + 1)!}{(2n)!}\]
    откуда \[\E X_n^{(1)} = \frac{(2n + 1)!}{((2n)!!)^2} \sim \frac{\sqrt{2 \pi (2n + 1)}\left(\frac{2n + 1}{e}\right)^{2n + 1}}{2^{2n}(2 \pi n)\left(\frac{n}{e}\right)^{2n}} \sim \frac{1}{\sqrt{\pi}}\frac{\sqrt{2 \cdot 2n}}{2n}\underbrace{\left(\frac{2n + 1}{2n}\right)^{2n}}_{\to e}\frac{2n + 1}{e} \sim \frac{2}{\sqrt{\pi}}\sqrt{n}\]
    Заметим, что в графе $2(n + 1)$ рёбер всего, поэтому в среднем степень вершины порядка $2$.
    Таким образом, видим, что степень первой вершины сильно больше средней степени.

    Очевидно, $\E X_n^{(2)} = \E X_n^{(1)}$.
    Можно написать формулу для произвольной вершины, она доказывается примерно так же.
    \[\E X_n^{(l + 1)} \sim \frac{2}{\sqrt{\pi}}\frac{(2l - 2)!!}{(2l-1)!!}\sqrt{n}\text{, где можно записать }\frac{(2l - 2)!!}{(2l - 1)!!}\sim l^{-\nicefrac{1}{2}}\]
    \subsection{Распределение степеней вершин}
    Пусть $V_n^{(d)}$ --- количество вершин степени $d$ после шага $n$.

    Рассмотрим $d = 1$.
    После 0 шагов $V_0^{(d)} = 2$ --- величина ещё неслучайная.
    Опять же, выпишем условные вероятности.
    Заметим, что $V_{n+1}^{(1)} - V_{n + 1}^{(1)}$ ---всегда либо 0, либо 1 (добавляется вершина степени 1, но, быть может, одна из вершин степени 1 станет вершиной степени 2).
    \gather{
        \P\left(V_{n+1}^{(1)} - V_{n + 1}^{(1)} = 0 \middle| V_n = k\right) = \frac{k}{2(n+1)}\\
        \P\left(V_{n+1}^{(1)} - V_{n + 1}^{(1)} = 1 \middle| V_n = k\right) = 1-\frac{k}{2(n+1)}\\
    }
    Аналогично подсчёту $\E X_{n}^{(1)}$ получаем
    \[\E V_{n + 1}^{(1)} - \E V_n^{(1)} = \E \left(V_{n + 1}^{(1)} - V_n^{(1)}\right) = \P\left(V_{n + 1}^{(1)} - V_n^{(1)} = 1\right) = \sum\limits_{k = 1}^{\infty}\left(1 - \frac{k}{2(n + 1)}\right)\P\left(V_n^{(1)} = k\right)\]
    Суммируя вероятности $\P(V_n^{(1)} = k)$ получаем 1;\ во второй половине правой части формулы опять получается матожидание.
    Значит,
    \[\E V_{n + 1}^{(1)} - \E V_n^{(1)} = 1 - \frac{\E V_n^{(1)}}{2(n + 1)}\]
    Чтобы решить эту рекурренту, предположим, что $\E V_n^{(1)} \sim \alpha n$ для некоего $\alpha \in \R$.
    По-хорошему, это надо обосновать, но давайте опустим.

    Тогда решая уравнение $\alpha = 1 - \frac{\alpha}{2}$, получаем $\alpha = \frac{2}{3}$.
    \[{\E V_n^{(1)} \underset{n \to \infty}\sim \frac{2}{3}n}\]
    В общем случае получится формула \[{\E V_n^{(d)} \underset{n \to \infty}\sim \frac{4}{d(d + 1)(d + 2)}n \underset{d \to \infty}\sim \frac{4}{d^3}n}\]
\end{document}